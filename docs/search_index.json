[["rolling-stones-auf-twitter.html", "Kapitel 14 Rolling Stones auf Twitter 14.1 Der Tod von Charlie Watts 14.2 Programme 14.3 Datenstrom holen 14.4 Tweets holen 14.5 Datensatz erstellen 14.6 Datensatz speichern 14.7 Datensatz laden 14.8 Verfasser der Tweets 14.9 Timeplot 14.10 User-Informationen 14.11 Geographische Verteilung 14.12 Speichern des erweiterten Datensatzes 14.13 Laden des erweiterten Datensatzes 14.14 Zeitlicher geographischer Verlauf 14.15 Lange Wörter 14.16 Topwörter 14.17 Netzwerke 14.18 Sentiment &amp; Emotion 14.19 Sentiment (Animation)", " Kapitel 14 Rolling Stones auf Twitter 14.1 Der Tod von Charlie Watts 14.2 Programme library(tidyverse) library(tidytext) library(rtweet) Das rtweet-Programm ermöglicht den Zugang zu Twitter-Texten und Twitter-Usern. Dazu benötigt man einen Twitter-Account, außerdem muss man eine Twitter-App einstellen. Das erfordert eine Telefonnummer zur Verifizierung. Genauere Angaben sind auf verschiedenen Internetseiten zu finden, z.B. Twitter-App setup. Im rtweet package stehen mehrere Funktionen zur Verfügung, um tweets vom Twitter-API zu erfassen: search_tweets()  erfasst Tweets der letzten 6-9 Tage, die einem vom User festgelegten Stichwort (query) entsprechen. stream_tweets()  erfasst Tweets aus dem live Datenstrom get_timelines()  erfasst Tweets von ausgewählten Twitter-Nutzern. Die Tweets (d.h. der Text und zahlreiche Metadaten) werden in der Form eines Datensatzes (data.frame bzw. tibble) organisiert und können auch auf der Festplatte gespeichert werden. 14.3 Datenstrom holen Eine Möglichkeit ist die Tweets live einzufangen, und zwar mit der Funktion stream_tweets(). library(tidyverse) library(rtweet) ## Stream keywords used to filter tweets q &lt;- &quot;RollingStones&quot; ## Stream for 30 minutes streamtime &lt;- 30 * 60 ## Filename to save json data (backup) filename &lt;- &quot;data/rollingstones.json&quot; ## Stream tweets rt_rollingstones &lt;- stream_tweets(q = q, timeout = streamtime, file_name = filename) Laden der gespeicherten Daten von Disk: library(jsonlite) fromJSON(&quot;data/rollingstones.json&quot;) 14.4 Tweets holen Typischerweise laden wir die Tweets der letzten sechs bis neun Tage herunter, indem wir in die Funktion search_tweets() ein Schlagwort (q) eingeben, das unserem Ziel entspricht. Die Anzahl der Tweets in unserer Recherche ist begrenzt (n = 18000 Tweets). Will man zwei oder mehrere miteinander auftretende Wörter (etwa Kollokationen) in einer Recherche verwenden, sollte man ein Pluszeichen zwischen die Wörter setzen, z.B. q = \"Charlie+Watts\". Die Argumente q und n sind notwendig zur Recherche. Die Suchfunktion hat mehrere optionale Argumente, z.B. die Sprache lang, Herausfiltern von Retweets mit Hilfe des Schalters include_rts = FALSE u.a. Tweets in deutscher Sprache zum Thema RollingStones: library(tidyverse) library(rtweet) q &lt;- &quot;RollingStones&quot; tweets_rollingstones_de &lt;- search_tweets(q = q, n = 18000, token = bearer_token(), include_rts = FALSE, `-filter` = &quot;replies&quot;, lang = &quot;de&quot;) tweets_rollingstones_de Ein Retweet bedeutet, dass ein Nutzer den Tweet einer anderen Person teilt, so dass auch die Follower den Beitrag sehen können. Tweets und Retweets kann man separat aus dem Datensatz abrufen. Tweets in slowenischer Sprache zum Thema RollingStones: q &lt;- &quot;RollingStones&quot; tweets_rollingstones_sl &lt;- search_tweets(q = q, n = 18000, token = bearer_token(), include_rts = FALSE, `-filter` = &quot;replies&quot;, lang = &quot;sl&quot;) tweets_rollingstones_sl Tweets in englischer Sprache zum Thema RollingStones: q &lt;- &quot;RollingStones&quot; tweets_rollingstones_en &lt;- search_tweets(q = q, n = 18000, token = bearer_token(), include_rts = FALSE, `-filter` = &quot;replies&quot;, lang = &quot;en&quot;) tweets_rollingstones_en 14.5 Datensatz erstellen Die drei sprachspezifischen Tabellen wollen wir in einer gemeinsamen Tabelle speichern. Die Tabellenspalte lang enthält eine Angabe darüber, welche Sprache in den einzelnen Tweets verwendet wurden. tweets_rollingstones &lt;- bind_rows(tweets_rollingstones_sl, tweets_rollingstones_de, tweets_rollingstones_en) 14.6 Datensatz speichern Die gemeinsame Tabelle können wir nun auf Festplatte speichern. Die Datei mit der Endung rds kann nur vom Programm R gelesen werden. Eine Excel-Datei kann man beispielsweise mit dem writexl-Packet schreiben. library(writexl) write_xlsx(tweets_rollingstones, &quot;data/tweets_rollingstones.xlsx&quot;) write_rds(tweets_rollingstones, &quot;data/tweets_rollingstones.rds&quot;) 14.7 Datensatz laden Am nächsten Tag fahren wir mit unsere Analyse fort und laden unseren Datensatz. tweets_rollingstones &lt;- read_rds(&quot;data/tweets_rollingstones.rds&quot;) 14.8 Verfasser der Tweets Unter den Twitternutzern, die Tweets anlässlich des Todes von Charlie Watts, dem Drummer der Rolling Stones, sind einige uns bekannte Namen zu finden, z.B. der slowenische Radiosender Val202. Die Schreiber der Tweets findet man in der Tabellenspalte screen_name. tweets_rollingstones %&gt;% filter(str_detect(screen_name, &quot;Val202&quot;)) ## # A tibble: 2 x 90 ## user_id status_id created_at screen_name text source ## &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 69192762 1430413916652331008 2021-08-25 06:17:08 Val202 &quot;\\&quot;Bil je~ Tweet~ ## 2 69192762 1430410967565967361 2021-08-25 06:05:25 Val202 &quot;\\&quot;Nepisa~ Tweet~ ## # ... with 84 more variables: display_text_width &lt;dbl&gt;, ## # reply_to_status_id &lt;chr&gt;, reply_to_user_id &lt;chr&gt;, ## # reply_to_screen_name &lt;chr&gt;, is_quote &lt;lgl&gt;, is_retweet &lt;lgl&gt;, ## # favorite_count &lt;int&gt;, retweet_count &lt;int&gt;, quote_count &lt;int&gt;, ## # reply_count &lt;int&gt;, hashtags &lt;list&gt;, symbols &lt;list&gt;, urls_url &lt;list&gt;, ## # urls_t.co &lt;list&gt;, urls_expanded_url &lt;list&gt;, media_url &lt;list&gt;, ## # media_t.co &lt;list&gt;, media_expanded_url &lt;list&gt;, media_type &lt;list&gt;, ... tweets_rollingstones_sl &lt;- subset(tweets_rollingstones, lang == &quot;sl&quot;) ## plot multiple time series by first grouping the data by screen name tweets_rollingstones_sl %&gt;% dplyr::group_by(screen_name) %&gt;% ts_plot() + ggplot2::labs( title = &quot;Tweets after the death of Charlie Watts, drummer&quot;, subtitle = &quot;Tweets collected, parsed, and plotted using `rtweet`&quot; ) Tweets der deutschen Zeitung FAZ (Frankfurter Allgemeine Zeitung): tweets_rollingstones %&gt;% filter(str_detect(screen_name, &quot;faznet&quot;)) ## # A tibble: 2 x 90 ## user_id status_id created_at screen_name text source ## &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 18047862 1430211425927053315 2021-08-24 16:52:30 faznet Der Schla~ Socia~ ## 2 18047862 1430274310845894661 2021-08-24 21:02:23 faznet Er galt a~ Socia~ ## # ... with 84 more variables: display_text_width &lt;dbl&gt;, ## # reply_to_status_id &lt;chr&gt;, reply_to_user_id &lt;chr&gt;, ## # reply_to_screen_name &lt;chr&gt;, is_quote &lt;lgl&gt;, is_retweet &lt;lgl&gt;, ## # favorite_count &lt;int&gt;, retweet_count &lt;int&gt;, quote_count &lt;int&gt;, ## # reply_count &lt;int&gt;, hashtags &lt;list&gt;, symbols &lt;list&gt;, urls_url &lt;list&gt;, ## # urls_t.co &lt;list&gt;, urls_expanded_url &lt;list&gt;, media_url &lt;list&gt;, ## # media_t.co &lt;list&gt;, media_expanded_url &lt;list&gt;, media_type &lt;list&gt;, ... Der Tagesspiegel: tweets_rollingstones %&gt;% filter(str_detect(screen_name, &quot;Tagesspiegel&quot;)) ## # A tibble: 3 x 90 ## user_id status_id created_at screen_name text source ## &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 22926365 1430548477952593922 2021-08-25 15:11:50 Tagesspiegel &quot;Verdamm~ Twitt~ ## 2 22926365 1431571952779550722 2021-08-28 10:58:45 Tagesspiegel &quot;#Rollin~ Tweet~ ## 3 22926365 1430269270609571847 2021-08-24 20:42:21 Tagesspiegel &quot;Charlie~ Twitt~ ## # ... with 84 more variables: display_text_width &lt;dbl&gt;, ## # reply_to_status_id &lt;chr&gt;, reply_to_user_id &lt;chr&gt;, ## # reply_to_screen_name &lt;chr&gt;, is_quote &lt;lgl&gt;, is_retweet &lt;lgl&gt;, ## # favorite_count &lt;int&gt;, retweet_count &lt;int&gt;, quote_count &lt;int&gt;, ## # reply_count &lt;int&gt;, hashtags &lt;list&gt;, symbols &lt;list&gt;, urls_url &lt;list&gt;, ## # urls_t.co &lt;list&gt;, urls_expanded_url &lt;list&gt;, media_url &lt;list&gt;, ## # media_t.co &lt;list&gt;, media_expanded_url &lt;list&gt;, media_type &lt;list&gt;, ... tweets_rollingstones_de &lt;- subset(tweets_rollingstones, lang == &quot;de&quot;) ## plot multiple time series by first grouping the data by screen name tweets_rollingstones_de %&gt;% group_by(created_at, screen_name) %&gt;% count(screen_name, sort = TRUE) %&gt;% ungroup() %&gt;% mutate(screen_name = fct_lump(screen_name, 9)) %&gt;% dplyr::group_by(screen_name) %&gt;% ts_plot() + ggplot2::labs(y = &quot;log10(# Tweets)&quot;, title = &quot;Tweets after the death of Charlie Watts, drummer&quot;, subtitle = &quot;Tweets collected, parsed, and plotted using `rtweet`&quot; ) + scale_y_log10() ## Warning: Transformation introduced infinite values in continuous y-axis tweets_rollingstones_en &lt;- subset(tweets_rollingstones, lang == &quot;en&quot;) ## plot multiple time series by first grouping the data by screen name tweets_rollingstones_en %&gt;% group_by(created_at, screen_name) %&gt;% count(screen_name, sort = TRUE) %&gt;% ungroup() %&gt;% mutate(screen_name = fct_lump(screen_name, 9)) %&gt;% dplyr::group_by(screen_name) %&gt;% ts_plot() + ggplot2::labs(y = &quot;log10(# Tweets)&quot;, title = &quot;Tweets after the death of Charlie Watts, drummer&quot;, subtitle = &quot;Tweets collected, parsed, and plotted using `rtweet`&quot; ) + scale_y_log10() ## Warning: Transformation introduced infinite values in continuous y-axis 14.9 Timeplot Die Anzahl der veröffentlichten Tweets zum Thema können wir in einem Diagramm chronologisch darstellen. Im folgenden Diagramm bildet die Anzahl der Tweets innerhalb von drei Stunden jeweils einen Datenpunkt. Zunächst bilden wir die englischsprachigen Tweets ab. ## plot time series of tweets tweets_rollingstones_en = subset(tweets_rollingstones, lang == &quot;en&quot;) p1 &lt;- ts_plot(tweets_rollingstones_en, &quot;3 hours&quot;, color = &quot;red&quot;) + ggplot2::theme_minimal() + ggplot2::theme(plot.title = ggplot2::element_text(face = &quot;bold&quot;)) + ggplot2::labs( x = NULL, y = NULL, title = &quot;Frequency of #rollingstones Twitter statuses from past 9 days&quot;, subtitle = &quot;Twitter status (tweet) counts aggregated using three-hour intervals&quot;, caption = &quot;\\nSource: Data collected from Twitter&#39;s REST API via rtweet&quot; ) library(plotly) ## ## Attaching package: &#39;plotly&#39; ## The following object is masked from &#39;package:ggplot2&#39;: ## ## last_plot ## The following object is masked from &#39;package:stats&#39;: ## ## filter ## The following object is masked from &#39;package:graphics&#39;: ## ## layout ggplotly(p1) Die deutschsprachigen Tweets: ## plot time series of tweets tweets_rollingstones_de = subset(tweets_rollingstones, lang == &quot;de&quot;) p2 &lt;- ts_plot(tweets_rollingstones_de, &quot;3 hours&quot;, color = &quot;darkgreen&quot;) + ggplot2::theme_minimal() + ggplot2::theme(plot.title = ggplot2::element_text(face = &quot;bold&quot;)) + ggplot2::labs( x = NULL, y = NULL, title = &quot;Frequency of #rollingstones Twitter statuses from past 9 days&quot;, subtitle = &quot;Twitter status (tweet) counts aggregated using three-hour intervals&quot;, caption = &quot;\\nSource: Data collected from Twitter&#39;s REST API via rtweet&quot; ) library(plotly) ggplotly(p2) In beiden Fällen flacht die Verlaufskurve schnell ab. 14.10 User-Informationen Aus unserem Datensatz können wir mit users_data() auch Informationen über die Twitter-Nutzer herausholen, die einen Tweet zum Thema #RollingStones (in den vergangenen 6-9 Tagen) verfasst hat, z.B. wie viele Follower sie haben, wie viele Freunde, wie viele Tweets sie verfasst haben, Beschreibungen über sich selbst u.a. tweets_rollingstones %&gt;% users_data() %&gt;% rmarkdown::paged_table() Ähnliche (obwohl weniger nützliche) Funktionen sind users_with_tweets() und tweets_with_users(). users_with_tweets(tweets_rollingstones) tweets_with_users(tweets_rollingstones) 14.11 Geographische Verteilung Aus welchen Ländern stammen die englischsprachigen Tweets? In der Tabellenspalte country finden wir leider in den meisten Fällen keine Angabe (NA), aber die am häufigsten angezeigten Staaten sind die USA, Großbritannien, Ausralien, Kanada und Irland, in denen Englisch Amtssprache ist. tweets_rollingstones_en %&gt;% count(country, sort = TRUE) ## # A tibble: 48 x 2 ## country n ## &lt;chr&gt; &lt;int&gt; ## 1 &lt;NA&gt; 17024 ## 2 United States 393 ## 3 United Kingdom 153 ## 4 Australia 69 ## 5 Canada 53 ## 6 Ireland 20 ## 7 France 19 ## 8 Argentina 15 ## 9 Brazil 15 ## 10 Italy 15 ## # ... with 38 more rows Wählen wir die Tabellenspalte location als Ausgangspunkt, dann erhalten wir recht chaotische Sammlung von Stadt-, Staats- und anderen geographischen Bezeichnungen, die man nach vorheriger Bereinigung nutzen könnte, z.B. kartographisch. tweets_rollingstones_en %&gt;% count(location, sort = TRUE) ## # A tibble: 6,264 x 2 ## location n ## &lt;chr&gt; &lt;int&gt; ## 1 &quot;&quot; 4682 ## 2 &quot;United States&quot; 155 ## 3 &quot;London, England&quot; 130 ## 4 &quot;London&quot; 126 ## 5 &quot;Los Angeles, CA&quot; 109 ## 6 &quot;United Kingdom&quot; 106 ## 7 &quot;Canada&quot; 101 ## 8 &quot;Chicago, IL&quot; 95 ## 9 &quot;New York, NY&quot; 91 ## 10 &quot;UK&quot; 75 ## # ... with 6,254 more rows Für eine graphische Darstellung wählen wir an dieser Stelle die (unkomplizierte) country-Spalte. library(lubridate) ## ## Attaching package: &#39;lubridate&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union p3 &lt;- tweets_rollingstones_en %&gt;% select(created_at, country) %&gt;% mutate(date = lubridate::as_date(created_at)) %&gt;% group_by(date, country) %&gt;% count(country, sort = TRUE) %&gt;% drop_na() %&gt;% ungroup() %&gt;% mutate(country = fct_lump(country, 9)) %&gt;% # nur 9+1 Staaten ggplot(aes(date, n, fill = country)) + geom_col() library(plotly) ggplotly(p3) Die graphische Darstellung für die deutschen Tweets nach Staaten: p4 &lt;- tweets_rollingstones_de %&gt;% select(created_at, country) %&gt;% mutate(date = lubridate::as_date(created_at)) %&gt;% group_by(date, country) %&gt;% count(country, sort = TRUE) %&gt;% drop_na() %&gt;% ungroup() %&gt;% mutate(country = fct_lump(country, 9)) %&gt;% ggplot(aes(date, n, fill = country)) + geom_col() library(plotly) ggplotly(p4) library(ggthemes) m1 &lt;- tweets_rollingstones %&gt;% unnest(geo_coords) %&gt;% unnest(coords_coords) %&gt;% separate(geo_coords, into = c(&quot;latitude&quot;,&quot;longit&quot;), sep = &quot;;&quot;, remove = FALSE, extra = &quot;merge&quot;) %&gt;% separate(coords_coords, into = c(&quot;longitude&quot;,&quot;latit&quot;), sep = &quot;;&quot;, remove = FALSE, extra = &quot;merge&quot;) %&gt;% mutate(latitude = parse_number(latitude), longitude = parse_number(longitude)) %&gt;% select(country, latitude, longitude, screen_name, status_id, location, text) %&gt;% filter(latitude != &quot;&quot; | longitude != &quot;&quot;) %&gt;% distinct(status_id, .keep_all = TRUE) %&gt;% ggplot(aes(longitude, latitude, color = country)) + borders() + geom_point() + theme_map() + theme(legend.position = &quot;bottom&quot;) + labs(title = &quot;Tweets around the World after Death of Charlie Watts&quot;, color = &quot;Country&quot;) ## Warning: Expected 2 pieces. Missing pieces filled with `NA` in 204 rows [2965, ## 2966, 2967, 2968, 7961, 7962, 7963, 7964, 8465, 8466, 8467, 8468, 8469, 8470, ## 8471, 8472, 9065, 9066, 9067, 9068, ...]. ## Warning: Expected 2 pieces. Missing pieces filled with `NA` in 204 rows [2965, ## 2966, 2967, 2968, 7961, 7962, 7963, 7964, 8465, 8466, 8467, 8468, 8469, 8470, ## 8471, 8472, 9065, 9066, 9067, 9068, ...]. library(plotly) ggplotly(m1) Es gibt mehrere Datensätze, in denen die geographische Lage von Städten (also Längen- und Breitengrad) gespeichert ist. Das rtweet-Paket verfügt über einen kleineren Datensatz, erreichbar durch: rtweet:::citycoords ## # A tibble: 747 x 3 ## city lat lng ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 aberdeen scotland 57.2 -2.15 ## 2 aberdeen 57.2 -2.15 ## 3 aberdeen scotland 57.2 -2.15 ## 4 adelaide australia -34.9 139. ## 5 adelaide -34.9 139. ## 6 adelaide australia -34.9 139. ## 7 algiers algeria 36.8 3 ## 8 algiers 36.8 3 ## 9 algiers algeria 36.8 3 ## 10 amsterdam netherlands 52.4 4.88 ## # ... with 737 more rows Einen wesentlich umfangreicheren Datensatz findet man auf der Webseite von simplempas, neben den Angaben zur geographischen Lage und Staatszugehörigkeit auch die Einwohnerzahl. world_cities &lt;- read_csv(&quot;data/worldcities.csv&quot;) ## Rows: 41001 Columns: 11 ## -- Column specification -------------------------------------------------------- ## Delimiter: &quot;,&quot; ## chr (7): city, city_ascii, country, iso2, iso3, admin_name, capital ## dbl (4): lat, lng, population, id ## ## i Use `spec()` to retrieve the full column specification for this data. ## i Specify the column types or set `show_col_types = FALSE` to quiet this message. world_cities &lt;- world_cities %&gt;% select(city_ascii, country, lat, lng) %&gt;% rename(city = city_ascii, state_country = country) head(world_cities) ## # A tibble: 6 x 4 ## city state_country lat lng ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Tokyo Japan 35.7 140. ## 2 Jakarta Indonesia -6.21 107. ## 3 Delhi India 28.7 77.2 ## 4 Mumbai India 19.0 72.8 ## 5 Manila Philippines 14.6 121. ## 6 Shanghai China 31.2 121. Die letztere Datensammlung fügen wir mit der Funktion left_join() unserem Twitter-Datensatz hinzu. Im Twitter-Datensatz nehmen wir außerdem mehrere Korrekturen vor, und zwar mit den tidyverse-Funktionen separate() zur Trennung von Tabellenspalten, str_replace() zum Austausch von Angaben in den Tabellenspalten, str_to_sentence() zur Vereinheitlichung der Schreibweise sowie ifelse() und str_detect(), um Bezeichnungen unter passenden Bedingungen in einer Tabellenspalte ausfindig zu machen und zu ersetzen. tweets_rollingstones_cities &lt;- tweets_rollingstones %&gt;% separate(location, into = c(&quot;city&quot;, &quot;state_country&quot;), extra = &quot;merge&quot;, fill = &quot;right&quot;, sep = &quot;, &quot;, remove = FALSE) %&gt;% separate(location, into = c(&quot;city&quot;, &quot;state_country&quot;), extra = &quot;merge&quot;, fill = &quot;right&quot;, sep = &quot; &quot;, remove = FALSE) %&gt;% mutate(state_country = str_replace(state_country, &quot;- &quot;, &quot;&quot;)) %&gt;% mutate(state_country = str_replace(state_country, &quot;\\\\| &quot;, &quot;&quot;)) %&gt;% mutate(city = str_replace(city, &quot;,&quot;, &quot;&quot;)) %&gt;% mutate(city = str_to_sentence(city)) %&gt;% mutate(state_country = str_to_sentence(state_country)) %&gt;% mutate(state_country = ifelse( country == &quot;United States&quot;, &quot;United States&quot;, state_country)) %&gt;% mutate(state_country = ifelse( country == &quot;United Kingdom&quot;, &quot;United Kingdom&quot;, state_country)) %&gt;% mutate(state_country = ifelse( str_detect(country, &quot;Ireland&quot;), &quot;Ireland&quot;, state_country)) %&gt;% mutate(state_country = ifelse( str_detect(country, &quot;Australia&quot;), &quot;Australia&quot;, state_country)) %&gt;% mutate(state_country = str_replace( state_country, &quot;Western australia&quot;, &quot;Australia&quot;)) %&gt;% mutate(state_country = str_replace(state_country, &quot;Slovenija&quot;, &quot;Slovenia&quot;)) %&gt;% mutate(state_country = str_replace(state_country, &quot;Deutschland&quot;, &quot;Germany&quot;)) %&gt;% mutate(state_country = str_replace(state_country, &quot;Österreich&quot;, &quot;Austria&quot;)) %&gt;% mutate(state_country = str_replace(state_country, &quot;Schweiz&quot;, &quot;Switzerland&quot;)) %&gt;% mutate(state_country = str_replace(state_country, &quot;England&quot;, &quot;United Kingdom&quot;)) %&gt;% mutate(state_country = str_replace(state_country, &quot;am Main&quot;, &quot;Germany&quot;)) %&gt;% mutate(city = str_replace(city, &quot;Zürich&quot;, &quot;Zurich&quot;)) %&gt;% mutate(city = str_replace(city, &quot;Wien&quot;, &quot;Vienna&quot;)) %&gt;% mutate(city = str_replace(city, &quot;München&quot;, &quot;Munich&quot;)) %&gt;% mutate(city = str_replace(city, &quot;Köln&quot;, &quot;Cologne&quot;)) %&gt;% mutate(city = str_replace(city, &quot;Düsseldorf&quot;, &quot;Dusseldorf&quot;)) %&gt;% mutate(city = str_replace(city, &quot;Gießen&quot;, &quot;Giessen&quot;)) %&gt;% mutate(state_country = ifelse( city %in% c(&quot;Ljubljana&quot;,&quot;Maribor&quot;,&quot;Celje&quot;,&quot;Kranj&quot;, &quot;Lucija&quot;), &quot;Slovenia&quot;, state_country)) %&gt;% mutate(state_country = ifelse(city %in% c(&quot;Zurich&quot;,&quot;Basel&quot;), &quot;Switzerland&quot;, state_country)) %&gt;% mutate(state_country = ifelse(city %in% c(&quot;Vienna&quot;,&quot;Graz&quot;), &quot;Austria&quot;, state_country)) %&gt;% mutate(state_country = ifelse(city %in% c(&quot;Teheran&quot;), &quot;Iran&quot;, state_country)) %&gt;% mutate(state_country = ifelse(city %in% c(&quot;Strasbourg&quot;), &quot;France&quot;, state_country)) %&gt;% mutate(state_country = ifelse( city %in% c(&quot;Berlin&quot;,&quot;Munich&quot;,&quot;Hamburg&quot;,&quot;Essen&quot;,&quot;Heilbronn&quot;, &quot;Dortmund&quot;,&quot;Cologne&quot;,&quot;Frankfurt&quot;,&quot;Hannover&quot;, &quot;Giessen&quot;,&quot;Konstanz&quot;,&quot;Rostock&quot;,&quot;Dusseldorf&quot;, &quot;Augsburg&quot;,&quot;Lohmar&quot;), &quot;Germany&quot;, state_country)) %&gt;% mutate(state_country = ifelse( str_detect(location, &quot;United Kingdom&quot;), &quot;United Kingdom&quot;, state_country)) %&gt;% mutate(city = ifelse(location == &quot;United Kingdom&quot;, &quot;United Kingdom&quot;, city)) %&gt;% mutate(state_country = ifelse( str_detect(location, &quot;United States&quot;), &quot;United States&quot;, state_country)) %&gt;% mutate(city = ifelse(location == &quot;United States&quot;, &quot;&quot; , city)) %&gt;% mutate(state_country = ifelse( str_detect(location, &quot;Germany&quot;), &quot;Germany&quot;, state_country)) %&gt;% mutate(city = ifelse(location == &quot;Germany&quot;, &quot;&quot; , city)) %&gt;% mutate(city = ifelse(location == &quot;Las Vegas, NV&quot;, &quot;Las Vegas&quot; , city)) %&gt;% mutate(state_country = ifelse(location == &quot;Las Vegas, NV&quot;, &quot;United States&quot; , state_country)) %&gt;% mutate(city = ifelse(location == &quot;Toronto/Las Vegas&quot;, &quot;Toronto&quot; , city)) %&gt;% mutate(state_country = ifelse(location == &quot;Toronto/Las Vegas&quot;, &quot;Canada&quot; , state_country)) %&gt;% mutate(city = ifelse(location == &quot;san francisco&quot;, &quot;San Francisco&quot; , city)) %&gt;% mutate(state_country = ifelse(location == &quot;san francisco&quot;, &quot;United States&quot; , state_country)) Der korrigierte und mit left_join() erweiterte Datensatz: tweets_rollingstones_cities_joined &lt;- tweets_rollingstones_cities %&gt;% left_join(world_cities, by = c(&quot;city&quot;, &quot;state_country&quot;)) tweets_rollingstones_cities_joined %&gt;% select(location, country, city, state_country, lat, lng) ## # A tibble: 18,951 x 6 ## location country city state_country lat lng ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 &quot;&quot; &lt;NA&gt; &quot;&quot; &lt;NA&gt; NA NA ## 2 &quot;Lucija, Istra, Slovenija&quot; &lt;NA&gt; &quot;Lucija&quot; Slovenia NA NA ## 3 &quot;Ljubljana, Slovenia&quot; &lt;NA&gt; &quot;Ljubljana&quot; Slovenia 46.0 14.5 ## 4 &quot;&quot; &lt;NA&gt; &quot;&quot; &lt;NA&gt; NA NA ## 5 &quot;&quot; &lt;NA&gt; &quot;&quot; &lt;NA&gt; NA NA ## 6 &quot;Slovenija&quot; &lt;NA&gt; &quot;Slovenija&quot; &lt;NA&gt; NA NA ## 7 &quot;Ljubljana, Slovenia&quot; &lt;NA&gt; &quot;Ljubljana&quot; Slovenia 46.0 14.5 ## 8 &quot;Ljubljana, Slovenia&quot; &lt;NA&gt; &quot;Ljubljana&quot; Slovenia 46.0 14.5 ## 9 &quot;Slovenija&quot; &lt;NA&gt; &quot;Slovenija&quot; &lt;NA&gt; NA NA ## 10 &quot;slovenija&quot; &lt;NA&gt; &quot;Slovenija&quot; &lt;NA&gt; NA NA ## # ... with 18,941 more rows 14.12 Speichern des erweiterten Datensatzes write_rds(tweets_rollingstones_cities_joined, &quot;data/tweets_rollingstones_cities_joined.rds&quot;) library(writexl) write_xlsx(tweets_rollingstones_cities_joined, &quot;data/tweets_rollingstones_cities_joined.xlsx&quot;) 14.13 Laden des erweiterten Datensatzes Am nächsten Tag brauchen wir nicht all die oben durchgeführten Schritte noch einmal durchzuführen, sondern hier an dieser Stelle den relevanten Datensatz laden und weitermachen. tweets_rollingstones_cities_joined &lt;- read_rds(&quot;data/tweets_rollingstones_cities_joined.rds&quot;) Eine einfache Weltkarte aus dem ggthemes-Paket, auf der die einzelnen Twitterorte als farbige Punkte eingetragen sind. library(ggthemes) m2 &lt;- tweets_rollingstones_cities_joined %&gt;% # unnest(geo_coords) %&gt;% # unnest(coords_coords) %&gt;% # separate(geo_coords, into = c(&quot;latitude&quot;,&quot;longit&quot;), # sep = &quot;;&quot;, remove = FALSE, extra = &quot;merge&quot;) %&gt;% # separate(coords_coords, into = c(&quot;longitude&quot;,&quot;latit&quot;), # sep = &quot;;&quot;, remove = FALSE, extra = &quot;merge&quot;) %&gt;% # mutate(latitude = parse_number(latitude), # longitude = parse_number(longitude)) %&gt;% select(country, lat, lng, state_country, screen_name, status_id, location, text) %&gt;% filter(lat != &quot;&quot; | lng != &quot;&quot;) %&gt;% # distinct(status_id, .keep_all = TRUE) %&gt;% ggplot(aes(lng, lat, color = state_country, alpha = 0.3)) + borders() + geom_point() + theme_map() + theme(legend.position = &quot;none&quot;) + labs(title = &quot;Tweets around the World after Death of Charlie Watts&quot;, color = &quot;Country&quot;) ggsave(&quot;pictures/worldmap_tweets_rollingstones.png&quot;, width = 12, height = 9) library(plotly) ggplotly(m2) Eine detailliertere und vergrößerbare Weltkarte (Paket leaflet) mit den Twitterorten aus unserem Twitter-Datensatz über den Drummer Charlie Watts und die Rolling Stones. library(leaflet) library(glue) ## ## Attaching package: &#39;glue&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## collapse library(htmlwidgets) library(DT) template &lt;- &quot;&lt;&gt;{ city }&lt;/p&gt;&lt;p&gt;{ state_country }&lt;/p&gt;&quot; tweets_rollingstones_cities_joined %&gt;% gather(key, value, city) %&gt;% mutate(key = str_to_title(str_replace_all(key, &quot;_&quot;, &quot; &quot;)), key = paste0(&quot;&lt;b&gt;&quot;, key, &quot;&lt;/b&gt;&quot;)) %&gt;% replace_na(list(value = &quot;Unknown&quot;)) %&gt;% nest(data = c(key, value)) %&gt;% mutate(html = map(data, knitr::kable, format = &quot;html&quot;, escape = FALSE, col.names = c(&quot;&quot;, &quot;&quot;))) %&gt;% leaflet() %&gt;% addTiles() %&gt;% addCircleMarkers(lat = ~ lat, lng = ~ lng, color = ~ state_country, popup = ~ html, radius = 3) %&gt;% addMeasure() ## Warning in validateCoords(lng, lat, funcName): Data contains 17983 rows with ## either missing or invalid lat/lon values and will be ignored 14.14 Zeitlicher geographischer Verlauf Mit dem Paket gganimate sind auch Animationen möglich, die die Entwicklung eines Prozesses graphisch darstellen. In diesem Fall soll gezeigt werden, wann und wo auf der Welt Tweets nach dem Tod von Charlie Watts verfasst wurden. Nach den oben durchgeführten Korrekturen und Erweiterungen verfügen wir zumindest über fast 1000 Tweets mit ausgewiesenen Twitterorten (d.h. mit den Koordinaaten ihrer geographischen Lage), was für eine Demonstration der Animation ausreicht. Im ersten Schritt leiten wir mit Hilfe von mutate() aus der Tabellenspalte created at eine Datumsspalte (date_time) ab und fügen sie unserem Datensatz hinzu. Im folgenden Chunk haben wir noch zwei weitere Datumsspalten als Varianten geschaffen, die wir bei Bedarf verwenden könnten. tweets_rollingstones_time &lt;- tweets_rollingstones_cities_joined %&gt;% mutate(date_time = lubridate::as_datetime(created_at)) %&gt;% mutate(dates = lubridate::as_date(created_at)) %&gt;% mutate(seconds = as.numeric(lubridate::as_datetime(created_at))) tweets_rollingstones_time %&gt;% select(date_time, dates, seconds) %&gt;% arrange(date_time) %&gt;% head(3) ## # A tibble: 3 x 3 ## date_time dates seconds ## &lt;dttm&gt; &lt;date&gt; &lt;dbl&gt; ## 1 2021-08-24 16:38:55 2021-08-24 1629823135 ## 2 2021-08-24 16:40:43 2021-08-24 1629823243 ## 3 2021-08-24 16:42:03 2021-08-24 1629823323 Nun wird die Animation vorbereitet, angezeigt und als gif-Datei gespeichert. library(gganimate) library(gifski) library(ggthemes) start = lubridate::as_datetime(&quot;2021-08-24 16:38:55&quot;) # start = as_date(&quot;2021-08-24 16:38:55&quot;) anim_graph &lt;- tweets_rollingstones_time %&gt;% arrange(date_time) %&gt;% filter(!is.na(lat) &amp; !is.na(lng)) %&gt;% filter(date_time &gt;= start) %&gt;% add_count(city, name = &quot;city_count&quot;) %&gt;% mutate(volume = city_count) %&gt;% ggplot(aes(lng, lat)) + borders() + geom_point(aes(size = volume, color = volume)) + theme_map() + scale_color_gradient2(low = &quot;blue&quot;, high = &quot;red&quot;, midpoint = log10(.01), trans = &quot;log10&quot;, guide = &quot;none&quot;) + scale_size_continuous(range = c(1, 6)) + # 38 # transition_reveal(start_date) + transition_time(date_time) + labs( title = &quot;Tweets about the Rolling Stones: { round(frame_time) }&quot;) + theme(legend.position = &quot;none&quot;) # animation.hook=&quot;gifski&quot; animate(anim_graph, nframes = 300, fps = 5, device = &quot;png&quot;) anim_save(&quot;pictures/rolling_stones_tweets_animated.png&quot;) anim_graph 14.15 Lange Wörter Ein spezielles Paket (ggpage), mit dem wir uns eine grobe graphische Übersicht über bestimmte quantifizierte Eigenschaften von Texten verschaffen können, und zwar über die Länge von Wörtern und ihre Textstelle. Diese graphische Darstellung kann insbesondere bei kürzeren Texten effektvoll eingesetzt werden. library(ggpage) ## Warning: package &#39;ggpage&#39; was built under R version 4.1.1 tweets_rollingstones_de %&gt;% ggpage_build() %&gt;% mutate(long_word = stringr::str_length(word) &gt; 8) %&gt;% ggpage_plot(aes(fill = long_word)) + labs(title = &quot;Longer words throughout the German Tweets&quot;) + scale_fill_manual(values = c(&quot;grey70&quot;, &quot;blue&quot;), labels = c(&quot;8 or less&quot;, &quot;9 or more&quot;), name = &quot;Word length&quot;) ## Warning: Use of `data$xmin` is discouraged. Use `xmin` instead. ## Warning: Use of `data$xmax` is discouraged. Use `xmax` instead. ## Warning: Use of `data$ymin` is discouraged. Use `ymin` instead. ## Warning: Use of `data$ymax` is discouraged. Use `ymax` instead. 14.16 Topwörter Für die Textzerlegung und Analyse stehen uns mehrere Pakete zur Verfügung, z.B. quanteda, udpipe oder tidytext, mit denen wir schon gearbeitet haben. Wir wählen hier das tidytext-Programm für die Textzerlegung. Zuerst bereiten wir eine Stoppwordliste für die deutsche Sprache vor. Dann wählen wir für die Zerlegung des Textes in Wörter eine besondere Einstellung, nämlich token = \"tweets\", bei der hashtags (#) und URL erhalten bleiben, so dass man danach suchen kann oder sie auch abzählen oder analysieren kann. Will man nur den reinen Text analysieren, ist es notwendig, diese besonderen Zeichenfolgen aus den Tweets zu entfernen. Verwendet man die tidytext-Funktionen, kann man das Argument token = \"tweets\" einfach weglassen oder eine der anderen Optionen verwenden (z.B. token = \"words\"). Je nach Zielsetzung erhalten wir Großbuchstaben (to_lower = FALSE) oder nicht (to_lower = TRUE). Wörter in deutschen Tweets: library(tidytext) stoplist_de &lt;- as_tibble(quanteda::stopwords(&quot;german&quot;)) %&gt;% rename(word = value) tw_rs_de_words &lt;- tweets_rollingstones_de %&gt;% unnest_tokens(word, text, token = &quot;tweets&quot;, to_lower = TRUE) %&gt;% anti_join(stoplist_de) %&gt;% count(word, sort = TRUE) ## Using `to_lower = TRUE` with `token = &#39;tweets&#39;` may not preserve URLs. ## Joining, by = &quot;word&quot; tw_rs_de_words %&gt;% rmarkdown::paged_table() Wortwolke aus deutschen Tweets: library(wordcloud2) wordcloud2(tw_rs_de_words) Englische Tweets: stoplist_en &lt;- stop_words tw_rs_en_words &lt;- tweets_rollingstones_en %&gt;% unnest_tokens(word, text, token = &quot;tweets&quot;, to_lower = TRUE) %&gt;% anti_join(stoplist_en) %&gt;% count(word, sort = TRUE) ## Using `to_lower = TRUE` with `token = &#39;tweets&#39;` may not preserve URLs. ## Joining, by = &quot;word&quot; tw_rs_en_words %&gt;% rmarkdown::paged_table() Die am häufigsten verwendeten Schlagwörter (topfeatures) sind in beiden Sprachen annähernd gleich. library(wordcloud2) wordcloud2(tw_rs_en_words) 14.17 Netzwerke Welche Wörter erscheinen häufiger gemeinsam in Tweets? Welche Wortpaare (also ngrams mit n = 2 Mitgliedern) lassen sich aus den Tweets herausholen? Arbeitet man mit tidyverse-Funktionen, kann man das Programm widyr verwenden. Im quanteda.textstats-Programm gibt es die Funktion textstat_collocations(). Auch das Programm udpipe hat Funktionen zur Ermittlung von ngrams, Kollokationen und Netzwerk-Diagramme. library(widyr) ## Warning: package &#39;widyr&#39; was built under R version 4.1.1 # remove punctuation, convert to lowercase, add id for each tweet! tweets_rollingstones_paired_words_de &lt;- tweets_rollingstones_de %&gt;% unnest_tokens(paired_words, text, token = &quot;ngrams&quot;, n = 2) tweets_rollingstones_paired_words_de %&gt;% count(paired_words, sort = TRUE) ## # A tibble: 8,770 x 2 ## paired_words n ## &lt;chr&gt; &lt;int&gt; ## 1 https t.co 464 ## 2 charlie watts 203 ## 3 rollingstones https 106 ## 4 charliewatts rollingstones 86 ## 5 die rollingstones 74 ## 6 der rollingstones 73 ## 7 rolling stones 57 ## 8 80 jahren 46 ## 9 rollingstones charliewatts 40 ## 10 charliewatts https 38 ## # ... with 8,760 more rows Wir verwenden wiederum die Stoppwortliste, um Funktionswörter herauszufiltern, so dass möglichst nur Kollokationen mit Inhaltswörtern übrig bleiben. library(tidyr) # Wörter in getrennten Tabllenspalten tweets_rs_separated_words_de &lt;- tweets_rollingstones_paired_words_de %&gt;% separate(paired_words, c(&quot;word1&quot;, &quot;word2&quot;), sep = &quot; &quot;) # Stoppwortliste erweitern stoplist_de &lt;- c(pull(stoplist_de), &quot;https&quot;,&quot;t.co&quot;) %&gt;% as_tibble() %&gt;% rename(word = value) # Filtern rs_tweets_filtered_de &lt;- tweets_rs_separated_words_de %&gt;% filter(!word1 %in% stoplist_de$word) %&gt;% filter(!word2 %in% stoplist_de$word) # new bigram counts: rs_words_counts_de &lt;- rs_tweets_filtered_de %&gt;% count(word1, word2, sort = TRUE) head(rs_words_counts_de) %&gt;% rmarkdown::paged_table() Aus der vorher erstellten Stoppwortliste haben wir auch die URL-Bestandteile (https, t.co) entfernt, die zwar in vielen Beiträgen vorkommen, aber keine konventionellen Wörter der deutschen Sprache darstellen. Oben wurde schon erwähnt, dass man die URL mit tidytext- oder quanteda-Funktionen bequem entfernen kann. Eine zwar unübersichtliche, aber sehr ökonomische Methode ist die Verwendung eines regulären Ausdrucks (Regex), um die gesamte URL (und nicht nur die beiden oben angeführten Bestandteile) aus den Tweets zu entfernen, z.B. diese: # Remove all urls gsub(pattern = &quot;\\\\s?(f|ht)(tp)(s?)(://)([^\\\\.]*)[\\\\.|/](\\\\S*)&quot;, replacement = &quot;&quot;, tweets_rollingstones$text) # unser Tweet-Text Das Netzwerk-Diagramm zeigt, welche Wörter (vor allem Inhaltswörter) in den deutschen Tweets häufiger miteinander auftreten. library(igraph) ## ## Attaching package: &#39;igraph&#39; ## The following objects are masked from &#39;package:lubridate&#39;: ## ## %--%, union ## The following object is masked from &#39;package:plotly&#39;: ## ## groups ## The following objects are masked from &#39;package:dplyr&#39;: ## ## as_data_frame, groups, union ## The following objects are masked from &#39;package:purrr&#39;: ## ## compose, simplify ## The following object is masked from &#39;package:tidyr&#39;: ## ## crossing ## The following object is masked from &#39;package:tibble&#39;: ## ## as_data_frame ## The following objects are masked from &#39;package:stats&#39;: ## ## decompose, spectrum ## The following object is masked from &#39;package:base&#39;: ## ## union library(ggraph) # plot climate change word network # (plotting graph edges is currently broken) rs_words_counts_de %&gt;% filter(n &gt;= 5) %&gt;% # Wie häufig muss ein Wort sein? graph_from_data_frame() %&gt;% ggraph(layout = &quot;fr&quot;) + # geom_edge_link(aes(edge_alpha = n, edge_width = n)) geom_edge_link(aes(edge_alpha = n, edge_width = n)) + geom_node_point(color = &quot;darkslategray4&quot;, size = 3) + geom_node_text(aes(label = name), vjust = 1.8, size = 3) + labs( title = &quot;Word Network: Tweets using the hashtag - RollingStones&quot;, subtitle = &quot;Text mining twitter data &quot;, x = &quot;&quot;, y = &quot;&quot;) 14.18 Sentiment &amp; Emotion Ein Paket mit zahlreichen Möglichkeiten (in verschiedenen Sprachen) für die Sentiment-Analyse ist library(syuzhet). Zusätzliche Möglichkeiten bietet auch das Paket udpipe, und zwar mit der Negationsumkehrung. Da wir bereits Twitter-Texte in unserem Datensatz geladen haben, ist unser erster Schritt die Umwandlung der Tweets in Äußerungen. Das wird mit der Funktion get_sentences() bewerkstelligt. library(syuzhet) # We need to parse the text into sentences. v_en &lt;- get_sentences(tweets_rollingstones_en$text) Dann wird mit der Funktion get_sentiment() der Sentiment-Wert für jede einzelne Äußerung (z.B. die Summe der einzelnen Werte für die Wörter in einer Äußerung) ermittelt, und zwar auf der Grundlage von Wortlisten, in denen Wörtern emotionale Zahlenwerte zugeordnet wurden (d.h. positive oder negative Werte). # Then we calculate a sentiment value for each sentence. rs_sentiment &lt;- get_sentiment(v_en) head(rs_sentiment) ## [1] 0.00 0.00 0.00 1.80 0.00 -0.25 Mit der Funktion get_nrc_sentiment() können außer den polarisierten Werten (positiv vs. negativ) auch verschiedene Emtionen wie etwa Freude (joy), Trauer (sadness) und einige weitere ermittelt werden, und zwar wieder auf der Grundlage von Wortlisten, die von Versuchspersonen emotional bewertete Wörter enthalten. rs_nrc_sentiment &lt;- get_nrc_sentiment(v_en) joy_items &lt;- which(rs_nrc_sentiment$joy &gt; 0) head(v_en[joy_items], 4) ## [1] &quot;We ended up no more than 20ft off the stage that night and right by the catwalk it was brilliant.&quot; ## [2] &quot;I know this is late to the table but in honour of Charlie Watts @RShrubb I thought I share a great @harleydavidson tribute to @RollingStones #CharlieWatts RIP https://t.co/qeyqaMB8Fc&quot; ## [3] &quot;She and I queued and then ran when gates open straight to the mosh and sat there for 10hrs waiting in the sun on the hottest day of that year!!!&quot; ## [4] &quot;&lt;U+0001F538&gt;#Robonzo &lt;U+0001F941&gt; \\n&lt;U+0001F539&gt;#Song: &#39;On Top Of The World&#39; \\n[#alternative, #psychadelic~#Rock\\n#drummer #guitarist #musician\\n#RollingStones #Spotify #YouTube \\n#Apple~#Music #Amazon #Pandora]\\n&lt;U+0001F538&gt;#Website:\\n&lt;U+23E9&gt; https://t.co/zBW0D0wk6U\\n&lt;U+0001F538&gt;#Video via: (@RobonzoDrummer)\\n&lt;U+23E9&gt; https://t.co/SKRzZWNOrz https://t.co/ECWAc4tysM&quot; Hier ist ein Ausschnitt aus solch einer Tabelle, die wir nach der Ermittlung der emotionalen Werte von Wörtern erhalten: rs_nrc_sentiment[1:10, 1:10] %&gt;% rmarkdown::paged_table() Die emotionale Valenz (d.h. wie positiv oder negativ die Bedeutung eines Wortes bewertet wird): valence_rs &lt;- (rs_nrc_sentiment[, 9]*-1) + rs_nrc_sentiment[, 10] head(valence_rs) ## [1] 0 0 0 1 0 -1 In den englischen Tweets wurden Wörter gefunden, die häufig Emotionen wie Freude, Zuversicht, Erwartung, Trauer ausdrücken. Das Ergebnis können wir wenigen Zeilen graphisch darstellen. barplot( sort(colSums(prop.table(rs_nrc_sentiment[, 1:8]))), horiz = TRUE, cex.names = 0.7, las = 1, col = 9:2, main = &quot;Emotions in Tweets&quot;, xlab=&quot;Percentage&quot; ) Hier ist eine ästhetisch etwas ansprechendere, aber auch erweiterbare graphische Darstellung mit ggplot(): library(scales) ## ## Attaching package: &#39;scales&#39; ## The following object is masked from &#39;package:syuzhet&#39;: ## ## rescale ## The following object is masked from &#39;package:purrr&#39;: ## ## discard ## The following object is masked from &#39;package:readr&#39;: ## ## col_factor rs_nrc_sentiment[,1:8] %&gt;% summarise(across(everything(), ~ mean(.))) %&gt;% pivot_longer(anger:trust, names_to = &quot;emotion&quot;, values_to = &quot;pct&quot;) %&gt;% mutate(emotion = fct_reorder(emotion, pct)) %&gt;% ggplot(aes(pct, emotion, fill = emotion)) + geom_col() + theme(legend.position = &quot;none&quot;) + scale_x_continuous(labels = percent) + labs(x = &quot;&quot;, y = &quot;&quot;, title = &quot;Emotion in English Tweets after Death of Charlie Watts&quot;) Zum Vergleich die deutschen Tweets: Zunächst wiederum die Umwandlung in Äußerungen, gefolgt von der Ermittlung der emtionalen Werte von Wörtern. v_de &lt;- get_sentences(tweets_rollingstones_de$text) rs_nrc_sentiment_de &lt;- get_nrc_sentiment(v_de, language = &quot;german&quot;) joy_items_de &lt;- which(rs_nrc_sentiment_de$joy &gt; 0) head(v_de[joy_items_de], 4) ## [1] &quot;Wir gedenken dem @RollingStones Drummer mit einem stündigen #PopRoutes Special abem 9ni uf @srf3 \\n\\nhttps://t.co/yXUtyb12y4&quot; ## [2] &quot;Synagoge von Vilnius gefunden.&quot; ## [3] &quot;Und ganz ehrlich ich freue mich auf jeden Ton, der noch von ihnen kommt.&quot; ## [4] &quot;Niemand ist unsterblich.&quot; Die graphische Darstellung der emotionalen Werte in deutschen Tweets: rs_nrc_sentiment_de[,1:8] %&gt;% summarise(across(everything(), ~ mean(.))) %&gt;% pivot_longer(anger:trust, names_to = &quot;emotion&quot;, values_to = &quot;pct&quot;) %&gt;% mutate(emotion = fct_reorder(emotion, pct)) %&gt;% ggplot(aes(pct, emotion, fill = emotion)) + geom_col() + theme(legend.position = &quot;none&quot;) + scale_x_continuous(labels = percent) + labs(x = &quot;&quot;, y = &quot;&quot;, title = &quot;Emotion in German Tweets after Death of Charlie Watts&quot;) Was für ein Unterschied! Woran das wohl liegen mag? Das müsste man sich auf jeden Fall mal genauer anschauen. 14.19 Sentiment (Animation) Auch hier können wir es mit einer Animation des Sentiments in den englischen Tweets versuchen. Da die Berechnung länger dauern könnte, wählen wir nur etwa 500 Tweets zur graphischen Darstellung des Sentiments aus. library(ggpage) library(purrr) library(gganimate) library(tidytext) library(zoo) # Beschränkung auf die Tweets 1000 bis 1500 prebuild &lt;- tweets_rollingstones_en$text[1000:1500] %&gt;% ggpage_build() %&gt;% left_join(get_sentiments(&quot;afinn&quot;), by = &quot;word&quot;) midbuild &lt;- map_df(.x = 0:50 * 10 + 1, ~ prebuild %&gt;% mutate(score = ifelse(is.na(value), 0, value), score_smooth = zoo::rollmean(score, .x, 0), score_smooth = score_smooth / max(score_smooth), rolls = .x)) anim_pages &lt;- midbuild %&gt;% ggpage_plot(aes(fill = score_smooth)) + scale_fill_gradient2(low = &quot;red&quot;, high = &quot;blue&quot;, mid = &quot;grey&quot;, midpoint = 0) + guides(fill = &quot;none&quot;) + labs( title = &quot;Smoothed sentiment of Rolling Stones Tweets, rolling average of {round(frame_time)}&quot;) + transition_time(rolls) anim_pages "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
