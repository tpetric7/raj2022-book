[["original-und-übersetzung.html", "Kapitel 7 Original und Übersetzung 7.1 Programi 7.2 Preberemo besedila 7.3 Ustvarimo korpus 7.4 Tokenizacija 7.5 ienje 7.6 Kwic 7.7 Pogostnost 7.8 Kolokacije 7.9 Lematizacija 7.10 Besedni oblaek 7.11 Poloaj v besedilu (xray) 7.12 Slovarska raznolikost 7.13 Podobnost besedil 7.14 Kljune besede 7.15 Razumljivost besedil 7.16 Omreje sopojavitev (FCM) 7.17 Slovnina analiza 7.18 Sentiment", " Kapitel 7 Original und Übersetzung (Izvirnik in prevod) 7.1 Programi Namestitev: e ste program(e) e namestili, lahko preskoite ta korak. Znak # v programskem bloku (chunk) pomeni, da se ta vrstica ne izvaja. Odstrani # e elite program namestiti. # # Programe, ki jih e nimate, lahko namestite tudi na ta nain (odstranite #): # install.packages(&quot;readtext&quot;) # ... ## First specify the packages of interest packages = c(&quot;tidyverse&quot;, &quot;quanteda&quot;, &quot;quanteda.textplots&quot;, &quot;quanteda.textstats&quot;, &quot;wordcloud2&quot;, &quot;tidytext&quot;, &quot;udpipe&quot;, &quot;janitor&quot;, &quot;scales&quot;, &quot;widyr&quot;, &quot;syuzhet&quot;, &quot;corpustools&quot;, &quot;readtext&quot;) ## Now load or install&amp;load all package.check &lt;- lapply( packages, FUN = function(x) { if (!require(x, character.only = TRUE)) { install.packages(x, dependencies = TRUE) library(x, character.only = TRUE) } } ) ## Loading required package: tidyverse ## -- Attaching packages --------------------------------------- tidyverse 1.3.1 -- ## v ggplot2 3.3.5 v purrr 0.3.4 ## v tibble 3.1.3 v dplyr 1.0.7 ## v tidyr 1.1.3 v stringr 1.4.0 ## v readr 2.0.1 v forcats 0.5.1 ## Warning: package &#39;readr&#39; was built under R version 4.1.1 ## -- Conflicts ------------------------------------------ tidyverse_conflicts() -- ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() ## Loading required package: quanteda ## Warning: package &#39;quanteda&#39; was built under R version 4.1.1 ## Package version: 3.1.0 ## Unicode version: 13.0 ## ICU version: 69.1 ## Parallel computing: 12 of 12 threads used. ## See https://quanteda.io for tutorials and examples. ## Loading required package: quanteda.textplots ## Loading required package: quanteda.textstats ## Loading required package: wordcloud2 ## Loading required package: tidytext ## Loading required package: udpipe ## Loading required package: janitor ## ## Attaching package: &#39;janitor&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## chisq.test, fisher.test ## Loading required package: scales ## ## Attaching package: &#39;scales&#39; ## The following object is masked from &#39;package:purrr&#39;: ## ## discard ## The following object is masked from &#39;package:readr&#39;: ## ## col_factor ## Loading required package: widyr ## Warning: package &#39;widyr&#39; was built under R version 4.1.1 ## Loading required package: syuzhet ## ## Attaching package: &#39;syuzhet&#39; ## The following object is masked from &#39;package:scales&#39;: ## ## rescale ## Loading required package: corpustools ## ## Attaching package: &#39;corpustools&#39; ## The following object is masked from &#39;package:tidytext&#39;: ## ## get_stopwords ## Loading required package: readtext Najprej moramo zagnati programe, ki jih potrebujemo za nartovano delo. library(readtext) library(quanteda) library(quanteda.textstats) library(quanteda.textplots) library(tidyverse) library(tidytext) library(wordcloud2) library(udpipe) library(janitor) library(scales) library(widyr) library(syuzhet) library(corpustools) 7.2 Preberemo besedila Besedilni datoteki odpremo s programom readtext z istoimensko funkcijo readtext(). txt = readtext(&quot;data/books/translations/sawyer/*.txt&quot;, encoding = &quot;UTF-8&quot;) Odstranili bomo zaetek obeh besedilnih nizov (v stolpcu text), ker niso sestavni del besedil. Uporabljamo ve funkcij / ukazov: - filter() za izbiranje vrstice v podatkovnem nizu, - separate() za delitev stolpca text v dva nova stolpca, - rbind() za zdruitev obeh podatkovnih nizov (txt1, txt2) v enega (txt) - mutate() in str_squish() za odstranjevanje nepotrebnih presledkov med besedami v stolpcu text. # Nemki prevod txt1 = txt %&gt;% filter(doc_id == &quot;tom_de.txt&quot;) %&gt;% separate(text, into = c(&quot;kolofon&quot;, &quot;text&quot;), sep = &quot;Source : Project Gutenberg Die Abenteuer Tom Sawyers Mark Twain &quot;) %&gt;% dplyr::select(-kolofon) # izloimo stolpec # Angleki izvirnik txt2 = txt %&gt;% filter(doc_id == &quot;tom_en.txt&quot;) %&gt;% separate(text, into = c(&quot;kolofon&quot;, &quot;text&quot;), sep = &quot;High up in Society Contentment &quot;) %&gt;% separate(text, into = c(&quot;text&quot;, &quot;project&quot;), sep = &quot;\\\\*\\\\*\\\\* END OF THE PROJECT GUTENBERG EBOOK THE ADVENTURES OF TOM SAWYER \\\\*\\\\*\\\\*&quot;) %&gt;% dplyr::select(-kolofon, -project) # izloimo stolpca # Obe datoteki zdruimo txt = rbind(txt1,txt2) # txt = txt %&gt;% mutate(text = str_squish(text)) 7.3 Ustvarimo korpus Ustvarimo korpus ali jezikovno gradivo. Ukaz v programu quanteda je corpus(). romane = corpus(txt) Povzetek korpusa: Program quanteda ima dve funkciji za povzemanje osnovnih vrednosti besedil: - summary() - textstat_summary() romanstatistik = textstat_summary(romane) romanstatistik %&gt;% rmarkdown::paged_table() # za lepi izpis v formatu html Iz evidence razberemo, da je nekaj razlik med nemkim prevodom in anglekim izvirnikom glede tevila znakov (chars), povedi (sents), pojavnic (tokens), razlinic ali besednih oblik (types), loil (puncts) in tevk (numbers). Podatke iz povzetka bi lahko uporabili npr. za izraun povprene doline povedi v besedilih: library(rmarkdown) romanstatistik %&gt;% dplyr::select(-tags, -emojis) %&gt;% # izloimo dva prazna stolpca group_by(document) %&gt;% mutate(dolzina_povedi = tokens/sents) %&gt;% paged_table() Izraun pokae, da je dolina povedi (tj. tevilo besed na poved) veja kot npr. v sproenem (zasebnem) ustnem dvogovoru o vsakdanji, manj zahtevni temi. Lahko bi tudi izraunali kazalnik slovarske raznolikosti v besedilih, tj. razmerje med razlinimi (types) in pojavnicami (tokens), kar se angleini imenuje type token ratio (ttr). Razlikujemo med slovarskimi enotami (lemma), razlinicami (types) in pojavnicami (tokens): npr. nemki glagol gehen je slovarska enota, ki ima ve razlinic ali oblik (npr. gehe, gehst, geht, gehen, geht, ging, gingst,  gegangen). Pojavnice: nekatere oblike glagola so pogosteje kot druge, nekatere pa se v izbranem besedilu ne pojavljajo. romanstatistik %&gt;% dplyr::select(-tags, -emojis, -urls) %&gt;% # izloimo stolpce iz prikaza group_by(document) %&gt;% mutate(dolzina_povedi = round(tokens/sents, 2)) %&gt;% # zaokroevanje &quot;round()&quot; mutate(ttr = round(types/tokens, 4)) %&gt;% paged_table() Vrednost slovarske raznolikosti (ttr) je (glede na zmerno dolino besedila) razmeroma nizka, mogoe znamenje, da je besedilo napisano v vsakdanjem pogovornem slogu. Program quanteda ima za ugotavljanje slovarske raznolikosti (lexical diversity) ve monosti, kar zahteva razcepitev besedil na manje enote, tj. tokens (besede, loila idr.). Za nekatere funkcije moramo ustvariti besedilno matriko (document frequency matrix, dfm). 7.4 Tokenizacija e elimo ve izvedeti o besedilih, npr. katere besede se pojavljajo v besedilih, moramo najprej ustvariti seznam besedilnih enot (tj. besed, loil idr.). Iz gradiva izvleemo besedne oblike (npr. s pomojo presledkov). Za tokenizacijo ima quanteda ukaz tokens(). besede = tokens(romane) head(besede) ## Tokens consisting of 2 documents. ## tom_de.txt : ## [1] &quot;Vorwort&quot; &quot;des&quot; &quot;Autors&quot; &quot;.&quot; &quot;Die&quot; &quot;meisten&quot; ## [7] &quot;der&quot; &quot;hier&quot; &quot;erzählten&quot; &quot;Abenteuer&quot; &quot;haben&quot; &quot;sich&quot; ## [ ... and 85,806 more ] ## ## tom_en.txt : ## [1] &quot;PREFACE&quot; &quot;Most&quot; &quot;of&quot; &quot;the&quot; &quot;adventures&quot; ## [6] &quot;recorded&quot; &quot;in&quot; &quot;this&quot; &quot;book&quot; &quot;really&quot; ## [11] &quot;occurred&quot; &quot;;&quot; ## [ ... and 85,775 more ] 7.5 ienje S seznama lahko izloimo nebesede: besede = tokens(romane, remove_punct = T, remove_symbols = T, remove_numbers = T, remove_url = T) head(besede) ## Tokens consisting of 2 documents. ## tom_de.txt : ## [1] &quot;Vorwort&quot; &quot;des&quot; &quot;Autors&quot; &quot;Die&quot; &quot;meisten&quot; ## [6] &quot;der&quot; &quot;hier&quot; &quot;erzählten&quot; &quot;Abenteuer&quot; &quot;haben&quot; ## [11] &quot;sich&quot; &quot;tatsächlich&quot; ## [ ... and 67,016 more ] ## ## tom_en.txt : ## [1] &quot;PREFACE&quot; &quot;Most&quot; &quot;of&quot; &quot;the&quot; &quot;adventures&quot; ## [6] &quot;recorded&quot; &quot;in&quot; &quot;this&quot; &quot;book&quot; &quot;really&quot; ## [11] &quot;occurred&quot; &quot;one&quot; ## [ ... and 70,732 more ] Izloimo lahko tudi besede, ki za vsebinsko analizo niso zaelene (stopwords). concatenate = zdrui: c() Seznamoma smo dodali e nekaj besed (funkcijske besede ali zelo pogoste glagolske oblike). stoplist_de = c(stopwords(&quot;de&quot;), &quot;dass&quot;, &quot;s&quot;, &quot;Na&quot;, &quot;wurde&quot;, &quot;ganz&quot;, &quot;immer&quot;, &quot;sagte&quot;, &quot;mehr&quot;, &quot;schon&quot;, &quot;ja&quot;, &quot;mal&quot;, &quot;ne&quot;, &quot;n&quot;, &quot;wohl&quot;, &quot;sagen&quot;, &quot;gar&quot;) stoplist_en = c(stopwords(&quot;en&quot;), &quot;now&quot;, &quot;one&quot;, &quot;got&quot;, &quot;upon&quot;, &quot;just&quot;, &quot;said&quot;, &quot;Well&quot;, &quot;Oh&quot;, &quot;ever&quot;, &quot;around&quot;, &quot;made&quot;, &quot;say&quot;, &quot;Project&quot;) stoplist = c(stoplist_de, stoplist_en) besede = tokens_select(besede, pattern = stoplist, selection = &quot;remove&quot;, padding = FALSE) Naslednji seznam bomo uporabljali za ustvarjanje konkordance, tj. seznama sobesedil, v katerem se nahaja iskalni niz (npr. neka beseda). Pri odstranjevanju nezaelenih izrazov je nastavljena opcija padding = TRUE. Na mestu nezaelenega izraza bo ostal znak doline ni (\"\"). To je pomembno pri iskanju vebesednih zvez (kolokacij). # Obdrali bomo loila woerter = tokens(romane, remove_symbols = T, remove_numbers = T, remove_url = T) woerter = tokens_select(woerter, pattern = stoplist, selection = &quot;remove&quot;, padding = TRUE) 7.6 Kwic Za sestavo konkordanc ima program quanteda funkcijo kwic() (keyword in context). Mono je iskati posamezne besede, besedne zveze, uporabljamo pa lahko tudi nadomestne znake (npr. *). kwic() ima ve monosti, npr. case_insensitive = FALSE razlikuje med velikimi in malimi rkami. Privzeta vrednost je TRUE (tako kot Excel). Konkordanco bomo pretvorili v podatkovno zbirko, tj. data.frame ali tibble(). Prednost je npr., da tako pridobimo imena stolpcev (tj. spremenljivk). konkordanca = kwic(woerter, pattern = c(&quot;Tom&quot;, &quot;Sawyer&quot;, &quot;Huck&quot;, &quot;Huckleberry&quot;, &quot;Finn&quot;), case_insensitive = FALSE, window = 10) %&gt;% as_tibble() head(konkordanca) %&gt;% paged_table() Z ukazom count() lahko pretejemo, koliko pojavnic je kwic() nael. konkordanca %&gt;% count(keyword, sort = TRUE) ## # A tibble: 5 x 2 ## keyword n ## &lt;chr&gt; &lt;int&gt; ## 1 Tom 1415 ## 2 Huck 460 ## 3 Sawyer 58 ## 4 Huckleberry 51 ## 5 Finn 32 Skladno z naim priakovanjem sta Tom in Huck, glavna junaka romana, pogosta izraza. Natanneje si lahko ogledamo tudi sobesedilo, v katerem se pojavljajo iskani znakovni nizi (keywords). 7.7 Pogostnost Besedilno-besedna matrika (dfm) je izhodie za izraun in grafini prikaz ve statistinih koliin, npr. tudi pogostnosti besednih oblik v posameznih besedilih: matrika = dfm(besede, tolower = FALSE) # za zdaj obdrimo velike zaetnice # Odstranimo besede, ki jih v vsebinski analizi ne potrebujemo (stopwords) matrika = dfm_select(matrika, selection = &quot;remove&quot;, pattern = stoplist) matrika ## Document-feature matrix of: 2 documents, 17,869 features (49.52% sparse) and 0 docvars. ## features ## docs Vorwort Autors meisten erzählten Abenteuer tatsächlich zugetragen ## tom_de.txt 1 1 14 1 13 2 3 ## tom_en.txt 0 0 0 0 0 0 0 ## features ## docs erlebt Schulkameraden Huck ## tom_de.txt 2 3 237 ## tom_en.txt 0 0 223 ## [ reached max_nfeat ... 17,859 more features ] Program quanteda ima posebno funkcijo, ki sestavi seznam besednih oblik in njihove pogostnosti, tj. textstat_frequency(). library(quanteda.textstats) library(quanteda.textplots) pogostnost = textstat_frequency(matrika, groups = c(&quot;tom_de.txt&quot;, &quot;tom_en.txt&quot;)) head(pogostnost) ## feature frequency rank docfreq group ## 1 Tom 737 1 1 tom_de.txt ## 2 Huck 237 2 1 tom_de.txt ## 3 Joe 124 3 1 tom_de.txt ## 4 Becky 101 4 1 tom_de.txt ## 5 Tante 94 5 1 tom_de.txt ## 6 Jungen 92 6 1 tom_de.txt tail(pogostnost) ## feature frequency rank docfreq group ## 18037 _man_ 1 3690 1 tom_en.txt ## 18038 novel 1 3690 1 tom_en.txt ## 18039 marriage 1 3690 1 tom_en.txt ## 18040 perform 1 3690 1 tom_en.txt ## 18041 prosperous 1 3690 1 tom_en.txt ## 18042 reveal 1 3690 1 tom_en.txt Na diagramu najpogostnejih izrazov v izvirniku in prevodu lahko zasledimo podobne tendence in razlike, nazorno pa nam pokae tudi, ali smo izloili vse tiste izraze, ki jih za vsebinsko analizo ne elimo imeti na seznamu in ali bi bilo smiselno, dopolniti seznam stoplist (gl. zgoraj). as_tibble(pogostnost) %&gt;% slice_max(order_by = frequency, n = 60) %&gt;% mutate(feature = reorder_within(feature, frequency, frequency, sep = &quot;: &quot;)) %&gt;% # ggplot(aes(frequency, reorder(feature, frequency))) + ggplot(aes(frequency, feature)) + geom_col(fill=&quot;steelblue&quot;) + labs(x = &quot;Frequency&quot;, y = &quot;&quot;) + facet_wrap(~ group, scales = &quot;free_y&quot;) 7.8 Kolokacije Koleksemi = slovarske enote, ki se sopojavljajo. Kolokacije = jezikovne prvine, ki se sopojavljajo. Statistina opredelitev: e se dva izraza (npr. dober dan) pojavljata bistveno pogosteje kot neposredna soseda, kakor bi nakljuno priakovali, potem ju lahko obravnavamo kot kolokacijo. Jezikoslovna opredelitev: Kolokacija je pomensko povezano zaporedje besed. Pomembno: za ugotavljanje kolokacij potrebujemo besedni seznam z opcijo padding = TRUE ! V besednem seznamu woerter smo sicer izloili nezaelene besedne oblike, ampak opcija padding = TRUE namesto izloenih besed vstavi vrzel oz. prazen niz \"\". Tako program preprei odkrivanje lanih kolokacij. Funkcija textstat_collocations() programa quanteda nam bo poiskala (statistino opredeljene) kolokacije. Z opcijo size nastavimo, koliko lenov naj vsebuje (npr. 2 za dve besedni obliki, 2:3 za dve ali tri besede). Opcija tolower = TRUE odpravi razlikovanje med malimi in velikimi rkami. Opcija minimal_count doloa, kolikna naj bo najmanja pogostnost. V naslednjih preglednicah so prikazane kolokacije obeh romanov, izvirnika in prevoda. coll_2 = textstat_collocations(woerter, # seznma besednih oblik size = 2, # obseg kolokacije tolower = TRUE, # naredi male rke ! min_count = 2) # prag pogostnosti head(coll_2) ## collocation count count_nested length lambda z ## 1 tante polly 45 0 2 8.240516 29.64628 ## 2 aunt polly 42 0 2 8.440653 28.14163 ## 3 injun joe 45 0 2 7.594641 27.05485 ## 4 joe harper 27 0 2 7.027402 22.82116 ## 5 muff potter 36 0 2 9.966474 22.28821 ## 6 becky thatcher 21 0 2 6.317666 22.20220 Trolenskih kolokacij je precej manj kot dvolenskih. coll_3 = textstat_collocations(woerter, size = 3, tolower = TRUE, min_count = 2) head(coll_3) ## collocation count count_nested length lambda z ## 1 tom fuhr zusammen 2 0 3 2.9999040 1.3188542 ## 2 tom went home 2 0 3 1.7420384 1.2562280 ## 3 hand tied behind 2 0 3 0.9722967 0.3775822 ## 4 nen ganzen haufen 2 0 3 0.7370573 0.2875748 ## 5 tom sawyer&#39;s gang 2 0 3 0.8010998 0.2757649 ## 6 every sound ceased 2 0 3 0.6641610 0.2587257 Program ni nael trilenskih kolokacij, ki bi se pojavljale vsaj dvakrat. coll_4 = textstat_collocations(woerter, size = 4, tolower = TRUE, min_count = 2) head(coll_4) ## [1] collocation count count_nested length lambda ## [6] z ## &lt;0 rows&gt; (or 0-length row.names) Seznam vseh kolokacij velikost 2, 3 in 4. V stolpcu count_nested program teje kolokacije, vsebovane v drugi kolokaciji (vijega reda). coll_2_4 = textstat_collocations(woerter, size = 2:4, tolower = TRUE, minimal_count = 2) ## Warning: minimal_count argument is not used. head(coll_2_4) ## collocation count count_nested length lambda z ## 1 tante polly 45 26 2 8.240516 29.64628 ## 2 aunt polly 42 16 2 8.440653 28.14163 ## 3 injun joe 45 23 2 7.594641 27.05485 ## 4 joe harper 27 11 2 7.027402 22.82116 ## 5 muff potter 36 13 2 9.966474 22.28821 ## 6 becky thatcher 21 2 2 6.317666 22.20220 Kolokacija samostalnikih izrazov. V nemini imajo samostalniki veliko zaetnico. Najprej bomo sestavili seznam besednih oblik z veliko zaetnico (woerter_caps). Pri tem nam pomagata regularni izraz 1 in opcija case_insensitive = FALSE. Potem lahko pridobimo seznam kolokacij (coll_caps2). Spremenljivki lambda in z nam povesta, kako znailna je kolokacija v besedilu. Najprej kolokacije v nemkem prevodu, ki so sestavljene iz besednih oblik z veliko zaetnico (poleg lastnih imen tudi splona imena): # seznam besed z veliko zaetnico woerter_caps_de = tokens_select(woerter[&quot;tom_de.txt&quot;], pattern = &quot;^[A-Z]&quot;, valuetype = &quot;regex&quot;, case_insensitive = FALSE, padding = TRUE) # kolokacije besed z veliko zaetnico coll_caps2_de = textstat_collocations(woerter_caps_de, size = 2, tolower = FALSE, min_count = 5) head(coll_caps2_de, 10) ## collocation count count_nested length lambda z ## 1 Joe Harper 13 0 2 6.276456 17.12449 ## 2 Muff Potter 21 0 2 10.204248 16.47734 ## 3 Becky Thatcher 10 0 2 5.916284 15.59540 ## 4 Huckleberry Finn 7 0 2 8.260899 15.19022 ## 5 Frau Thatcher 7 0 2 7.547491 14.96977 ## 6 Richter Thatcher 6 0 2 6.951130 14.07828 ## 7 Herr Gott 6 0 2 6.810621 13.99320 ## 8 Thomas Sawyer 6 0 2 8.506141 13.71857 ## 9 Jeff Thatcher 7 0 2 8.485842 13.59754 ## 10 Tom Sawyer 20 0 2 5.924027 13.11498 e kolokacije v anglekem izvirniku, ki so sestavljene le iz lastnih imen: woerter_caps_en = tokens_select(woerter[&quot;tom_en.txt&quot;], pattern = &quot;^[A-Z]&quot;, valuetype = &quot;regex&quot;, case_insensitive = FALSE, padding = TRUE) coll_caps2_en = textstat_collocations(woerter_caps_en, size = 2, tolower = FALSE, min_count = 5) head(coll_caps2_en, 10) ## collocation count count_nested length lambda z ## 1 Injun Joe 45 0 2 7.624360 26.98981 ## 2 Injun Joe&#39;s 18 0 2 7.952462 19.77999 ## 3 Joe Harper 14 0 2 6.278145 17.50510 ## 4 Muff Potter 15 0 2 9.196406 17.16147 ## 5 Becky Thatcher 11 0 2 6.098456 16.49557 ## 6 Huckleberry Finn 8 0 2 8.388678 15.66984 ## 7 Judge Thatcher 7 0 2 7.093846 15.01281 ## 8 Tom Sawyer 25 0 2 6.092915 14.60283 ## 9 Thomas Sawyer 7 0 2 8.430545 14.16191 ## 10 Aunt Polly 41 0 2 12.236764 13.87560 7.9 Lematizacija Slovarska enota (lema) je osnovna oblika neke besede (geslo v slovarju): imenovalnik ednine, e gre za samostalniko obliko oz. nedolonik, e gre za glagolsko obliko itd. Seznam slovarskih enot lahko sestavimo sami, bistveno hitreje (eprav ne brez napak!) pa to opravimo programsko, npr. z udpipe ali spacyr. 7.9.1 Lasten seznam Seznam slovarskih enot (lem) lahko naloimo z medmreja na na disk. Tu je prikazan postopek za nemki prevod. Na quanteda korpus vsebuje tudi angleko besedilo, ki ga moramo izloiti, preden zanem lematizacijo nemkih besednih oblik. besede_de = besede[&quot;tom_de.txt&quot;] e imamo primeren seznam na disku, je postopek za uporabo s korpusom quanteda npr. taken: - odpremo datoteko, ki vsebuje seznam lem (npr. z ukazom read.delim2() - odvisno od datotene oblike); - za uporabo s korpusom pretvorimo stolpca podatkovnega niza v besedna seznama (tj. as.character()); - nazadnje zamenjamo besedne oblike z lemami(s funkcijo token_replace()). e ustrezne leme ne najde, obdri besedno obliko, ki jo je program nael v besedilu. # Preberi seznam slovarskih enot in pojavnic z diska lemdict = read.delim2(&quot;data/lemmatization_de.txt&quot;, sep = &quot;\\t&quot;, # stolpci so loeni tabulatorsko encoding = &quot;UTF-8&quot;, # univerzalno kodiranje rk col.names = c(&quot;lemma&quot;, &quot;word&quot;), # dodamo imena stolpcev stringsAsFactors = F) # preberi kot rkovne nize # Pretvori podatkovna niza v znakovna niza lemma = as.character(lemdict$lemma) # v tem stolpcu je osnovna oblika besede word = as.character(lemdict$word) # v tem stolpcu je ena izmed besednih oblik # Lematiziraj pojavnice v naih besedilih lemmas_de &lt;- tokens_replace(besede_de, # seznam nemkih besednih oblik (tokens) pattern = word, # obliko, ki jo elimo zamenjati replacement = lemma, # zamenjava case_insensitive = TRUE, # ne glede na zaetnico valuetype = &quot;fixed&quot;) # natanno ujemanje oblik lemmas_de # zdaj imamo leme (e je program nael zamenjavo za besedno obliko) ## Tokens consisting of 1 document. ## tom_de.txt : ## [1] &quot;Vorwort&quot; &quot;Autor&quot; &quot;meist&quot; &quot;erzählen&quot; ## [5] &quot;Abenteuer&quot; &quot;tatsächlich&quot; &quot;zutragen&quot; &quot;erleben&quot; ## [9] &quot;Schulkameraden&quot; &quot;Huck&quot; &quot;Finn&quot; &quot;Leben&quot; ## [ ... and 32,480 more ] Zdaj ko imamo seznam slovarskih enot, lahko ustvarimo tudi matriko s slovarskimi enotami (namesto s pojavnicami), in sicer z funkcijo dfm() tako kot zgoraj. matrika_lem_de = dfm(lemmas_de, tolower = FALSE) # za zdaj obdrimo velike zaetnice # Odstranimo besede, ki jih v vsebinski analizi ne potrebujemo (stopwords) matrika_lem_de = dfm_select(matrika_lem_de, selection = &quot;remove&quot;, pattern = stoplist_de) matrika_lem_de ## Document-feature matrix of: 1 document, 7,108 features (0.00% sparse) and 0 docvars. ## features ## docs Vorwort Autor meist erzählen Abenteuer tatsächlich zutragen ## tom_de.txt 1 1 14 25 18 2 7 ## features ## docs erleben Schulkameraden Huck ## tom_de.txt 4 3 237 ## [ reached max_nfeat ... 7,098 more features ] 7.9.2 Udpipe 7.9.2.1 Angleki izvirnik Lematizacijo anglekega izvirnika bomo opravili s programom udpipe, ki je na voljo za tevilne jezike (tudi slovenino). Pred prvo uporabo moramo naloiti model za nemki jezik z interneta. # install.packages(&quot;udpipe) library(udpipe) language_model &lt;- udpipe_download_model(language = &quot;english&quot;) ## Downloading udpipe model from https://raw.githubusercontent.com/jwijffels/udpipe.models.ud.2.5/master/inst/udpipe-ud-2.5-191206/english-ewt-ud-2.5-191206.udpipe to D:/Users/teodo/Documents/R/raj2022-book/english-ewt-ud-2.5-191206.udpipe ## - This model has been trained on version 2.5 of data from https://universaldependencies.org ## - The model is distributed under the CC-BY-SA-NC license: https://creativecommons.org/licenses/by-nc-sa/4.0 ## - Visit https://github.com/jwijffels/udpipe.models.ud.2.5 for model license details. ## - For a list of all models and their licenses (most models you can download with this package have either a CC-BY-SA or a CC-BY-SA-NC license) read the documentation at ?udpipe_download_model. For building your own models: visit the documentation by typing vignette(&#39;udpipe-train&#39;, package = &#39;udpipe&#39;) ## Downloading finished, model stored at &#39;D:/Users/teodo/Documents/R/raj2022-book/english-ewt-ud-2.5-191206.udpipe&#39; V naslednjem koraku naloimo jezikovni model v pomnilnik. ud_en &lt;- udpipe_load_model(language_model$file_model) e je jezikovni model e v nai delovni mapi, download ni potreben, saj ga lahko takoj naloimo z diska v pomnilnik. file_model = &quot;english-ewt-ud-2.5-191206.udpipe&quot; ud_en &lt;- udpipe_load_model(file_model) Naslednji korak je udpipe_annotate(): program udpipe oznauje besedne oblike po ve merilih. Lematizacijo je le ena izmed nalog, ki jih program opravi. Udpipe prebere in oznauje besedilo takole: Na zaetku je readtext() prebral besedila, shranili smo jih pod imenom txt. Angleki izvirnik smo shranili pod imenom txt2, besedilo pa je v stolpcu text. x &lt;- udpipe_annotate(ud_en, # jezikovni model x = txt2$text, # izbran je le angleki izvirnik trace = TRUE) # sledimo napredku anotacije ## 2021-08-23 17:40:50 Annotating text fragment 1/1 Pretvorba seznama v podatkovni niz s funkcijo as.data.frame(): # # Alternativno branje anglekega izvirnika # # samo drugo besedilo: # x &lt;- udpipe_annotate(ud_en, x = txt$text[2], trace = TRUE) en_df &lt;- as.data.frame(x) head(en_df) ## doc_id paragraph_id sentence_id ## 1 doc1 1 1 ## 2 doc1 2 2 ## 3 doc1 2 2 ## 4 doc1 2 2 ## 5 doc1 2 2 ## 6 doc1 2 2 ## sentence ## 1 PREFACE ## 2 Most of the adventures recorded in this book really occurred; one or two were experiences of my own, the rest those of boys who were schoolmates of mine. ## 3 Most of the adventures recorded in this book really occurred; one or two were experiences of my own, the rest those of boys who were schoolmates of mine. ## 4 Most of the adventures recorded in this book really occurred; one or two were experiences of my own, the rest those of boys who were schoolmates of mine. ## 5 Most of the adventures recorded in this book really occurred; one or two were experiences of my own, the rest those of boys who were schoolmates of mine. ## 6 Most of the adventures recorded in this book really occurred; one or two were experiences of my own, the rest those of boys who were schoolmates of mine. ## token_id token lemma upos xpos feats ## 1 1 PREFACE Preface NOUN NN Number=Sing ## 2 1 Most most ADJ JJS Degree=Sup ## 3 2 of of ADP IN &lt;NA&gt; ## 4 3 the the DET DT Definite=Def|PronType=Art ## 5 4 adventures adventure NOUN NNS Number=Plur ## 6 5 recorded record VERB VBN Tense=Past|VerbForm=Part ## head_token_id dep_rel deps misc ## 1 0 root &lt;NA&gt; SpacesAfter=\\\\n\\\\n\\\\n ## 2 10 nsubj &lt;NA&gt; &lt;NA&gt; ## 3 4 case &lt;NA&gt; &lt;NA&gt; ## 4 4 det &lt;NA&gt; &lt;NA&gt; ## 5 1 obl &lt;NA&gt; &lt;NA&gt; ## 6 4 acl &lt;NA&gt; &lt;NA&gt; 7.9.2.2 Nemki prevod Lematizacijo nemkega prevod bomo tokrat opravili s programom udpipe. Pred prvo uporabo moramo naloiti model za nemki jezik z interneta. # install.packages(&quot;udpipe) library(udpipe) sprachmodell &lt;- udpipe_download_model(language = &quot;german&quot;) ## Downloading udpipe model from https://raw.githubusercontent.com/jwijffels/udpipe.models.ud.2.5/master/inst/udpipe-ud-2.5-191206/german-gsd-ud-2.5-191206.udpipe to D:/Users/teodo/Documents/R/raj2022-book/german-gsd-ud-2.5-191206.udpipe ## - This model has been trained on version 2.5 of data from https://universaldependencies.org ## - The model is distributed under the CC-BY-SA-NC license: https://creativecommons.org/licenses/by-nc-sa/4.0 ## - Visit https://github.com/jwijffels/udpipe.models.ud.2.5 for model license details. ## - For a list of all models and their licenses (most models you can download with this package have either a CC-BY-SA or a CC-BY-SA-NC license) read the documentation at ?udpipe_download_model. For building your own models: visit the documentation by typing vignette(&#39;udpipe-train&#39;, package = &#39;udpipe&#39;) ## Downloading finished, model stored at &#39;D:/Users/teodo/Documents/R/raj2022-book/german-gsd-ud-2.5-191206.udpipe&#39; V naslednjem koraku naloimo jezikovni model v pomnilnik. ud_de &lt;- udpipe_load_model(sprachmodell$file_model) e je jezikovni model e v nai delovni mapi, download ni potreben, saj ga lahko takoj naloimo z diska v pomnilnik. file_model = &quot;german-gsd-ud-2.5-191206.udpipe&quot; ud_de &lt;- udpipe_load_model(file_model) Naslednji korak je udpipe_annotate(): program udpipe oznauje besedne oblike po ve merilih. Lematizacijo je le ena izmed nalog, ki jih program opravi. Udpipe prebere in oznauje besedilo takole: Na zaetku je readtext() prebral besedila, shranili smo jih pod imenom txt. Nemki prevod smo shranili pod imenom txt1, besedilo pa je v stolpcu text. x &lt;- udpipe_annotate(ud_de, # jezikovni model x = txt1$text, # izbran je le nemki prevod romana trace = TRUE) # sledimo napredku anotacije ## 2021-08-23 17:42:11 Annotating text fragment 1/1 Pretvorba seznama v podatkovni niz s funkcijo as.data.frame(): # # Alternativno branje anglekega izvirnika # # samo drugo besedilo: # x &lt;- udpipe_annotate(ud_en, x = txt$text[2], trace = TRUE) de_df &lt;- as.data.frame(x) head(de_df) ## doc_id paragraph_id sentence_id ## 1 doc1 1 1 ## 2 doc1 1 1 ## 3 doc1 1 1 ## 4 doc1 1 1 ## 5 doc1 1 1 ## 6 doc1 1 1 ## sentence ## 1 Vorwort des Autors . Die meisten der hier erzählten Abenteuer haben sich tatsächlich zugetragen . Das eine oder das andere habe ich selbst erlebt , die anderen meine Schulkameraden . Huck Finn ist nach dem Leben gezeichnet , nicht weniger Tom Sawyer , doch entspricht dieser nicht einer bestimmten Persönlichkeit , sondern wurde mit charakteristischen Zügen mehrerer meiner Altersgenossen ausgestattet und darf daher jenem gegenüber als einigermaßen kompliziertes psychologisches Problem gelten . Ich muß hier bemerken , daß zur Zeit meiner Erzählung -- vor dreißig bis vierzig Jahren -- unter den Unmündigen und Unwissenden des Westens noch die seltsamsten , unwahrscheinlichsten Vorurteile und Aberglauben herrschten . Obwohl dies Buch vor allem zur Unterhaltung der kleinen Welt geschrieben wurde , so darf ich doch wohl hoffen , daß es auch von Erwachsenen nicht ganz unbeachtet gelassen werde , habe ich doch darin versucht , ihnen auf angenehme Weise zu zeigen , was sie einst selbst waren , wie sie fühlten , dachten , sprachen , und welcher Art ihr Ehrgeiz und ihre Unternehmungen waren . Erstes Kapitel . , ,Tom ! &quot; Keine Antwort . , ,Tom ! &quot; Alles still . , ,Soll mich doch wundern , wo der Bengel wieder steckt ! Tom ! &quot; Die alte Dame schob ihre Brille hinunter und schaute darüber hinweg ; dann schob sie sie auf die Stirn und schaute darunter weg. ## 2 Vorwort des Autors . Die meisten der hier erzählten Abenteuer haben sich tatsächlich zugetragen . Das eine oder das andere habe ich selbst erlebt , die anderen meine Schulkameraden . Huck Finn ist nach dem Leben gezeichnet , nicht weniger Tom Sawyer , doch entspricht dieser nicht einer bestimmten Persönlichkeit , sondern wurde mit charakteristischen Zügen mehrerer meiner Altersgenossen ausgestattet und darf daher jenem gegenüber als einigermaßen kompliziertes psychologisches Problem gelten . Ich muß hier bemerken , daß zur Zeit meiner Erzählung -- vor dreißig bis vierzig Jahren -- unter den Unmündigen und Unwissenden des Westens noch die seltsamsten , unwahrscheinlichsten Vorurteile und Aberglauben herrschten . Obwohl dies Buch vor allem zur Unterhaltung der kleinen Welt geschrieben wurde , so darf ich doch wohl hoffen , daß es auch von Erwachsenen nicht ganz unbeachtet gelassen werde , habe ich doch darin versucht , ihnen auf angenehme Weise zu zeigen , was sie einst selbst waren , wie sie fühlten , dachten , sprachen , und welcher Art ihr Ehrgeiz und ihre Unternehmungen waren . Erstes Kapitel . , ,Tom ! &quot; Keine Antwort . , ,Tom ! &quot; Alles still . , ,Soll mich doch wundern , wo der Bengel wieder steckt ! Tom ! &quot; Die alte Dame schob ihre Brille hinunter und schaute darüber hinweg ; dann schob sie sie auf die Stirn und schaute darunter weg. ## 3 Vorwort des Autors . Die meisten der hier erzählten Abenteuer haben sich tatsächlich zugetragen . Das eine oder das andere habe ich selbst erlebt , die anderen meine Schulkameraden . Huck Finn ist nach dem Leben gezeichnet , nicht weniger Tom Sawyer , doch entspricht dieser nicht einer bestimmten Persönlichkeit , sondern wurde mit charakteristischen Zügen mehrerer meiner Altersgenossen ausgestattet und darf daher jenem gegenüber als einigermaßen kompliziertes psychologisches Problem gelten . Ich muß hier bemerken , daß zur Zeit meiner Erzählung -- vor dreißig bis vierzig Jahren -- unter den Unmündigen und Unwissenden des Westens noch die seltsamsten , unwahrscheinlichsten Vorurteile und Aberglauben herrschten . Obwohl dies Buch vor allem zur Unterhaltung der kleinen Welt geschrieben wurde , so darf ich doch wohl hoffen , daß es auch von Erwachsenen nicht ganz unbeachtet gelassen werde , habe ich doch darin versucht , ihnen auf angenehme Weise zu zeigen , was sie einst selbst waren , wie sie fühlten , dachten , sprachen , und welcher Art ihr Ehrgeiz und ihre Unternehmungen waren . Erstes Kapitel . , ,Tom ! &quot; Keine Antwort . , ,Tom ! &quot; Alles still . , ,Soll mich doch wundern , wo der Bengel wieder steckt ! Tom ! &quot; Die alte Dame schob ihre Brille hinunter und schaute darüber hinweg ; dann schob sie sie auf die Stirn und schaute darunter weg. ## 4 Vorwort des Autors . Die meisten der hier erzählten Abenteuer haben sich tatsächlich zugetragen . Das eine oder das andere habe ich selbst erlebt , die anderen meine Schulkameraden . Huck Finn ist nach dem Leben gezeichnet , nicht weniger Tom Sawyer , doch entspricht dieser nicht einer bestimmten Persönlichkeit , sondern wurde mit charakteristischen Zügen mehrerer meiner Altersgenossen ausgestattet und darf daher jenem gegenüber als einigermaßen kompliziertes psychologisches Problem gelten . Ich muß hier bemerken , daß zur Zeit meiner Erzählung -- vor dreißig bis vierzig Jahren -- unter den Unmündigen und Unwissenden des Westens noch die seltsamsten , unwahrscheinlichsten Vorurteile und Aberglauben herrschten . Obwohl dies Buch vor allem zur Unterhaltung der kleinen Welt geschrieben wurde , so darf ich doch wohl hoffen , daß es auch von Erwachsenen nicht ganz unbeachtet gelassen werde , habe ich doch darin versucht , ihnen auf angenehme Weise zu zeigen , was sie einst selbst waren , wie sie fühlten , dachten , sprachen , und welcher Art ihr Ehrgeiz und ihre Unternehmungen waren . Erstes Kapitel . , ,Tom ! &quot; Keine Antwort . , ,Tom ! &quot; Alles still . , ,Soll mich doch wundern , wo der Bengel wieder steckt ! Tom ! &quot; Die alte Dame schob ihre Brille hinunter und schaute darüber hinweg ; dann schob sie sie auf die Stirn und schaute darunter weg. ## 5 Vorwort des Autors . Die meisten der hier erzählten Abenteuer haben sich tatsächlich zugetragen . Das eine oder das andere habe ich selbst erlebt , die anderen meine Schulkameraden . Huck Finn ist nach dem Leben gezeichnet , nicht weniger Tom Sawyer , doch entspricht dieser nicht einer bestimmten Persönlichkeit , sondern wurde mit charakteristischen Zügen mehrerer meiner Altersgenossen ausgestattet und darf daher jenem gegenüber als einigermaßen kompliziertes psychologisches Problem gelten . Ich muß hier bemerken , daß zur Zeit meiner Erzählung -- vor dreißig bis vierzig Jahren -- unter den Unmündigen und Unwissenden des Westens noch die seltsamsten , unwahrscheinlichsten Vorurteile und Aberglauben herrschten . Obwohl dies Buch vor allem zur Unterhaltung der kleinen Welt geschrieben wurde , so darf ich doch wohl hoffen , daß es auch von Erwachsenen nicht ganz unbeachtet gelassen werde , habe ich doch darin versucht , ihnen auf angenehme Weise zu zeigen , was sie einst selbst waren , wie sie fühlten , dachten , sprachen , und welcher Art ihr Ehrgeiz und ihre Unternehmungen waren . Erstes Kapitel . , ,Tom ! &quot; Keine Antwort . , ,Tom ! &quot; Alles still . , ,Soll mich doch wundern , wo der Bengel wieder steckt ! Tom ! &quot; Die alte Dame schob ihre Brille hinunter und schaute darüber hinweg ; dann schob sie sie auf die Stirn und schaute darunter weg. ## 6 Vorwort des Autors . Die meisten der hier erzählten Abenteuer haben sich tatsächlich zugetragen . Das eine oder das andere habe ich selbst erlebt , die anderen meine Schulkameraden . Huck Finn ist nach dem Leben gezeichnet , nicht weniger Tom Sawyer , doch entspricht dieser nicht einer bestimmten Persönlichkeit , sondern wurde mit charakteristischen Zügen mehrerer meiner Altersgenossen ausgestattet und darf daher jenem gegenüber als einigermaßen kompliziertes psychologisches Problem gelten . Ich muß hier bemerken , daß zur Zeit meiner Erzählung -- vor dreißig bis vierzig Jahren -- unter den Unmündigen und Unwissenden des Westens noch die seltsamsten , unwahrscheinlichsten Vorurteile und Aberglauben herrschten . Obwohl dies Buch vor allem zur Unterhaltung der kleinen Welt geschrieben wurde , so darf ich doch wohl hoffen , daß es auch von Erwachsenen nicht ganz unbeachtet gelassen werde , habe ich doch darin versucht , ihnen auf angenehme Weise zu zeigen , was sie einst selbst waren , wie sie fühlten , dachten , sprachen , und welcher Art ihr Ehrgeiz und ihre Unternehmungen waren . Erstes Kapitel . , ,Tom ! &quot; Keine Antwort . , ,Tom ! &quot; Alles still . , ,Soll mich doch wundern , wo der Bengel wieder steckt ! Tom ! &quot; Die alte Dame schob ihre Brille hinunter und schaute darüber hinweg ; dann schob sie sie auf die Stirn und schaute darunter weg. ## token_id token lemma upos xpos ## 1 1 Vorwort Vorwort ADP NN ## 2 2 des der DET ART ## 3 3 Autors Autor NOUN NN ## 4 4 . . PUNCT $. ## 5 5 Die der PRON ART ## 6 6 meisten meist PRON NN ## feats head_token_id ## 1 Case=Nom|Gender=Neut|Number=Sing 3 ## 2 Case=Gen|Definite=Def|Gender=Masc|Number=Sing|PronType=Art 3 ## 3 Case=Gen|Gender=Masc|Number=Sing 14 ## 4 &lt;NA&gt; 14 ## 5 Case=Nom|Number=Plur|PronType=Art 6 ## 6 Case=Dat|Gender=Masc|Number=Sing 14 ## dep_rel deps misc ## 1 case &lt;NA&gt; &lt;NA&gt; ## 2 det &lt;NA&gt; &lt;NA&gt; ## 3 obl &lt;NA&gt; &lt;NA&gt; ## 4 punct &lt;NA&gt; SpacesAfter=\\\\s\\\\s\\\\s ## 5 det &lt;NA&gt; &lt;NA&gt; ## 6 nsubj &lt;NA&gt; &lt;NA&gt; 7.10 Besedni oblaek Besedni oblaki so smiseln in razmeroma preprost prikaz najpogostejih besed v besedilu. Najvekrat jih uporabljajo za prikaz vsebinsko relevantnih besed. Zato je treba najprej odstraniti funkcijske in druge neprimerne izraze. e bolji pregled nad vsebino besedila nam besedni oblaki dajejo, e uporabljamo slovarske enote (leme) namesto besednih oblik. To e posebej velja v oblikoslovno bogatih jezikih kot sta slovenino in nemina. Podatkovni niz en_df, ki ga je ustvaril udpipe, moramo pripraviti za program wordcloud2: - izloiti nezaelene izraze, - ugotoviti pogostnost besed in - omejiti tevilo besed za prikaz v besednem oblaku. en_df_ud &lt;- en_df %&gt;% filter(upos != &quot;PUNCT&quot;) %&gt;% # izloimo loila filter(str_detect(lemma, &quot;^[:alpha:]&quot;)) %&gt;% # samo rke, ne simobolov itd. mutate(word = str_to_lower(lemma)) # vse pretvorimo v male rke # iz besednega senzama naredimo podatkovni niz stoplist_eng = as_tibble(stoplist_en) %&gt;% rename(word = value) # sprememba imena # odstranimo nezaelene besede en_df_cleaned = en_df_ud %&gt;% anti_join(stoplist_eng, by = &quot;word&quot;) # pretejemo besede in izberemo najpogosteje topfeat_en = en_df_cleaned %&gt;% count(word, sort = TRUE) %&gt;% head(300) %&gt;% as_tibble() # Oblaek set.seed(1320) library(wordcloud2) wordcloud2(topfeat_en) Oblaek nemkih slovarskih enot: de_df_ud &lt;- de_df %&gt;% filter(upos != &quot;PUNCT&quot;) %&gt;% # brez loil filter(str_detect(lemma, &quot;^[:alpha:]&quot;)) %&gt;% # samo rke, ne simobolov itd. mutate(word = str_to_lower(lemma)) # vse pretvorimo v male rke # iz besednega seznama naredimo podatkovni niz stoplist_deu = as_tibble(stoplist_de) %&gt;% rename(word = value) # odstranimo nezaelene besede de_df_cleaned = de_df_ud %&gt;% anti_join(stoplist_deu, by = &quot;word&quot;) # pretejemo besede, zadnji popravki in izberemo najpogosteje topfeat_de = de_df_cleaned %&gt;% count(word, sort = TRUE) %&gt;% filter(!str_detect(word, &quot;er\\\\|es\\\\|sie&quot;)) %&gt;% # izloimo z regularnim izrazom filter(!str_detect(word, &quot;sie\\\\|sie&quot;)) %&gt;% # izloimo z regex mutate(word = str_replace(word, &quot;hucken&quot;, &quot;huck&quot;)) %&gt;% # popravek !!! head(300) %&gt;% as_tibble() # Oblaek set.seed(1321) library(wordcloud2) wordcloud2(topfeat_de) Oblaek anglekih slovarskih enot, ki smo jih pridobili s programom udpipe, lahko tudi pripravimo za prikaz s funkcijo textplot_wordcloud() programa quanteda. tok_en = en_df_cleaned %&gt;% dplyr::select(word) %&gt;% mutate(word = paste(word, collapse = &quot; &quot;)) %&gt;% head(1) toks_en = tokens(tok_en$word) matrika_lem_en = dfm(toks_en) matrika_lem_en = dfm_select(matrika_lem_en, pattern = stoplist_en, selection = &quot;remove&quot;) # spremenimo ime (doc_id) docnames(matrika_lem_en) &lt;- &quot;tom_en&quot; textplot_wordcloud(matrika_lem_en, # le nemki prevod comparison = FALSE, # brez primerjave z drugim besedilom adjust = 0.025, color = c(&quot;darkblue&quot;,&quot;orange&quot;,&quot;darkgreen&quot;), max_size = 5, min_size = 0.75, rotation = 0.5, min_count = 10, # spodnji prag pogostnosti max_words = 250) # koliko besed sme biti v oblaku Priprava seznama nemkih slovarskih enot, ki smo jih pridobili z udpipe, in prikaz s funkcijo textplot_wordcloud(). tok_de = de_df_cleaned %&gt;% dplyr::select(word) %&gt;% mutate(word = paste(word, collapse = &quot; &quot;)) %&gt;% head(1) toks_de = tokens(tok_de$word) matrika_lem_de = dfm(toks_de) matrika_lem_de = dfm_select(matrika_lem_de, pattern = c(stoplist_de, &quot;|&quot;), selection = &quot;remove&quot;) # spremenimo ime (doc_id) docnames(matrika_lem_de) &lt;- &quot;tom_de&quot; textplot_wordcloud(matrika_lem_de, # le nemki prevod comparison = FALSE, # brez primerjave z drugim besedilom adjust = 0.025, color = c(&quot;darkblue&quot;,&quot;orange&quot;,&quot;darkgreen&quot;), max_size = 5, min_size = 0.75, rotation = 0.5, min_count = 10, # spodnji prag pogostnosti max_words = 250) # koliko besed sme biti v oblaku Zdruimo matriki s funkcijo rbind(). matrika_lem_de_en = rbind(matrika_lem_de, matrika_lem_en) matrika_lem_de_en ## Document-feature matrix of: 2 documents, 13,091 features (48.91% sparse) and 0 docvars. ## features ## docs vorwort autor meist erzählt abenteuer tatsächlich zugetragen erleben ## tom_de 1 1 14 2 16 2 3 3 ## tom_en 0 0 0 0 0 0 0 0 ## features ## docs schulkameraden hucken ## tom_de 3 226 ## tom_en 0 0 ## [ reached max_nfeat ... 13,081 more features ] e elimo, lahko matriko pretvorimo v podatkovni niz: convert(matrika_lem_de_en, to = &quot;data.frame&quot;) %&gt;% write_csv(&quot;data/tom_tom_matrika.csv&quot;) Primerjalni oblaek nemkih in anglekih slovarskih enot: textplot_wordcloud(matrika_lem_de_en, comparison = TRUE, # primerjava z drugim besedilom adjust = 0.025, color = c(&quot;darkblue&quot;,&quot;darkgreen&quot;), max_size = 4, min_size = 0.5, rotation = 0.5, min_count = 10, # spodnji prag pogostnosti max_words = 120) # koliko besed sme biti v oblaku 7.11 Poloaj v besedilu (xray) Diagram prikazuje, kje v besedilih se pojavlja doloena besedna oblika. Podobno: Voyant Tools (MicroSearch). Za primerjavo so bili izbrani izrazi, ki dandanes niso ve nevtralni, temve bolj ali manj rasistino obarvani ali celo pejorativni. kwic_tom = kwic(besede, pattern = c(&quot;indian*&quot;, &quot;injun&quot;, # indinaer? &quot;neg*&quot;, &quot;nigg*&quot;)) # neger? textplot_xray(kwic_tom) 7.12 Slovarska raznolikost Za oceno slovarske raznolikosti besedil je ve meril. Najosnovneja in najbr najbolj znano je razmerje med tevilom razlinic in pojavnic (TTR). Slaba lastnost tega merila je odvisnost od velikosti besedila. Program quanteda nam s funkcijo textstat_lexdiv() priara celo paleto meril za slovarsko raznolikost (ve o njih v pomoi programa). V spodnji razpredelnici vidimo tevilke po odstranitvi funkcijskih besed in nekaterih drugih nezaelenih izrazov (stopwords). TTR nemkega prevoda je veji kot tisti za angleki izvirnik, kar bi lahko pomenilo, da vsebuje ve oblik. textstat_lexdiv(matrika, measure = &quot;all&quot;) ## document TTR C R CTTR U S K ## 1 tom_de.txt 0.3120153 0.8878880 56.24243 39.76940 40.24348 0.9210789 10.44913 ## 2 tom_en.txt 0.2452145 0.8645934 44.02472 31.13018 33.29454 0.9033840 13.22338 ## I D Vm Maas lgV0 lgeV0 ## 1 94.03320 0.001014167 0.03076157 0.1576348 8.707463 20.04968 ## 2 45.73572 0.001291354 0.03458063 0.1733060 7.757339 17.86193 V naslednji tabeli vidimo izraun slovarske raznolikosti na osnovi slovarskih enot (namesto razlinic). textstat_lexdiv(matrika_lem_de_en, measure = &quot;all&quot;) ## document TTR C R CTTR U S K ## 1 tom_de 0.2384871 0.8616471 42.39104 29.97499 32.52277 0.9009906 15.49656 ## 2 tom_en 0.1810230 0.8353586 32.50308 22.98315 27.38304 0.8805434 20.84018 ## I D Vm Maas lgV0 lgeV0 ## 1 36.88205 0.001518054 0.03764229 0.1753502 7.639455 17.59049 ## 2 15.76658 0.002053064 0.04373406 0.1910993 6.851152 15.77536 7.13 Podobnost besedil Ta postopek je bolj zanimiv, e elimo primerjati ve besedil. Zato bomo dodali e Kafkino novelo. # odpremo datoteko verwandl = readtext(&quot;data/books/verwandlung/verwandlung.txt&quot;, encoding = &quot;UTF-8&quot;) # ustvarimo nov korpus verw_corp = corpus(verwandl) # zdruimo novi korpus s prrejnjim romane3 = romane + verw_corp # tokenizacija romane3_toks = tokens(romane3) # ustvarimo matriko (dfm) romane3_dfm = dfm(romane3_toks) Rezultat (ki je bil priakovan): Kafkina novela Die Verwandlung je nemkemu prevoda podobneji kot angleki izvirnik Twainovega romana Tom Sawyer. Program oitno ne primerja vsebine besedil, temve besedne oblike. textstat_simil(romane3_dfm, method = &quot;cosine&quot;, margin = &quot;documents&quot;) ## textstat_simil object; method = &quot;cosine&quot; ## tom_de.txt tom_en.txt verwandlung.txt ## tom_de.txt 1.000 0.615 0.933 ## tom_en.txt 0.615 1.000 0.496 ## verwandlung.txt 0.933 0.496 1.000 Podobnost oblik (features). # compute some term similarities simil1 = textstat_simil(matrika, matrika[, c(&quot;Tom&quot;, &quot;Sawyer&quot;, &quot;Huck&quot;, &quot;Finn&quot;)], method = &quot;cosine&quot;, margin = &quot;features&quot;) head(as.matrix(simil1), 10) ## Tom Sawyer Huck Finn ## Vorwort 0.7359509 0.6305926 0.7282902 0.7071068 ## Autors 0.7359509 0.6305926 0.7282902 0.7071068 ## meisten 0.7359509 0.6305926 0.7282902 0.7071068 ## erzählten 0.7359509 0.6305926 0.7282902 0.7071068 ## Abenteuer 0.7359509 0.6305926 0.7282902 0.7071068 ## tatsächlich 0.7359509 0.6305926 0.7282902 0.7071068 ## zugetragen 0.7359509 0.6305926 0.7282902 0.7071068 ## erlebt 0.7359509 0.6305926 0.7282902 0.7071068 ## Schulkameraden 0.7359509 0.6305926 0.7282902 0.7071068 ## Huck 0.9999368 0.9911012 1.0000000 0.9995372 tail(as.matrix(simil1), 10) ## Tom Sawyer Huck Finn ## chronicle 0.6770349 0.776114 0.6852688 0.7071068 ## strictly 0.6770349 0.776114 0.6852688 0.7071068 ## _boy_ 0.6770349 0.776114 0.6852688 0.7071068 ## _man_ 0.6770349 0.776114 0.6852688 0.7071068 ## writes 0.6770349 0.776114 0.6852688 0.7071068 ## novel 0.6770349 0.776114 0.6852688 0.7071068 ## marriage 0.6770349 0.776114 0.6852688 0.7071068 ## perform 0.6770349 0.776114 0.6852688 0.7071068 ## prosperous 0.6770349 0.776114 0.6852688 0.7071068 ## reveal 0.6770349 0.776114 0.6852688 0.7071068 Razlinost besedil (Kaj je ta metoda upotevala? Razliko v dolini?): # plot a dendrogram after converting the object into distances dist1 = textstat_dist(romane3_dfm, method = &quot;euclidean&quot;, margin = &quot;documents&quot;) plot(hclust(as.dist(dist1))) 7.14 Kljune besede Katere besedne oblike lahko uvrstimo med kljune besede, tj. take izraze, ki so najbolj znailni za neko besedilo? Program quanteda ima funkcijo textstat_keyness(): ciljno besedilo (target) primerjamo z referennim besedilom (reference). key_tom_de &lt;- textstat_keyness(matrika, target = &quot;tom_de.txt&quot;) key_tom_de %&gt;% rmarkdown::paged_table() key_tom_en &lt;- textstat_keyness(matrika, target = &quot;tom_en.txt&quot;) key_tom_en %&gt;% rmarkdown::paged_table() textplot_keyness(key_tom_de, key_tom_de$n_target == 1) ## Warning in if (show_reference) {: the condition has length &gt; 1 and only the ## first element will be used ## Warning in if (show_reference) {: the condition has length &gt; 1 and only the ## first element will be used ## Warning in if (show_reference) {: the condition has length &gt; 1 and only the ## first element will be used ## Warning in if (show_reference) min(data$x1) - margin else 0: the condition has ## length &gt; 1 and only the first element will be used textplot_keyness(key_tom_de, key_tom_en$n_target == 1) ## Warning in if (show_reference) {: the condition has length &gt; 1 and only the ## first element will be used ## Warning in if (show_reference) {: the condition has length &gt; 1 and only the ## first element will be used ## Warning in if (show_reference) {: the condition has length &gt; 1 and only the ## first element will be used ## Warning in if (show_reference) min(data$x1) - margin else 0: the condition has ## length &gt; 1 and only the first element will be used textplot_keyness(key_tom_de) textplot_keyness(key_tom_en) 7.15 Razumljivost besedil Indeksi razumljivosti (readability index) so prirejeni za angleino, za druge jezike veljajo v manji meri. Flesch-Index velja angleka besedila: nija vrednost nakazuje, da neko besedilo teje beremo (razumemo). Indeks nemkega prevoda ima nijo vrednost (61) kot Tom Sawyer (81), kar je lahko povezano (a) z daljimi povedmi in/ali (b) daljimi besedami (zloenke v nemini piemo kot eno besedo, v angleini pogosto ne). textstat_readability(romane, measure = c(&quot;Flesch&quot;, &quot;Flesch.Kincaid&quot;, &quot;FOG&quot;, &quot;FOG.PSK&quot;, &quot;FOG.NRI&quot;)) ## document Flesch Flesch.Kincaid FOG FOG.PSK FOG.NRI ## 1 tom_de.txt 60.58738 8.393636 10.609800 5.072836 6012.711 ## 2 tom_en.txt 80.59447 5.657490 8.183574 4.513384 5826.937 7.16 Omreje sopojavitev (FCM) Matriko sopojavljanja besednih oblik (FCM) pridobimo v dveh korakih: - najprej izberemo seznam izrazov (pattern) iz matrike (dfm()), - potem doloimo matriko sopojavljanja besednih oblik (fcm()). Primer omreja iz nemkega prevoda: dfm_tags_de &lt;- dfm_select(matrika[1,], # tom_de.txt pattern = (c(&quot;tom&quot;, &quot;huck&quot;, &quot;*joe&quot;, &quot;becky&quot;, &quot;tante&quot;, &quot;witwe&quot;,&quot;polly&quot;, &quot;sid&quot;, &quot;mary&quot;, &quot;thatcher&quot;, &quot;höhle&quot;, &quot;herz&quot;,&quot;*schule&quot;, &quot;katze&quot;, &quot;geld&quot;, &quot;zaun&quot;, &quot;piraten&quot;,&quot;schatz&quot;))) toptag_de &lt;- names(topfeatures(dfm_tags_de, 50)) head(toptag_de) ## [1] &quot;Tom&quot; &quot;Huck&quot; &quot;Joe&quot; &quot;Becky&quot; &quot;Tante&quot; &quot;Sid&quot; # Construct feature-cooccurrence matrix (fcm) of tags fcm_tom_de &lt;- fcm(matrika[1,]) # besedilo 1 je tom_de.txt head(fcm_tom_de) ## Feature co-occurrence matrix of: 6 by 17,869 features. ## features ## features Vorwort Autors meisten erzählten Abenteuer tatsächlich zugetragen ## Vorwort 0 1 14 1 13 2 3 ## Autors 0 0 14 1 13 2 3 ## meisten 0 0 91 14 182 28 42 ## erzählten 0 0 0 0 13 2 3 ## Abenteuer 0 0 0 0 78 26 39 ## tatsächlich 0 0 0 0 0 1 6 ## features ## features erlebt Schulkameraden Huck ## Vorwort 2 3 237 ## Autors 2 3 237 ## meisten 28 42 3318 ## erzählten 2 3 237 ## Abenteuer 26 39 3081 ## tatsächlich 4 6 474 ## [ reached max_nfeat ... 17,859 more features ] top_fcm_de &lt;- fcm_select(fcm_tom_de, pattern = toptag_de) textplot_network(top_fcm_de, min_freq = 0.6, edge_alpha = 0.8, edge_size = 5) 7.17 Slovnina analiza Za slovnino analizo in lematizacijo besednih oblik lahko uporabljamo posebne programe (npr. spacyr ali udpipe). Program udpipe je na voljo za tevilne jezike (angleino, nemino, slovenino idr.). Tu bomo ponovno uporabljali e pridobljena jezikovna modela in podatkovna niza (gl. lematizacijo), ampak tokrat za prikaz enostavnih primerov slovnine analize. 7.17.1 Podatkovna niza Za laje prepoznavo besedil bomo najprej spremenili imeni v stolpcu doc_id. Potem bomo podatkovna niza zdruili. en_df = en_df %&gt;% mutate(doc_id = str_replace(doc_id, &quot;doc1&quot;, &quot;tom_en&quot;)) de_df = de_df %&gt;% mutate(doc_id = str_replace(doc_id, &quot;doc1&quot;, &quot;tom_de&quot;)) tom_df = rbind(en_df, de_df) %&gt;% mutate(token_id = as.integer(factor(token_id))) %&gt;% arrange(doc_id, paragraph_id, sentence_id, token_id) head(tom_df) ## doc_id paragraph_id sentence_id ## 1 tom_de 1 1 ## 2 tom_de 1 1 ## 3 tom_de 1 1 ## 4 tom_de 1 1 ## 5 tom_de 1 1 ## 6 tom_de 1 1 ## sentence ## 1 Vorwort des Autors . Die meisten der hier erzählten Abenteuer haben sich tatsächlich zugetragen . Das eine oder das andere habe ich selbst erlebt , die anderen meine Schulkameraden . Huck Finn ist nach dem Leben gezeichnet , nicht weniger Tom Sawyer , doch entspricht dieser nicht einer bestimmten Persönlichkeit , sondern wurde mit charakteristischen Zügen mehrerer meiner Altersgenossen ausgestattet und darf daher jenem gegenüber als einigermaßen kompliziertes psychologisches Problem gelten . Ich muß hier bemerken , daß zur Zeit meiner Erzählung -- vor dreißig bis vierzig Jahren -- unter den Unmündigen und Unwissenden des Westens noch die seltsamsten , unwahrscheinlichsten Vorurteile und Aberglauben herrschten . Obwohl dies Buch vor allem zur Unterhaltung der kleinen Welt geschrieben wurde , so darf ich doch wohl hoffen , daß es auch von Erwachsenen nicht ganz unbeachtet gelassen werde , habe ich doch darin versucht , ihnen auf angenehme Weise zu zeigen , was sie einst selbst waren , wie sie fühlten , dachten , sprachen , und welcher Art ihr Ehrgeiz und ihre Unternehmungen waren . Erstes Kapitel . , ,Tom ! &quot; Keine Antwort . , ,Tom ! &quot; Alles still . , ,Soll mich doch wundern , wo der Bengel wieder steckt ! Tom ! &quot; Die alte Dame schob ihre Brille hinunter und schaute darüber hinweg ; dann schob sie sie auf die Stirn und schaute darunter weg. ## 2 Vorwort des Autors . Die meisten der hier erzählten Abenteuer haben sich tatsächlich zugetragen . Das eine oder das andere habe ich selbst erlebt , die anderen meine Schulkameraden . Huck Finn ist nach dem Leben gezeichnet , nicht weniger Tom Sawyer , doch entspricht dieser nicht einer bestimmten Persönlichkeit , sondern wurde mit charakteristischen Zügen mehrerer meiner Altersgenossen ausgestattet und darf daher jenem gegenüber als einigermaßen kompliziertes psychologisches Problem gelten . Ich muß hier bemerken , daß zur Zeit meiner Erzählung -- vor dreißig bis vierzig Jahren -- unter den Unmündigen und Unwissenden des Westens noch die seltsamsten , unwahrscheinlichsten Vorurteile und Aberglauben herrschten . Obwohl dies Buch vor allem zur Unterhaltung der kleinen Welt geschrieben wurde , so darf ich doch wohl hoffen , daß es auch von Erwachsenen nicht ganz unbeachtet gelassen werde , habe ich doch darin versucht , ihnen auf angenehme Weise zu zeigen , was sie einst selbst waren , wie sie fühlten , dachten , sprachen , und welcher Art ihr Ehrgeiz und ihre Unternehmungen waren . Erstes Kapitel . , ,Tom ! &quot; Keine Antwort . , ,Tom ! &quot; Alles still . , ,Soll mich doch wundern , wo der Bengel wieder steckt ! Tom ! &quot; Die alte Dame schob ihre Brille hinunter und schaute darüber hinweg ; dann schob sie sie auf die Stirn und schaute darunter weg. ## 3 Vorwort des Autors . Die meisten der hier erzählten Abenteuer haben sich tatsächlich zugetragen . Das eine oder das andere habe ich selbst erlebt , die anderen meine Schulkameraden . Huck Finn ist nach dem Leben gezeichnet , nicht weniger Tom Sawyer , doch entspricht dieser nicht einer bestimmten Persönlichkeit , sondern wurde mit charakteristischen Zügen mehrerer meiner Altersgenossen ausgestattet und darf daher jenem gegenüber als einigermaßen kompliziertes psychologisches Problem gelten . Ich muß hier bemerken , daß zur Zeit meiner Erzählung -- vor dreißig bis vierzig Jahren -- unter den Unmündigen und Unwissenden des Westens noch die seltsamsten , unwahrscheinlichsten Vorurteile und Aberglauben herrschten . Obwohl dies Buch vor allem zur Unterhaltung der kleinen Welt geschrieben wurde , so darf ich doch wohl hoffen , daß es auch von Erwachsenen nicht ganz unbeachtet gelassen werde , habe ich doch darin versucht , ihnen auf angenehme Weise zu zeigen , was sie einst selbst waren , wie sie fühlten , dachten , sprachen , und welcher Art ihr Ehrgeiz und ihre Unternehmungen waren . Erstes Kapitel . , ,Tom ! &quot; Keine Antwort . , ,Tom ! &quot; Alles still . , ,Soll mich doch wundern , wo der Bengel wieder steckt ! Tom ! &quot; Die alte Dame schob ihre Brille hinunter und schaute darüber hinweg ; dann schob sie sie auf die Stirn und schaute darunter weg. ## 4 Vorwort des Autors . Die meisten der hier erzählten Abenteuer haben sich tatsächlich zugetragen . Das eine oder das andere habe ich selbst erlebt , die anderen meine Schulkameraden . Huck Finn ist nach dem Leben gezeichnet , nicht weniger Tom Sawyer , doch entspricht dieser nicht einer bestimmten Persönlichkeit , sondern wurde mit charakteristischen Zügen mehrerer meiner Altersgenossen ausgestattet und darf daher jenem gegenüber als einigermaßen kompliziertes psychologisches Problem gelten . Ich muß hier bemerken , daß zur Zeit meiner Erzählung -- vor dreißig bis vierzig Jahren -- unter den Unmündigen und Unwissenden des Westens noch die seltsamsten , unwahrscheinlichsten Vorurteile und Aberglauben herrschten . Obwohl dies Buch vor allem zur Unterhaltung der kleinen Welt geschrieben wurde , so darf ich doch wohl hoffen , daß es auch von Erwachsenen nicht ganz unbeachtet gelassen werde , habe ich doch darin versucht , ihnen auf angenehme Weise zu zeigen , was sie einst selbst waren , wie sie fühlten , dachten , sprachen , und welcher Art ihr Ehrgeiz und ihre Unternehmungen waren . Erstes Kapitel . , ,Tom ! &quot; Keine Antwort . , ,Tom ! &quot; Alles still . , ,Soll mich doch wundern , wo der Bengel wieder steckt ! Tom ! &quot; Die alte Dame schob ihre Brille hinunter und schaute darüber hinweg ; dann schob sie sie auf die Stirn und schaute darunter weg. ## 5 Vorwort des Autors . Die meisten der hier erzählten Abenteuer haben sich tatsächlich zugetragen . Das eine oder das andere habe ich selbst erlebt , die anderen meine Schulkameraden . Huck Finn ist nach dem Leben gezeichnet , nicht weniger Tom Sawyer , doch entspricht dieser nicht einer bestimmten Persönlichkeit , sondern wurde mit charakteristischen Zügen mehrerer meiner Altersgenossen ausgestattet und darf daher jenem gegenüber als einigermaßen kompliziertes psychologisches Problem gelten . Ich muß hier bemerken , daß zur Zeit meiner Erzählung -- vor dreißig bis vierzig Jahren -- unter den Unmündigen und Unwissenden des Westens noch die seltsamsten , unwahrscheinlichsten Vorurteile und Aberglauben herrschten . Obwohl dies Buch vor allem zur Unterhaltung der kleinen Welt geschrieben wurde , so darf ich doch wohl hoffen , daß es auch von Erwachsenen nicht ganz unbeachtet gelassen werde , habe ich doch darin versucht , ihnen auf angenehme Weise zu zeigen , was sie einst selbst waren , wie sie fühlten , dachten , sprachen , und welcher Art ihr Ehrgeiz und ihre Unternehmungen waren . Erstes Kapitel . , ,Tom ! &quot; Keine Antwort . , ,Tom ! &quot; Alles still . , ,Soll mich doch wundern , wo der Bengel wieder steckt ! Tom ! &quot; Die alte Dame schob ihre Brille hinunter und schaute darüber hinweg ; dann schob sie sie auf die Stirn und schaute darunter weg. ## 6 Vorwort des Autors . Die meisten der hier erzählten Abenteuer haben sich tatsächlich zugetragen . Das eine oder das andere habe ich selbst erlebt , die anderen meine Schulkameraden . Huck Finn ist nach dem Leben gezeichnet , nicht weniger Tom Sawyer , doch entspricht dieser nicht einer bestimmten Persönlichkeit , sondern wurde mit charakteristischen Zügen mehrerer meiner Altersgenossen ausgestattet und darf daher jenem gegenüber als einigermaßen kompliziertes psychologisches Problem gelten . Ich muß hier bemerken , daß zur Zeit meiner Erzählung -- vor dreißig bis vierzig Jahren -- unter den Unmündigen und Unwissenden des Westens noch die seltsamsten , unwahrscheinlichsten Vorurteile und Aberglauben herrschten . Obwohl dies Buch vor allem zur Unterhaltung der kleinen Welt geschrieben wurde , so darf ich doch wohl hoffen , daß es auch von Erwachsenen nicht ganz unbeachtet gelassen werde , habe ich doch darin versucht , ihnen auf angenehme Weise zu zeigen , was sie einst selbst waren , wie sie fühlten , dachten , sprachen , und welcher Art ihr Ehrgeiz und ihre Unternehmungen waren . Erstes Kapitel . , ,Tom ! &quot; Keine Antwort . , ,Tom ! &quot; Alles still . , ,Soll mich doch wundern , wo der Bengel wieder steckt ! Tom ! &quot; Die alte Dame schob ihre Brille hinunter und schaute darüber hinweg ; dann schob sie sie auf die Stirn und schaute darunter weg. ## token_id token lemma upos xpos ## 1 1 Vorwort Vorwort ADP NN ## 2 3 Abenteuer Abenteuer NOUN NN ## 3 5 seltsamsten seltsam ADJ NN ## 4 7 , , PUNCT $, ## 5 9 unwahrscheinlichsten unwahrscheinlich ADJ NN ## 6 10 Vorurteile Vorurteil NOUN NN ## feats head_token_id dep_rel deps misc ## 1 Case=Nom|Gender=Neut|Number=Sing 3 case &lt;NA&gt; &lt;NA&gt; ## 2 Case=Acc|Gender=Neut|Number=Plur 6 nmod &lt;NA&gt; &lt;NA&gt; ## 3 Case=Acc|Gender=Masc|Number=Plur 103 amod &lt;NA&gt; &lt;NA&gt; ## 4 &lt;NA&gt; 100 punct &lt;NA&gt; &lt;NA&gt; ## 5 Case=Acc|Gender=Masc|Number=Plur 103 amod &lt;NA&gt; &lt;NA&gt; ## 6 Case=Acc|Gender=Neut|Number=Plur 106 obj &lt;NA&gt; &lt;NA&gt; tail(tom_df) ## doc_id paragraph_id sentence_id ## 174376 tom_en 1898 5231 ## 174377 tom_en 1898 5231 ## 174378 tom_en 1898 5231 ## 174379 tom_en 1898 5231 ## 174380 tom_en 1898 5231 ## 174381 tom_en 1898 5231 ## sentence ## 174376 Some day it may seem worth while to take up the story of the younger ones again and see what sort of men and women they turned out to be; therefore it will be wisest not to reveal any of that part of their lives at present. ## 174377 Some day it may seem worth while to take up the story of the younger ones again and see what sort of men and women they turned out to be; therefore it will be wisest not to reveal any of that part of their lives at present. ## 174378 Some day it may seem worth while to take up the story of the younger ones again and see what sort of men and women they turned out to be; therefore it will be wisest not to reveal any of that part of their lives at present. ## 174379 Some day it may seem worth while to take up the story of the younger ones again and see what sort of men and women they turned out to be; therefore it will be wisest not to reveal any of that part of their lives at present. ## 174380 Some day it may seem worth while to take up the story of the younger ones again and see what sort of men and women they turned out to be; therefore it will be wisest not to reveal any of that part of their lives at present. ## 174381 Some day it may seem worth while to take up the story of the younger ones again and see what sort of men and women they turned out to be; therefore it will be wisest not to reveal any of that part of their lives at present. ## token_id token lemma upos xpos feats head_token_id dep_rel deps ## 174376 619 . . PUNCT . &lt;NA&gt; 5 punct &lt;NA&gt; ## 174377 621 seem seem VERB VB VerbForm=Inf 0 root &lt;NA&gt; ## 174378 642 worth worth ADJ JJ Degree=Pos 5 xcomp &lt;NA&gt; ## 174379 663 while while SCONJ IN &lt;NA&gt; 9 mark &lt;NA&gt; ## 174380 684 to to PART TO &lt;NA&gt; 9 mark &lt;NA&gt; ## 174381 703 take take VERB VB VerbForm=Inf 6 advcl &lt;NA&gt; ## misc ## 174376 SpacesAfter=\\\\n\\\\n\\\\n\\\\n\\\\n ## 174377 &lt;NA&gt; ## 174378 &lt;NA&gt; ## 174379 &lt;NA&gt; ## 174380 &lt;NA&gt; ## 174381 &lt;NA&gt; Shranjujemo in nadaljujemo naslednji. # write_rds(tom_df, &quot;data/tom_df.rds&quot;) # tom_df = read_rds(&quot;data/tom_df.rds&quot;) 7.17.2 Primerjava Noun : Pron Zdaj lahko zanemo poizvedovati po besednih oblikah, slovarskih enotah in slovninih kategorijah. tabela = tom_df %&gt;% group_by(doc_id) %&gt;% count(upos) %&gt;% filter(!is.na(upos), upos != &quot;PUNCT&quot;) head(tabela) ## # A tibble: 6 x 3 ## # Groups: doc_id [1] ## doc_id upos n ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 tom_de ADJ 5537 ## 2 tom_de ADP 5525 ## 3 tom_de ADV 6708 ## 4 tom_de AUX 3387 ## 5 tom_de CCONJ 3268 ## 6 tom_de DET 6887 tabela %&gt;% mutate(upos = reorder_within(upos, n, n, sep = &quot;: &quot;)) %&gt;% ggplot(aes(n, upos, fill = upos)) + geom_col() + facet_wrap(~ doc_id, scales = &quot;free&quot;) + theme(legend.position = &quot;none&quot;) + labs(x = &quot;tevilo pojavnic&quot;, y = &quot;&quot;) Izraun deleev: delezi = tabela %&gt;% mutate(prozent = n/sum(n)) %&gt;% pivot_wider(id_cols = upos, names_from = doc_id, values_from = n:prozent) head(delezi) ## # A tibble: 6 x 5 ## upos n_tom_de n_tom_en prozent_tom_de prozent_tom_en ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ADJ 5537 4324 0.0818 0.0588 ## 2 ADP 5525 7048 0.0816 0.0959 ## 3 ADV 6708 5743 0.0991 0.0782 ## 4 AUX 3387 4592 0.0500 0.0625 ## 5 CCONJ 3268 3761 0.0483 0.0512 ## 6 DET 6887 7081 0.102 0.0964 delezi %&gt;% filter(upos %in% c(&quot;NOUN&quot;, &quot;PRON&quot;)) ## # A tibble: 2 x 5 ## upos n_tom_de n_tom_en prozent_tom_de prozent_tom_en ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 NOUN 10871 12410 0.161 0.169 ## 2 PRON 9027 9831 0.133 0.134 Ali se besedili razlikujeta glede razmerja med samostalniki in zaimki? Glede na to, da gre za vsebinsko in najbr tudi slogovno zelo podobni besedili (izvirnik in prevod), in glede na to, da gre za sorodna jezika (angleinao in nemino), bi bila verjetna nielna domneva (H0: med izvirnikom in prevodom ni statistino znailne razlike). Manj verjetna se zdi alternativna hipoteza (H1: med izvirnikom in prevodom je statistino znailna razlika). # za hi kvadrat test potrebujemo le drugi in tretji stolpec nominal = delezi %&gt;% filter(upos %in% c(&quot;NOUN&quot;, &quot;PRON&quot;)) %&gt;% dplyr::select(n_tom_de, n_tom_en) # statisticni preskus chisq.test(nominal) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: nominal ## X-squared = 5.7103, df = 1, p-value = 0.01687 Hi kvadrat test potrjuje alternativno domnevo (H1). Angleki izvirnik in nemki prevod se razlikujeta glede razmerja med samostalniki in zaimki: X^2 (1) = 5,71; p &lt; 0,001. Iz gornje tabele pogostnosti je razvidno, da je dele samostalnikov v anglekem izvirniku nekoliko veji kot v nemkem prevodu. Razlika je sicer zaradi velikih vzorcev statistino znailna, ni pa velika, saj so delei zelo podobni. Da bi ugotovili, ali je ugotovljena statistina znailna razlika pomembna, bi si morali podrobneje ogledati, kateri zaimki in kateri samostalniki bistveno vplivajo na to tevilno razmerje. Na splono velja, da so zaimki manj zanesljiva jezikovna sredstva kot samostalniki, samostalniki pa so bolj zapleteni. e elimo primerjati eno besedno vrsto z vsemi drugimi v podatkovnem nizu, je pretvorba bolj zapletena, saj moramo - podobno kot v Excelu: - najprej izraunati vsoto za vse besedne vrste, - potem odteti tevilo zaimkov oz. samostalnikov od vsote, - razliko pa upotevati za tabelo 2x2 za hi kvadrat test. (zaimki = tom_df %&gt;% group_by(doc_id) %&gt;% count(upos) %&gt;% filter(!is.na(upos), upos != &quot;PUNCT&quot;) %&gt;% mutate(vsota = sum(n), no_noun = vsota - n[upos == &quot;NOUN&quot;], no_pron = vsota - n[upos == &quot;PRON&quot;]) %&gt;% filter(upos == &quot;PRON&quot;) %&gt;% dplyr::select(doc_id, n, no_pron) %&gt;% pivot_longer(-doc_id, &#39;kategorija&#39;, &#39;vrednost&#39;) %&gt;% pivot_wider(kategorija, doc_id) ) ## # A tibble: 2 x 3 ## kategorija tom_de tom_en ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 n 9027 9831 ## 2 no_pron 58691 63649 (samostalniki = tom_df %&gt;% group_by(doc_id) %&gt;% count(upos) %&gt;% filter(!is.na(upos), upos != &quot;PUNCT&quot;) %&gt;% mutate(vsota = sum(n), no_noun = vsota - n[upos == &quot;NOUN&quot;], no_pron = vsota - n[upos == &quot;PRON&quot;]) %&gt;% filter(upos == &quot;NOUN&quot;) %&gt;% dplyr::select(doc_id, n, no_noun) %&gt;% pivot_longer(-doc_id, &#39;kategorija&#39;, &#39;vrednost&#39;) %&gt;% pivot_wider(kategorija, doc_id) ) ## # A tibble: 2 x 3 ## kategorija tom_de tom_en ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 n 10871 12410 ## 2 no_noun 56847 61070 Hi kvadrat testa: - primerjava tevila zaimkov nasproti ostalim besednim vrstam, - primerjava tevila samostalnikov nasproti ostalim besednim vrstam. V obeh primerih spet velja: H0 (med vzorcema ni statistino znailne razlike). H1 (vzorca se znailno razlikujeta). # izloimo prvi stolpec [, -1], # saj za hi kvadrat test potrebujemo le tevilke v drugem in tretjem stolpcu chisq.test(zaimki[,-1]) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: zaimki[, -1] ## X-squared = 0.068568, df = 1, p-value = 0.7934 chisq.test(samostalniki[,-1]) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: samostalniki[, -1] ## X-squared = 17.81, df = 1, p-value = 2.441e-05 Statistini izid: Delea zaimkov se v besedilih ne razlikujeta (prvi test potrjuje H0), vendar pa se besedili razlikujeta glede delea samostalnikov (drugi test potrjuje H1). 7.17.3 Primerjava veznikov Primerjati elimo tevilo stavkov s prirednim in podrednim veznikom. Osnovna domneva je, da priredno zloene povedi (vsebujejo stavek, uveden s prirednim veznikom) laje razumemo kot podredno zloene povedi (vsebujejo stavek, uveden s podrednim veznikom). (vezniki = tabela %&gt;% filter(upos %in% c(&quot;CCONJ&quot;, &quot;SCONJ&quot;)) %&gt;% mutate(prozent = n/sum(n)) %&gt;% pivot_wider(id_cols = upos, names_from = doc_id, values_from = n:prozent) ) ## # A tibble: 2 x 5 ## upos n_tom_de n_tom_en prozent_tom_de prozent_tom_en ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 CCONJ 3268 3761 0.716 0.732 ## 2 SCONJ 1295 1378 0.284 0.268 Odstotki nakazujejo, da je dele prirednih veznikov v anglekem izvirniku rahlo veji kot v nemkem prevodu. Spet uporabljamo hi kvadrat test (upotevane so le povedi, ki vsebujejo veznik) za preverjanje, ali je razlika dovolj velika, da bi bila nenakljuna. chisq.test(vezniki[,c(2:3)]) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: vezniki[, c(2:3)] ## X-squared = 2.8912, df = 1, p-value = 0.08907 Z ozirom na hi kvadrat test razlika med besediloma ni statistino znailna (potrjen je H0). e upotevamo tudi vsote drugih besednih vrst (kot zgoraj): (koord = tabela %&gt;% mutate(vsota = sum(n), no_cconj = vsota - n[upos == &quot;CCONJ&quot;], no_sconj = vsota - n[upos == &quot;SCONJ&quot;]) %&gt;% filter(upos == &quot;CCONJ&quot;) %&gt;% dplyr::select(doc_id, n, no_cconj) %&gt;% pivot_longer(-doc_id, &#39;kategorija&#39;, &#39;vrednost&#39;) %&gt;% pivot_wider(kategorija, doc_id) ) ## # A tibble: 2 x 3 ## kategorija tom_de tom_en ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 n 3268 3761 ## 2 no_cconj 64450 69719 (subord = tabela %&gt;% mutate(vsota = sum(n), no_cconj = vsota - n[upos == &quot;CCONJ&quot;], no_sconj = vsota - n[upos == &quot;SCONJ&quot;]) %&gt;% filter(upos == &quot;SCONJ&quot;) %&gt;% dplyr::select(doc_id, n, no_sconj) %&gt;% pivot_longer(-doc_id, &#39;kategorija&#39;, &#39;vrednost&#39;) %&gt;% pivot_wider(kategorija, doc_id) ) ## # A tibble: 2 x 3 ## kategorija tom_de tom_en ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 n 1295 1378 ## 2 no_sconj 66423 72102 Hi kvadrat preizkus izkazuje razliko med besediloma v primeru prirednih veznikov (potrjen je H1), v primeru podrednih veznikov pa ne (potrjen je H0). chisq.test(koord[,-1]) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: koord[, -1] ## X-squared = 6.3124, df = 1, p-value = 0.01199 chisq.test(subord[,-1]) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: subord[, -1] ## X-squared = 0.24025, df = 1, p-value = 0.624 Besedili se razlikujeta glede delea prirednih veznikov (e jih primerjamo z vsemi drugimi besednimi vrstami). 7.17.4 Slovarske enote Program udpipe je vsako besedno obliko dodelil slovarski enoti (lemma). Koliko koliko slovarskih enot je v besedilih? Katerim besednim vrstam najpogosteje pripadajo? (tabela2 = tom_df %&gt;% group_by(doc_id, upos) %&gt;% filter(!is.na(upos), upos != &quot;PUNCT&quot;, upos != &quot;X&quot;) %&gt;% distinct(lemma) %&gt;% count(lemma) %&gt;% summarise(lemmas = sum(n)) %&gt;% mutate(prozent = round(lemmas/sum(lemmas), 4)) %&gt;% arrange(-prozent) ) ## `summarise()` has grouped output by &#39;doc_id&#39;. You can override using the `.groups` argument. ## # A tibble: 28 x 4 ## # Groups: doc_id [2] ## doc_id upos lemmas prozent ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 tom_en NOUN 3245 0.403 ## 2 tom_de NOUN 3400 0.361 ## 3 tom_en VERB 1912 0.238 ## 4 tom_de VERB 1935 0.206 ## 5 tom_de ADJ 1875 0.199 ## 6 tom_en ADJ 1294 0.161 ## 7 tom_de PROPN 967 0.103 ## 8 tom_en ADV 627 0.0779 ## 9 tom_de ADV 672 0.0714 ## 10 tom_en PROPN 389 0.0483 ## # ... with 18 more rows tabela2 %&gt;% # slice_max(order_by = prozent, n=6) %&gt;% mutate(upos = reorder_within(upos, lemmas, paste(&quot;(&quot;,100*prozent,&quot;%)&quot;), sep = &quot; &quot;)) %&gt;% ggplot(aes(prozent, upos, fill = upos)) + geom_col() + facet_wrap(~ doc_id, scales = &quot;free&quot;) + theme(legend.position = &quot;none&quot;) + scale_x_continuous(labels = percent_format()) + labs(x = &quot;Anteil&quot;, y = &quot;Wortklasse&quot;) 7.17.5 Korelacija besed Katere besedne pogostnosti se vzporedno poveujejo ali zmanjujejo (pairwise correlation) ? Podobno analizno orodje ima tudi Voyant Tools. library(widyr) # pairwise correlation correlations = tom_df %&gt;% filter(dep_rel != &quot;punct&quot;, dep_rel != &quot;nummod&quot;) %&gt;% mutate(lemma = tolower(lemma), token = tolower(token), lemma = str_trim(lemma), token = str_trim(token)) %&gt;% janitor::clean_names() %&gt;% group_by(doc_id, lemma, token, sentence_id) %&gt;% # add_count(token) %&gt;% summarize(Freq = n()) %&gt;% arrange(-Freq) %&gt;% filter(Freq &gt; 2) %&gt;% pairwise_cor(lemma, sentence_id, sort = TRUE) %&gt;% filter(correlation &lt; 1 &amp; correlation &gt; 0.3) ## `summarise()` has grouped output by &#39;doc_id&#39;, &#39;lemma&#39;, &#39;token&#39;. You can override using the `.groups` argument. head(correlations) ## # A tibble: 6 x 3 ## item1 item2 correlation ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 der und 0.934 ## 2 und der 0.934 ## 3 zu und 0.829 ## 4 und zu 0.829 ## 5 sein und 0.812 ## 6 und sein 0.812 Tom Sawyer: Becky (dekle, ki je Tomu ve). correlations %&gt;% filter(item1 == &quot;tom&quot;) %&gt;% mutate(item2 = fct_reorder(item2, correlation)) %&gt;% ggplot(aes(item2, correlation, fill = item2)) + geom_col(show.legend = F) + coord_flip() + labs(title = &quot;What tends to appear with &#39;Becky&#39;?&quot;, subtitle = &quot;Among elements that appeared in at least 2 sentences&quot;) 7.18 Sentiment Stopnjo ustvenosti ali emocionalnosti besedila je mogoe doloiti s sentimentnim slovarjem. 7.18.1 Razliica 1 Uporaba nrc leksikona za nemino (priloen programu syuzhet). Najprej besedilo s funkcijo get_sentences() razcepimo na povedi. library(syuzhet) tom_v = get_sentences(txt$text[1]) # izberemo prvo besedilo: tom_de.txt tom_v = (tom_v[-1]) # tako lahko izloimo prvo vrstico (uredniko pripombo) head(tom_v[-1]) ## [1] &quot;Das eine oder das andere habe ich selbst erlebt , die anderen meine Schulkameraden .&quot; ## [2] &quot;Huck Finn ist nach dem Leben gezeichnet , nicht weniger Tom Sawyer , doch entspricht dieser nicht einer bestimmten Persönlichkeit , sondern wurde mit charakteristischen Zügen mehrerer meiner Altersgenossen ausgestattet und darf daher jenem gegenüber als einigermaßen kompliziertes psychologisches Problem gelten .&quot; ## [3] &quot;Ich muß hier bemerken , daß zur Zeit meiner Erzählung -- vor dreißig bis vierzig Jahren -- unter den Unmündigen und Unwissenden des Westens noch die seltsamsten , unwahrscheinlichsten Vorurteile und Aberglauben herrschten .&quot; ## [4] &quot;Obwohl dies Buch vor allem zur Unterhaltung der kleinen Welt geschrieben wurde , so darf ich doch wohl hoffen , daß es auch von Erwachsenen nicht ganz unbeachtet gelassen werde , habe ich doch darin versucht , ihnen auf angenehme Weise zu zeigen , was sie einst selbst waren , wie sie fühlten , dachten , sprachen , und welcher Art ihr Ehrgeiz und ihre Unternehmungen waren .&quot; ## [5] &quot;Erstes Kapitel .&quot; ## [6] &quot;, ,Tom !&quot; Funkcija get_sentiment() dodeli besedam v povedih pozitivno (+1), negativno (-1) ali nevtralno (0) ustveno vrednost. Program te vrednosti seteje. tom_values &lt;- get_sentiment(tom_v, method = &quot;nrc&quot;, language = &quot;german&quot;) length(tom_values) ## [1] 5047 tom_values[100:110] ## [1] 0 -2 0 1 0 1 0 0 0 0 0 Povedi, ustvene vrednosti in dolino povedi poveemo v podatkovni niz. To nam olajuje oceno, kako uspena je bila uporaba sentimentnega slovarja v naem besedilu. Preimenovali bomo tudi nekaj stolpcev. sentiment1 = cbind(tom_v, tom_values, ntoken(tom_v)) %&gt;% as.data.frame() %&gt;% rename(words = V3, text = tom_v, values = tom_values) %&gt;% mutate(doc_id = &quot;tom_de.txt&quot;) %&gt;% rowid_to_column(var = &quot;sentence&quot;) head(sentiment1) ## sentence ## 1 1 ## 2 2 ## 3 3 ## 4 4 ## 5 5 ## 6 6 ## text ## 1 Die meisten der hier erzählten Abenteuer haben sich tatsächlich zugetragen . ## 2 Das eine oder das andere habe ich selbst erlebt , die anderen meine Schulkameraden . ## 3 Huck Finn ist nach dem Leben gezeichnet , nicht weniger Tom Sawyer , doch entspricht dieser nicht einer bestimmten Persönlichkeit , sondern wurde mit charakteristischen Zügen mehrerer meiner Altersgenossen ausgestattet und darf daher jenem gegenüber als einigermaßen kompliziertes psychologisches Problem gelten . ## 4 Ich muß hier bemerken , daß zur Zeit meiner Erzählung -- vor dreißig bis vierzig Jahren -- unter den Unmündigen und Unwissenden des Westens noch die seltsamsten , unwahrscheinlichsten Vorurteile und Aberglauben herrschten . ## 5 Obwohl dies Buch vor allem zur Unterhaltung der kleinen Welt geschrieben wurde , so darf ich doch wohl hoffen , daß es auch von Erwachsenen nicht ganz unbeachtet gelassen werde , habe ich doch darin versucht , ihnen auf angenehme Weise zu zeigen , was sie einst selbst waren , wie sie fühlten , dachten , sprachen , und welcher Art ihr Ehrgeiz und ihre Unternehmungen waren . ## 6 Erstes Kapitel . ## values words doc_id ## 1 1 11 tom_de.txt ## 2 0 15 tom_de.txt ## 3 -2 42 tom_de.txt ## 4 0 34 tom_de.txt ## 5 6 68 tom_de.txt ## 6 0 3 tom_de.txt View(sentiment1) Gornje postopke ponovimo za besedilo, ki ga elimo primerjati s prvim. prozess_v = get_sentences(txt$text[2]) # izberemo drugo besedilo: tom_en.txt prozess_v = (prozess_v[-1]) # tako lahko izloimo prvo vrstico (uredniko pripombo) prozess_values &lt;- get_sentiment(prozess_v, method = &quot;nrc&quot;, language = &quot;english&quot;) sentiment2 = cbind(prozess_v, prozess_values, ntoken(prozess_v)) %&gt;% as.data.frame() %&gt;% rename(words = V3, text = prozess_v, values = prozess_values) %&gt;% mutate(doc_id = &quot;tom_en.txt&quot;) %&gt;% rowid_to_column(var = &quot;sentence&quot;) head(sentiment2) ## sentence ## 1 1 ## 2 2 ## 3 3 ## 4 4 ## 5 5 ## 6 6 ## text ## 1 Huck Finn is drawn from life; Tom Sawyer also, but not from an\\nindividualhe is a combination of the characteristics of three boys whom\\nI knew, and therefore belongs to the composite order of architecture. ## 2 The odd superstitions touched upon were all prevalent among children and\\nslaves in the West at the period of this storythat is to say, thirty or\\nforty years ago. ## 3 Although my book is intended mainly for the entertainment of boys and\\ngirls, I hope it will not be shunned by men and women on that account,\\nfor part of my plan has been to try to pleasantly remind adults of what\\nthey once were themselves, and of how they felt and thought and talked,\\nand what queer enterprises they sometimes engaged in. ## 4 THE AUTHOR. ## 5 HARTFORD, 1876. ## 6 CHAPTER I\\n\\n\\n&quot;TOM!&quot; ## values words doc_id ## 1 0 41 tom_en.txt ## 2 -1 33 tom_en.txt ## 3 4 68 tom_en.txt ## 4 1 3 tom_en.txt ## 5 0 4 tom_en.txt ## 6 0 6 tom_en.txt View(sentiment2) S setevanjem ustvenih vrednosti je mogoe oceniti, katero besedilo ima ve pozitivno ocenjenih besed. V ta namen bomo zdruili podatkovna niza in uredili obliko stolpcev words in values. sentiment = rbind(sentiment1, sentiment2) %&gt;% as_tibble() %&gt;% mutate(values = parse_number(values), words = parse_number(words)) %&gt;% dplyr::select(doc_id, sentence, words, values, text) head(sentiment) ## # A tibble: 6 x 5 ## doc_id sentence words values text ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 tom_de.txt 1 11 1 Die meisten der hier erzählten Abenteuer hab~ ## 2 tom_de.txt 2 15 0 Das eine oder das andere habe ich selbst erl~ ## 3 tom_de.txt 3 42 -2 Huck Finn ist nach dem Leben gezeichnet , ni~ ## 4 tom_de.txt 4 34 0 Ich muß hier bemerken , daß zur Zeit meiner ~ ## 5 tom_de.txt 5 68 6 Obwohl dies Buch vor allem zur Unterhaltung ~ ## 6 tom_de.txt 6 3 0 Erstes Kapitel . tail(sentiment) ## # A tibble: 6 x 5 ## doc_id sentence words values text ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 tom_en.txt 4848 46 -1 &quot;I&#39;ll stick to the widder till I rot, Tom; a~ ## 2 tom_en.txt 4849 6 1 &quot;CONCLUSION\\n\\nSO endeth this chronicle.&quot; ## 3 tom_en.txt 4850 29 -1 &quot;It being strictly a history of a _boy_, it\\~ ## 4 tom_en.txt 4851 38 1 &quot;When one writes a novel about grown people,~ ## 5 tom_en.txt 4852 18 2 &quot;Most of the characters that perform in this~ ## 6 tom_en.txt 4853 49 3 &quot;Some day it may seem worth while to take up~ Rezultat: po gornji metodi je povpreje ustvenih vrednosti v nemkem prevodu rahlo manje kot v anglekem izvirniku Tom Sawyer, vendar je razlika tako majhna, da najbr ne bi bila statistino znailna. Povpreje je v obeh primerih blizu nevtralne vrednosti (tj. 0): Tom Sawyer vsebuje kar nekaj vedrih prigod in dogodivin, je pa res, da so njegove pustolovine pogosto tudi nevarne ali straljive. sentiment %&gt;% group_by(doc_id) %&gt;% summarise(polarnost = mean(values)) ## # A tibble: 2 x 2 ## doc_id polarnost ## &lt;chr&gt; &lt;dbl&gt; ## 1 tom_de.txt -0.0109 ## 2 tom_en.txt 0.0196 Poskusimo e drugae: pozitivne, nevtralne in negativne vrednosti obravnajmo loeno in upotevajmo tudi dolino povedi. sentiment1 = sentiment %&gt;% group_by(doc_id) %&gt;% mutate(positive = ifelse(values &gt; 0, abs(values), 0), neutral = ifelse(values == 0, 1, 0), negative = ifelse(values &lt; 0, abs(values), 0)) sentiment1 %&gt;% summarise(pos = mean(100*positive/words), neut = mean(100*neutral/words), neg = mean(100*negative/words)) ## # A tibble: 2 x 4 ## doc_id pos neut neg ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 tom_de.txt 2.63 6.77 2.81 ## 2 tom_en.txt 2.07 6.74 2.10 Ta rezultat nakazuje, so ustvene vrednosti v nemkem prevodu nekoliko skrajneje (pozitivne ali negativne) kot v anglekem izvirniku. Zanimivo bi bilo vpraati poznavalca anglekega izvirnika in nemkega prevoda, ali je ob slogovni primerjavi dobil podoben vtis. Poglejmo e nekaj povedi, ki so bile ocenjene negativno: sentiment1 %&gt;% filter(negative &gt; 0) ## # A tibble: 2,157 x 8 ## # Groups: doc_id [2] ## doc_id sentence words values text positive neutral negative ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 tom_de.txt 3 42 -2 &quot;Huck Finn ist na~ 0 0 2 ## 2 tom_de.txt 15 81 -2 &quot;Unruhig hielt si~ 0 0 2 ## 3 tom_de.txt 16 8 -1 &quot;Sie hatte nichts~ 0 0 1 ## 4 tom_de.txt 17 12 -1 &quot;, ,So ein Junge ~ 0 0 1 ## 5 tom_de.txt 25 5 -1 &quot;\\&quot; , ,Nicht~ 0 0 1 ## 6 tom_de.txt 26 5 -1 &quot;\\&quot; , ,Nicht~ 0 0 1 ## 7 tom_de.txt 34 5 -3 &quot;Die Gefahr war d~ 0 0 3 ## 8 tom_de.txt 38 8 -1 &quot;, ,Der Kuckuck h~ 0 0 1 ## 9 tom_de.txt 41 18 -2 &quot;Aber alte Torhei~ 0 0 2 ## 10 tom_de.txt 47 11 -1 &quot;Er steckt voller~ 0 0 1 ## # ... with 2,147 more rows 7.18.2 Razliica 2 tom_v = get_sentences(txt$text[2]) # angleki izvirnik tom_nrc_values = get_nrc_sentiment(tom_v) tom_joy_items = which(tom_nrc_values$joy &gt; 0) head(tom_v[tom_joy_items], 4) ## [1] &quot;Although my book is intended mainly for the entertainment of boys and\\ngirls, I hope it will not be shunned by men and women on that account,\\nfor part of my plan has been to try to pleasantly remind adults of what\\nthey once were themselves, and of how they felt and thought and talked,\\nand what queer enterprises they sometimes engaged in.&quot; ## [2] &quot;She seldom or\\nnever looked _through_ them for so small a thing as a boy; they were\\nher state pair, the pride of her heart, and were built for \\&quot;style,\\&quot; not\\nserviceshe could have seen through a pair of stove-lids just as well.&quot; ## [3] &quot;She went to the open door and stood in it and looked out among the\\ntomato vines and \\&quot;jimpson\\&quot; weeds that constituted the garden.&quot; ## [4] &quot;His aunt Polly stood surprised a moment, and then broke into a gentle\\nlaugh.&quot; nrc_sentiment = as.data.frame(cbind(tom_v, tom_nrc_values)) head(nrc_sentiment) %&gt;% paged_table() 7.18.3 Razliica 3 Drugi sentimentni slovarji z medmreja: npr. BAWLR lahko uporabljamo kot sentimentni slovar. # This lexicons contains values of Emotional valence and arousal ranging from 1 to 5. # But this extended version contains also binary Emo_Val values (1, -1). bawlr &lt;- read.delim2(&quot;data/BAWLR_utf8.txt&quot;, sep = &quot;\\t&quot;, dec = &quot;,&quot;, fileEncoding = &quot;UTF-8&quot;, header = T, stringsAsFactors = T) # # bawlr$EmoVal &lt;- as.character(bawlr$EmoVal) # # str(EmoVal) # bawlr$EmoVal &lt;- gsub(&#39;NEG&#39;, &#39;-1&#39;, bawlr$EmoVal) # bawlr$EmoVal &lt;- gsub(&#39;POS&#39;, &#39;1&#39;, bawlr$EmoVal) # bawlr$EmoVal &lt;- as.numeric(bawlr$EmoVal) head(bawlr) ## EmoVal Freq WORD WORD_LOWER WORD_CLASS EMO_MEAN EMO_STD AROUSAL_MEAN ## 1 NEG HF AAL aal N -0.5 0.7 2.4 ## 2 NEG NF AAS aas N -2.1 1.1 2.6 ## 3 NEG NF ABART abart N -1.6 0.7 3.3 ## 4 NEG HF ABBAU abbau N -1.0 1.2 3.0 ## 5 NEG HF ABBAUEN abbauen V -0.8 0.9 2.1 ## 6 NEG NF ABBILD abbild N -0.2 0.6 2.1 ## AROUSAL_STD IMAGE_MEAN IMAGE_STD LETTERS PHONEMES SYLLABLES Ftot.1MIL N ## 1 1.2 6.6 0.7 3 2 1 13.3 6 ## 2 1.4 5.4 0.9 3 2 1 1.0 6 ## 3 1.0 2.3 1.3 5 5 2 1.2 2 ## 4 1.3 2.2 1.2 5 4 2 14.5 1 ## 5 1.2 3.7 1.6 7 6 3 15.5 3 ## 6 0.8 3.8 2.0 6 6 2 3.5 0 ## FN HFN FHFN BIGmean.TOKEN. ACCENT ## 1 3182.0 3 3175.2 83677.5 1 ## 2 10568.8 5 10568.5 30120.5 1 ## 3 3.0 1 2.3 80270.0 1 ## 4 6.8 0 0.0 94054.8 1 ## 5 51.0 1 38.0 238806.3 1 ## 6 0.0 0 0.0 45958.4 1 Sestavimo dva seznama: positive.words = bawlr %&gt;% mutate(WORD_LOWER = as.character(WORD_LOWER)) %&gt;% dplyr::select(EmoVal, WORD_LOWER) %&gt;% filter(EmoVal == &quot;POS&quot;) %&gt;% dplyr::select(WORD_LOWER) %&gt;% filter(str_detect(WORD_LOWER, &quot;[a-zA-Z]&quot;)) negative.words = bawlr %&gt;% mutate(WORD_LOWER = as.character(WORD_LOWER)) %&gt;% dplyr::select(EmoVal, WORD_LOWER) %&gt;% filter(EmoVal == &quot;NEG&quot;) %&gt;% dplyr::select(WORD_LOWER) %&gt;% filter(str_detect(WORD_LOWER, &quot;[a-zA-Z]&quot;)) Ustvarimo quanteda slovar dictionary(): bawlr_dict = dictionary(list(positive = list(positive.words), negative = list(negative.words))) Quanteda slovar lahko shranimo na disk. # jsonlite::write_json(bawlr_dict, &quot;data/quanteda_bawlr_dict.json&quot;) Uporabljamo matriko (dfm) s slovarskimi enotami (lemma), saj slovar bawlr_dict vsebujejo le osnovno obliko slovarskih enot. matrika_lemmas = dfm(matrika_lem_de, tolower = TRUE) result = matrika_lemmas %&gt;% dfm_lookup(bawlr_dict) %&gt;% convert(to = &quot;data.frame&quot;) %&gt;% as_tibble result ## # A tibble: 1 x 3 ## doc_id positive negative ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 tom_de 9137052 5245512 Dodamo lahko skupno dolino besed, e elimo normalizirati rezultat z ozirom na dolino besedil. result = result %&gt;% mutate(length=ntoken(matrika_lemmas)) result ## # A tibble: 1 x 4 ## doc_id positive negative length ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 tom_de 9137052 5245512 31618 Po navadi elimo izraunati skupno sentimentno vrednost. Monosti je ve: npr. - odteti negativne vrednosti od pozitivnih in nato razliko deliti z vsoto obeh vrednosti, - odteti negativne vrednosti od pozitivnih in nato razliko deliti z dolino besedil, Izraunamo lahko tudi stopnjo subjektivnosti, tj. koliko ustvenih vrednosti je skupno izraenih: result = result %&gt;% mutate(sentiment1=(positive - negative) / (positive + negative)) result = result %&gt;% mutate(sentiment2=(positive - negative) / length) result = result %&gt;% mutate(subjektivnost=(positive + negative) / length) result %&gt;% paged_table() 7.18.4 Barvno oznaevanje Program corpustools barvno oznauje besede v besedilih z ozirom na ustvene vrednosti besed v sentimentnem slovarju. Prvi korak je ustvarjanje tcorpusa. library(corpustools) t = create_tcorpus(txt1, doc_column=&quot;doc_id&quot;) # izbrali smo le nemki prevod V drugem koraku sledi iskanje po slovarju (tcorpus): t$code_dictionary(bawlr_dict, column = &#39;bawlr&#39;) t$set(&#39;sentiment&#39;, 1, subset = bawlr %in% c(&#39;positive&#39;,&#39;neg_negative&#39;)) t$set(&#39;sentiment&#39;, -1, subset = bawlr %in% c(&#39;negative&#39;,&#39;neg_positive&#39;)) Prikaz barvno oznaenih besedil v oknu Viewer: browse_texts(t, scale=&#39;sentiment&#39;) Prikaz barvno oznaenih besedil v spletnem brskalniku in shranjevanje v obliki html datoteke: browse_texts(t, scale=&#39;sentiment&#39;, filename = &quot;sentiment_tom.html&quot;, header = &quot;Sentiment in Twains Tom Sawyer&quot;) A-Z "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
