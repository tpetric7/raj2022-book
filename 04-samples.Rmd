# Stichprobentests

## Nominalskalierte Größen

**Chi-Quadrat-Test** ($\chi^2$-Test):    
Der $\chi^2$-Test ist einer der grundlegenden statistischen Tests zum Vergleich von nominalskalierten Kategorien, z.B.

-   *biologisches Geschlecht*: Frauen vs. Männer;   
-   *Größe*: klein vs. groß;   
-   *Texte*: Text A vs. Text B vs. Text C ...   

Mit dem $\chi^2$-Test testen wir, ob eine *beobachtete* Verteilung der Daten der *erwarteten* Verteilung entspricht. Der Test funktioniert auf allen Skalenniveaus. Es gibt aber verschiedene Anwendungsspielarten:   

- als *Anpassungstest* (z.B. ist ein Merkmal normalverteilt?);   
- als *Homogenitätstest* (z.B. ähneln sich Frauen und Männer bezüglich eines Merkmals, etwa ob sie rauchen oder nicht?);   
- als *Unabhängigkeitstest* (z.B. ist der Dieselverbrauch unabhängig von elektronischer Regulierung des Motors oder nicht?).   

Ein Beispiel aus einem empfehlenswerten Video aus [Kurzes Tutorium Statistik](https://www.youtube.com/watch?v=MCmZ-HXSZ4A), in dem der $@chi³2$-Test und seine Anwendungen erklärt werden. Im Beispiel geht es um den $@chi³2$-*Anpassungstest*:   

Eine Firma verkauft Armbanduhren in vier Farben (blau, grün, gelb, rot). Im letzten Monat wurden 1000 Stück verkauft. Ein Verkaufsleiter behauptet, dass die Nachfrage nach der Uhr in allen vier Farben gleich gut sei. Das können wir mit dem $\chi^2$-Test überprüfen. Wenn die Behauptung des Verkaufsleiters stimmt, dann **erwarten** wir, dass 250 blaue Uhren, 250 grüne Uhren, 250 gelbe Uhren und 250 rote Uhren verkauft wurden - dass also *Gleichverteilung* der *erwarteten Häufigkeiten* vorliegt (250 + 250 + 250 + 250). Also ein Viertel der verkauften Uhren war blau, ein Viertel war gelb, ein Viertel war rot und ein Viertel war grün.   

Wären die (**beobachteten**) Verkaufszahlen im vergangenen Monat (unserer Stichprobe) 245 + 252 + 254 + 249, dann würde der $@chi^2$-Test bestätigen, dass Gleichverteilung der Uhrfarben vorliegt und damit die Hypothese $H_0$ bestätigen. Die Unterschiede sind ja gering. Wenn aber die beobachteten Verkaufszahlen in unserer Stichprobe 60 + 320 + 100 + 520 wären, dann würde der $@chi^2$-Test die Gleichverteilung der Farben nicht bestätigen und die Nullhypothese $H_0$ verwerfen.   

Die Statistikexpertin erhält vom Verkaufsleiter die tatsächlichen Verkaufszahlen: 300 blaue Urhen + 200 gelbe Uhren + 400 rote Uhren + 100 grüne Uhren wurden im vergangenen Monat verkauft. Kann man das noch immer als Gleichverteilung der Farben auffassen?   

Wir verwenden die folgende Teststatistik:   
- Wir *subtrahieren* die jeweilige erwartete Häufikgeit von der beobachteten und erhalten somit Differenzen;   
- dann *quadrieren* wir jede *Differenz*, so dass wir nur mit positiven Zahlenwerten zu tun haben;    
- dann *dividieren* wir jede der *quadrierten Differenzen* mit der *erwarteten* Häufigkeit (hier: 250) und erhalten somit Quotienten;   
- dann *addieren* wir die *Quotienten* und erhalten somit den *empirischen* $@chi^2$-Wert (im Beispiel beträgt dieser 200).   

$$
\frac{(300 - 250)^2}{250} + \frac{(200 - 250)^2}{250} + \frac{(400 - 250)^2}{250} + \frac{(100 - 250)^2}{250} = 200 = \chi^2_{empirisch}
$$

Das **Test- oder Signifikanzniveau** (auch **Irrtumswahrscheinlichkeit** genannt) wird gewöhnlich auf 5% festgelegt (p = 0,05). Die Wahrscheinlichkeit, dass wir fälschlicherweise die Nullhypothese verwerfen, soll demnach bei diesem Testniveau höchstens 5% betragen.    

Da die Warscheinlichkeit ein Viertel pro Uhrfarbe beträgt (250 von 1000; siehe oben), liegt eine *Binomialverteilung* vor. Bei ausreichend großen Stichproben (wie der hier vorliegenden) kann man diese durch die *Normalverteilung* ersetzen. Mit der Normalverteilung lässt sich einfacher rechnen.    

Da wir in unserer Teststatistik die erwarteten Häufigkeiten von den beobachteten abziehen und danach dividieren, wird die Normalverteilung zum Nullpunkt des Koordinatensystems verschoben. Die Werte der Teststatistik werden durch diesen Rechenvorgang *normalisiert*.   

Durch Quadrieren der Differenzen erreichen wir, dass wir keine negativen Werte mehr erhalten können. Alle Werte sind damit positiv und befinden sich im ersten Quadranten des Koordinatensystems. Da wir mehrere Terme addieren (hier sind es 4) und damit potentiell mehrere Zufallsvariablen in die Summe einbeziehen, kann die *Verteilungskurve* verschiedene Formen annehmen. Das Ergebnis ist eine $\chi^2$-Verteilung. Diese Verteilung sagt uns, welche Werte die Teststatistik mit welcher Wahrscheinlichkeit annehmen wird, wenn die Nullhypothese $H_0$ stimmt. Danach sind die Werte in der Nähe des Koordinatenursprungs (der Null) wahrscheinlich. Die meisten Werte unserer Teststatistik sollten gemäß der Nullhypothese in diesem Bereich, dem *Annahmebereich*, liegen. Werte, die weit entfernt von der Null (dem Koordinatenursprung) vorkommen, sind weniger wahrscheinlich. Sie liegen im *Ablehnungsbereich* (Verwerfungsbereich).   

Eine grundlegende Bedingung für die Anwendung des $\chi^2$-Tests ist, dass die erwarteten Häufigkeiten nicht kleiner als fünf sein dürfen: $Freq_{erwartet}\geq{5}$. In unserem Beispiel ist das der Fall (hier: 250).    

In unserem Beispiel haben wir vier Summenterme, die die Gesamtsumme 1000 (Uhren) ergeben müssen. Die ersten drei Summen könnten vom Zufall abhängen, die letzte ist dagegen immer die Differenz zur Gesamtsumme (hier: 1000). In unserem Beispiel gibt es demnach nur drei Größen (Summen), die frei variieren können. In unserem Beispiel liegen demnach drei *Freiheitsgrade* vor. Das ist notwendig zu wissen, falls man (noch) mit Tabellen arbeitet und wenn man sich sicher sein möchte, dass man den Test richtig durchgeführt hat. Bei drei Freiheitsgraden und einem *Signifikanzniveau* von 5% beträgt der *kritische* $\chi^2$-Wert (*Schwellenwert* für die Annahme bzw. Ablehnung der Nullhypothese) etwa 7,815. Wenn die Nullhypothese stimmt, dann beträgt unsere Teststatistik mit 95%-iger Wahrscheinlichkeit höchstens 7,815. Unser empirischer $\chi^2$-Wert beträgt jedoch 200 und ist damit größer als der Schwellenwert (kritische Wert). Das bedeutet, dass wir die Nullhypothese verwerfen und die alternative Hypothese $H_1$ annehmen. 

**Zusammenfassung**   
Frage: Werden die Uhrfarben gleichhäufig verkauft?   
Hypothese $H_0$: Die Farben werden gleichhäufig verkauft.   
Hypothese $H_1$: Die Farben werden NICHT gleichhäufig verkauft.   
Testverteilung: $\chi^2$-Verteilung.   
Testniveau: $\alpha = 5%$   
Teststatistik:    

$$
\chi^2_{emp} = \Sigma{\frac{(Freq_{beobachtet} - Freq_{erwartet})^2}{Freq_{erwartet}}}
$$

*Ergebnis* (im obigen Beispiel):   
Die Nachfrage nach den verschiedenfarbigen Uhren ist NICHT gleichmäßig verteilt: $\chi^2_{empirisch} > \chi^2_{erwartet}$ bei 3 Freiheitsgraden und 5%-iger Irrtumswahrscheinlichkeit. Wir lehnen die Nullhypothese damit ab und akzeptieren die alternative Hypothese. 


### Lange und kurze Kommentare

Die Verwendung des $@chi³2$-Tests im sprachlichen Bereich wollen wir zunächst am Beispiel eines erfundenen Datensatzes kennen lernen.

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE}
library(tidyverse)
library(janitor)
library(kableExtra)

# rm(list=ls(all=TRUE)) # clear memory
kommentare = read.delim("data/chisq_kommentare.txt", sep = "\t") %>% clean_names()
kommentare %>% knitr::kable()
```

Im Datensatz wird zwischen langen und kurzen Kommentaren einer Lehrerin unterschieden und die jeweilige Anzahl sprachlicher Fehler von Schülern in ihren Aufsätzen. Geklärt werden soll die Frage, welche Wirkung lange und kurze Kommentare der Lehrerin auf die Anzahl der sprachlichen Fehler hatten.

#### Programme

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(janitor)
library(scales)
library(rmarkdown)
library(kableExtra)
```

#### Kurzversion:

Wie sinnvoll sind lange bzw. kurze Kommentare einer Lehrerin zu sprachlichen Fehlern in Essays?

```{r message=FALSE, warning=FALSE, paged.print=TRUE}
library(tidyverse)
library(janitor)

# Datei laden und die Variablennamen vereinheitlichen
kommentare = read.delim("data/chisq_kommentare.txt", sep = "\t") %>% 
  clean_names()

head(kommentare)

library(janitor)
# Chi-Quadrat-Test
chisq.test(kommentare[,-1])

```

Ergebnis: Wir verwerfen die Hypothese H0 und nehmen die Hypothese H1 an: zwischen kurzen und langen Kommentaren besteht ein nicht zufälliger Unterschied.

#### Längere Version

##### Datei laden

Eine Lehrerin möchte wissen, ob es effektiver ist, wenn sie am Rand der Schüleressays kurze oder ausführlichere Kommentare zu den Fehlern der Schüler_innen notiert. Sie vergleicht somit zwei Schülergruppen (Schüler_innen mit kurzen vs. langen Kommentaren) und zwei Beurteilungskategorien (korrekte vs. inkorrekte Äußerungen in den Essays).

```{r message=FALSE, warning=FALSE, paged.print=TRUE}
library(tidyverse)

# von github laden
kommentare = read.delim(
  "https://raw.githubusercontent.com/tpetric7/tpetric7.github.io/main/data/chisq_kommentare.txt",
  sep = "\t", fileEncoding = "UTF-8")

library(janitor)

# Variablennamen konsequent schreiben
kommentare = kommentare %>% 
  clean_names()

# Von der Festplatte laden
kommentare = read.delim("data/chisq_kommentare.txt", sep = "\t", fileEncoding = "UTF-8") %>% 
  clean_names()
head(kommentare) %>% knitr::kable()

```

##### Chi-Quadrat-Test

Stichproben: kurzer Kommentar vs. langer Kommentar

-   H0: Zwischen den beiden Stichproben besteht kein signifikanter Unterschied (Unterschiede zufällig).
-   H1: Zwischen den beiden Stichproben besteht ein signifikanter Unterschied (Unterschiede nicht zufällig).

```{r message=FALSE, warning=FALSE}
library(janitor)
chisq.test(kommentare[,-1])

```

Wir verwerfen H0 und nehmen H1 an: zwischen kurzen und langen Kommentaren besteht ein nicht zufälliger Unterschied.

##### Graphische Darstellung

```{r message=FALSE, warning=FALSE, paged.print=TRUE}
library(tidyverse)
library(scales)

kom_lang = kommentare %>% 
  as_tibble() %>% 
  pivot_longer(kurzer_kommentar:ausfuhrlicher_kommentar, 
               names_to = "Kommentar",
               values_to = "Fehler") %>% 
  mutate(pct = Fehler/sum(Fehler))

kom_lang %>% knitr::kable()

kom_lang  %>%  ggplot(aes(Kommentar, pct, fill = neugeschriebener_satz)) +
  geom_col(position = "dodge") +
  scale_y_continuous(labels = percent_format()) +
  labs(x = "Neugeschriebener Satz", y = "",
       title = "Wirksamkeit kurzer und langer Kommentare")

```

### Plural von Kunstwörtern

#### Programme laden

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(scales)
library(kableExtra)
```

#### Dateien laden

Für die Durchführung eines $\chi^2$-Tests solle eine Tabelle geladen werden, die Ergebnisse eines Experiments mit deutschen Kunstwörtern enthält, von denen slowenische Studierende der Germanistik den Plural bilden sollten. 

```{r message=FALSE, warning=FALSE}
# Branje datoteke je možno na več načinov
plural_subj1 = read.csv("data/plural_Subj_sum.csv", sep = ";")
plural_subj1 = read.csv2("data/plural_Subj_sum.csv")
plural_subj1 = read_csv2("data/plural_Subj_sum.csv")

# Pokaži prvih šest vrstic
head(plural_subj1) %>% knitr::kable()

```

#### Datensatz-Aggregation und Test

Zuerst müssen wir die Rohdaten in eine Tabelle umformen, so dass ein $\chi^2$-Test durchgeführt werden kann. Eine derartige Transformation eines Datensatzes wird oft als Aggregation bezeichnet (also eine Art von Zusammenfassung). In der neu gebildeten 2x2-Tabelle sind die Beobachtungsdaten (d.h. die Häufigkeiten oder Frequenzen) zu finden. Das Programm berechnet für uns die erwarteten Häufigkeiten (theoretischen Frequenzen) und bewertet dann, ob die Differenz zwischen den Stichproben statistisch signifikant ist.

Die statistischen Annahmen können folgendermaßen formuliert werden:   
- $H_0$: Die Versuchspersonen verwenden sowohl für Reimwörter als auch für Nicht-Reimwörter dieselben deutschen Pluralmarker. Der Worttyp hat demnach keinen Einfluss auf die Auswahl des Pluralmarkers.   
- $H_1$: Die Versuchspersonen verwenden für Reimwörter nicht dieselben deutschen Pluralmarker wie für Nicht-Reimwörterverschieden für die beiden Worttypen (Reimwort vs. Nicht-Reimwort). Der Worttyp hat demnach Einfluss auf die Auswahl des Pluralmarkers.   

Wenn der beim statistischen Test erhaltene p-Wert \< 0,05 ist (d.h. bei einer Fehlerwahrscheinlichkeit von weniger als 5%), dann gilt die alternative Hypothese $H_1$: die Differenz zwischen den beobachteten und den theoretisch erwarteten Häufigkeiten ist in diesem Fall statistisch signifikant, d.h. die Differenz ist nicht zufällig und bei 5% Fehlerwahrscheinlichkeit hinreichend groß.

Wenn der p-Wert jedoch p \> 0,05 ist, dann wird die Nullhypothese $H_0$ beibehalten. In diesem Fall wäre die Differenz nicht hinreichend groß und daher vermutlich zufällig entstanden (z.B. durch die geringe Größe der Stichproben oder die Auswahl der Stichprobendaten).

Im ersten statischen Test vergleichen wir die Häufigkeiten der Pluralmarker *--e* und *--s* miteinander.   

```{r message=FALSE, warning=FALSE}
# Povzemamo ("aggregate")
# Ergebnisse summieren
p = plural_subj1 %>% 
  group_by(WordType) %>% 
  summarise(Sigstark = mean(Sigstark),
            En = sum(En), E = sum(E), Er = sum(Er), 
            S = sum(S), Z = sum(Z)) 

# izpis tabele
knitr::kable(p)

# Izberemo tri stolpce
q = p %>% select(WordType, E, S)

# Razlika med deleži množinskih pripon E in S (npr. Bal-e oder Bal-s)
chisq.test(q[,-1]) # prvi stolpec naj se ne upošteva, zato [, -1]

```

#### Naslednji preizkus(i)

Wir machen noch einen $\chi^2$-Test mit einer 2x2-Tabelle, und zwar
mit den Pluralmarkern *--e* und *--er* durchgeführt.   

```{r message=FALSE, warning=FALSE}
# Izberemo tri stolpce za naslednji preizkus
q = p %>% select(WordType, E, Er)

# Razlika med deleži množinskih pripon E in Er (npr. Bal-e oder Bal-er)
chisq.test(q[,-1]) # prvi stolpec naj se ne upošteva, zato [, -1]

```

#### Tabela 2 x 3

Der $\chi^2$-Test kann auch mit größeren Tabellen durchgeführt werden, z.B. mit einer 2x3-Tabelle. Dies ermöglicht den Vergleich von mehr als zwei Stichproben.   

Der $\chi^2$-Test kann statistisch signifikante Unterschiede zwischen Stichproben melden, kann aber leider nicht darüber Auskunft oben, welche Stichprobe sich von den übrigen unterscheidet.   

```{r message=FALSE, warning=FALSE}
# Izberemo tri stolpce za naslednji preizkus
q = p %>% select(WordType, Er, E, S)

# Razlika med deleži množinskih pripon E in Er (npr. Bal-e oder Bal-er)
chisq.test(q[,-1]) # prvi stolpec naj se ne upošteva, zato [, -1]

```

#### Zweite Version

Es gibt verschiedene Wege, um die Rohdaten in eine Tabelle umzuformen, die für die Durchführung eines $\chi^2$-Tests geeignet ist. Hier folgt eine weitere Aggregationsvariante mit Hilfe von `tidyverse`-Funktionen. 
Zuerst gruppieren wir die Rohdaten nach der Spalte, in der die Versuchspersonen eingetragen sind. Dann lassen wir die Summe der ausgewählten Pluralmarker berechnen:

```{r message=FALSE, warning=FALSE}
(p = plural_subj1 %>% 
  group_by(WordType) %>% 
  summarise(En = sum(En), E = sum (E))
)
```

Falls p \< 0,05 ist, gilt $H_1$ (die Stichproben unterscheiden sich). Falls p \> 0,05 ist, gilt $H_0$ (kein signifikanter Unterschied zwischen Stichproben).   

```{r message=FALSE, warning=FALSE}
(chi = chisq.test(p[,-1])
)
```

Zum Schluss werfen wir noch einen Blick auf beobachtete und erwartete Häufigkeiten: 

```{r message=FALSE, warning=FALSE}
tabelle <- as_tibble(cbind(chi$observed, chi$expected)) %>%
    # Spalte wieder hinzufügen
   mutate(Wordtyp = unlist(p[,1])) %>%
   # auf deutsch
   mutate(Wordtyp = str_replace(Wordtyp, "NoRhyme", "Nicht-Reimwort"), 
          Wordtyp = str_replace(Wordtyp, "Rhyme", "Reimwort")) %>%
   # erwartete Werte, wenn H0 richtig ist
   rename(En_erwartet = V3, E_erwartet = V4) %>% 
   # Reihenfolge der Variablen verändern
   select(Wordtyp, En, E, En_erwartet, E_erwartet)

tabelle %>% rmarkdown::paged_table()
```

### Modalkonstruktionen 

In diesem Abschnitt wird die Vorkommenshäufigkeit (token frequency) der slowenischen Modalkonstruktionen *morati + Infinitiv* und *biti + treba + Infinitiv* in einer Auswahl von slowenischen Texten miteinander verglichen. Der statistische Vergleich wird mit dem $\chi^2$-Test durchgeführt. 

#### Packages

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(scales)
library(janitor)
library(readxl)
```

#### Datei laden

Bei Recherchen auf dem slowenischen *Gigafida*-Portal wurden Gebrauchsfrequenzen (Tokenfrequenzen) von zwei Modalkonstruktionen ermittelt, und zwar:   
- *morati + Infinitiv* und   
- *biti + treba + Infinitive*.   

Die erste Tabelle mit den Gebrauchsfrequenzen laden wir von der Festplatte: 

```{r message=FALSE, warning=FALSE}
naklonska <- read_xlsx("data/morati_treba.xlsx") %>% 
  clean_names()
naklonska
```

Die zweite Tabelle zeigt die Distribution der beiden Modalkonstruktionen in fünf Funktionalstilen.

```{r message=FALSE, warning=FALSE}
naklonska2 <- read_xlsx("data/morati_treba.xlsx", 
                        sheet = "List2") %>% clean_names()
naklonska2

```

Die Modalkonstruktion *morati + Infinitiv* wird ca. dreimal so häufig verwendet wie *biti + treba + Infinitiv*.

#### Graphische Darstellung

Die graphischen Darstellungen zeigen eher geringe Distributionsunterschiede.

```{r message=FALSE, warning=FALSE}
naklonska %>%
  pivot_longer(treba:morati, names_to = "konstruktion", 
               values_to = "freq") %>% 
  ggplot(aes(konstruktion, freq, fill = vrsta_besedila)) +
  geom_col(position = "fill") +
  scale_y_continuous(labels = percent_format()) +
  labs(x = "Modalkonstruktion", y = "Gebrauchsfrequenz", 
       fill = "Vrsta besedila")

```

Die Modalkonstruktion *morati + Infinitiv* scheint in den alltagssprachlich näherstehenden Funktionalstilen Belletristik (leposlovje), Internet und Sachtexten (stvarna besedila) etwas häufiger belegt zu sein als die Modalkonstruktion *biti + treba + Infinitiv*, dafür aber in Zeitungen (Časopisi) etwas seltener.

```{r message=FALSE, warning=FALSE}
naklonska2 %>%
  pivot_longer(treba:morati, names_to = "konstruktion", 
               values_to = "freq") %>% 
  ggplot(aes(konstruktion, freq, fill = vrsta_besedila)) +
  geom_col(position = "fill") +
  scale_y_continuous(labels = percent_format()) +
  labs(x = "Modalkonstruktion", y = "Gebrauchsfrequenz", 
       fill = "Vrsta besedila")

```

#### Chi-Quadrat-Test

Linguistische Annahme: Die Modalkonstruktion *morati + Infinitiv* ist weniger markiert (natürlicher) als die Modalkonstruktion *biti + treba + Infinitiv*.    

Formale Begründung: Die erste Konstruktion ist kürzer und daher ökonomischer als die zweite.   
Semantische Begründung: Die erste Konstruktion ist semantisch weniger spezifisch als die zweite.   
Dies sollte dazu führen, dass die erste Konstruktion in einer größeren Anzahl von Kontexten erscheint als die zweite.   

Die statistischen Annahmen lassen sich folgendermaßen formulieren:    
$H_0$: Die beiden Modalkonstruktionen kommen in denselben Funktionalstilen vor.    
$H_1$: Die beiden Modalkonstruktionen kommen nicht in denselben Funktionalstilen vor.

Der erste $\chi^2$-Test zeigt, dass die beiden Stichproben (*morati* vs. *treba*) unabhängig voneinander sind. Dies bestätigt der geringe p-Wert (p \< 0,001), der unterhalb dem Grenzwert von p = 0,05 (5%) liegt. Damit können wir die Nullhypothese ($H_0$) verwerfen und die alternative Hypothese ($H_1$) akzeptieren. Die beiden Modalkonstruktionen kommen demnach nicht im gleichen Maße in denselben Funktionalstilen vor.

```{r message=FALSE, warning=FALSE}
chisq.test(naklonska[ , -1])

```

Der zweite $@chi³2$-Test, der mit den Zahlenwerten der zweiten Tabelle durchgeführt wird, bestätigt Hypothese $H_1$. Die Distribution der beiden Modalkonstruktionen unterscheidet sich. Die graphische Darstellung deutet an, dass dies vor allem am vergleichsweise selteneren Gebrauch der (natürlicheren) Modalkonstruktion *morati + Infinitiv* in publizistischen Texten liegen könnte. Nach unser Annahme wird die (weniger natürliche) Modalkonstruktion *biti + treba + Infinitiv* häufiger in weniger natürlichen Textsorten mit dem Merkmal [+Distanz] eingesetzt.

```{r message=FALSE, warning=FALSE}
chisq.test(naklonska2[ , -1])

```


## Intervallskalierte Größen

Statistische Tests:

-   t-Test,

-   lineare Regression,

-   lineare Regression mit gemischten Effekten.


### Äußerungslänge in einer Kurzgeschichte

Im *Wikipedia*-[Artikel](https://de.wikipedia.org/wiki/Satzl%C3%A4nge#Durchschnittliche_Satzl%C3%A4nge) zum Thema *Satzlänge* (nach unserer Terminologie: *Äußerungslänge*) wird angegeben, dass die durchschnittliche Satzlänge in Prosatexten für literarische Prosa im 20. Jahrhundert gemäß [Best(2002)](https://de.wikipedia.org/wiki/Satzl%C3%A4nge#Durchschnittliche_Satzl%C3%A4nge) zwischen 7,08 und 19,62 Wörtern liegt. 

#### Programme und Tabelle laden

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(scales)
library(janitor)
library(readxl)
wiki_utter_length <- 
  read_xlsx("data/wikipedia_satzlaenge_durchschnitt.xlsx")
wiki_utter_length %>% rmarkdown::paged_table()
```

Roman-Dialoge weisen laut [Pieper(1979)](https://de.wikipedia.org/wiki/Satzl%C3%A4nge#Durchschnittliche_Satzl%C3%A4nge) einen Medianwert von 6,01 Wörtern auf, Roman-Nichtdialoge dagegen einen Medianwert von 12,98 Wörtern. Der Median ist ein Mittelwert, der genau in der Mitte aller Werte liegt: 50% aller Werte liegen unterhalb des Medians, 50% oberhalb davon. 

```{r message=FALSE, warning=FALSE}
wiki_utter_length_median <- 
  read_xlsx("data/wikipedia_satzlaenge_median.xlsx")
wiki_utter_length_median %>% rmarkdown::paged_table()
```

#### Hypothesen für den t-Test

Aufgrund der in den beiden Tabellen vorgestellten Mittelwerte gehen wir im Fall von *Borcherts* Kurzgeschichte *Die Küchenuhr* von der folgende *Nullhypothese* ($H_0$) aus:    
Die durchschnittliche Äußerungslänge beträgt so wie in literarischer Prosa etwa $\mu$ = 12 Wörter pro Äußerung. Die Kurzgeschichte ist ein Beispiel für literarische Prosa, in der auch Dialoge vorkommen. 
Die *Alternativhypothese* ($H_1$) besagt dagegen, dass das arithmetische Mittel (der Durchschnittswert) in Borcherts Kurzgeschichte von dem erwarteten Durchschnitt für literarische Prosa (mit Dialog- und Nicht-Dialog-Passagen) $\mu$ abweicht. 

Der t-Test wird auf folgende Weise berechnet:   

$$
t = \frac{m - \mu}{s/{\sqrt{n}}}
$$
- *m* ist der arithmetische Mittelwert der Stichprobe;   
- $\mu$ ist der arithmetische Mittelwert für literarische Prosa;   
- *n* ist die Stichprobengröße (d.h. die Anzahl der Äußerungen);   
- *s* ist die Standardabweichung mit $n - 1$ Freiheitsgraden. Da wir die Standardabweichung in der Grundgesamtheit $\sigma$ nicht kennen, sind wir bei diesem t-Test mit einer Stichprobe auf die Standardabweichung der Stichprobe $s$ (d.h. einer Zufallsvariable) angewiesen.    

Der *t-Wert* und der *p-Wert* werden bei *df* = $n - 1$ *Freiheitsgraden* berechnet. Falls der p-Wert < 0,05, verwerfen wir die Nullhypothese, liegt er dagegen oberhalb dieses Signifikanzniveaus, behalten wir die Nullhypothese bei.  


#### Textvorbereitung

Zuerst muss der Text geöffnet und dann in Äußerungen zerlegt werden. Dann kann `quanteda` die Anzahl der Tokens (d.h. Wörter + Interpunktionszeichen) zählen. Die Interpunktionszeichen werden hier der Einfachheit halber nicht herausgefiltert, so dass die ermittelten Zahlen etwas höher ausfallen. Für die Durchführung eines t-Test erstellen wir einen Datensatz, in dem die Wortanzahl (Tokenanzahl) für jede Äußerung auftritt. 

```{r message=FALSE, warning=FALSE}
library(quanteda)
library(quanteda.textstats)
# open the text file
borchert_kuechenuhr <- read_lines(
  "data/borchert/borchert_kuechenuhr.txt")
# create corpus
borchert_corp_basic <- corpus (borchert_kuechenuhr)
# corpus reshaped by utterances
borchert_corp_utter <- corpus_reshape(borchert_corp_basic, 
                                      to = "sentences")
# create a dataframe
borchert_df <- as.character(borchert_corp_utter) %>% 
  as.data.frame() %>% 
  rename(text = ".") %>% 
  rownames_to_column(., var = "doc_id")

# mandatory for t-test: count tokens per utterance
borchert_textstats <- summary(borchert_corp_utter, n = 130) %>% 
  rename(doc_id = Text)

# join both datasets
borchert_df_all <- left_join(borchert_df, borchert_textstats, 
                             by = "doc_id") %>% 
  filter(Tokens > 0)

# remove title and author from dataframe
# 109 sentences remain
borchert_df_all <- borchert_df_all %>% 
  filter(doc_id != "text1.1")
```


#### Durchführung des t-Tests

Nun führen wir den **Ein-Stichproben t-Test** durch. Dazu genügt der Datensatz *borchert_textstats*. 

```{r message=FALSE, warning=FALSE}
# install.packages("ggpubr")
library(ggpubr)
# remove 0 values and title
borchert_textstats <- borchert_textstats %>% 
  filter(Tokens > 0, doc_id != "text1.1")
# test
t.test(borchert_textstats$Tokens, mu = 12, alternative = "two.sided")
```

Das *Ergebnis*: Die durchschnittliche Äußerungslänge in Borcherts Kurzgeschichte (mean = 9,25 Wörter pro Äußerung) unterscheidet sich signifikant vom erwarteten arithmetischen Mittelwert für literarische Prosa $\mu$ = 12 Wörter. 

Der folgende t-Test wird mit dem vollständigen Datensatz *borchert_df_all* durchgeführt, aber dieses Mal mit der Nullhypothese, dass der Mittelwert *m* der Stichprobe gleich dem Mittelwert $\mu$ = 7,08 beträgt (d.h. der Untergrenze der Äußerungslänge literarischer Prosa). 

```{r message=FALSE, warning=FALSE}
# install.packages("ggpubr")
library(ggpubr)
t.test(borchert_df_all$Tokens, mu = 7.08, alternative = "two.sided")

```

Die durchschnittliche Äußerungslänge in Borcherts Kurzgeschichte unterscheidet sich demnach mit statistischer Signifikanz sowohl vom angenommenen Mittelwert $\mu$ = 12 Wörter für literarische Prosa als auch von der Untergrenze $\mu$ = 7,08 Wörter. 

Der schwarze Balken im Boxplot zeigt den Medianwert unserer Stichprobe (median = 9 Wlrter bzw. genauer: Tokens), der nur knapp unter dem arithmetischen Mittelwert liegt (mean = 9,29 Tokens). Die gestrichelten blauen Linien kennzeichnen die Ober- und Untergrenze der durchschnittlichen Äußerungslängen für literarische Prosa (s. Wikipedia-Tabelle oben). Genau 50% aller Äußerungslängen aus Borcherts Kurzgeschichte liegen im blauen Kasten. 

```{r message=FALSE, warning=FALSE}
borchert_df_all %>% 
  ggplot(aes(y = Tokens)) +
  geom_boxplot(fill = "cyan") + 
  geom_hline(yintercept = 19.62, color = "blue", lty = 3, size = 2) +
  geom_hline(yintercept = 7.08, color = "blue", 
             linetype = "dotted", size = 2)
```


### Wirkung von Unterrichtsmethoden

Welche Wirkung haben zwei verschiedene Unterrichtsmethoden auf die Ergebnisse von Sprachtests? Welche Gruppe von Studierenden erreichte eine höhere Punktzahl beim Test? 

Diese Frage soll mit Hilfe eines *t-Tests für zwei unabhängige Stichproben* geprüft werden. 

#### Data

```{r message=FALSE, warning=FALSE}
# Two teaching methods and the scores in a language test.
metode <- read.csv("data/ttest2a.csv", dec=",")
attach(metode)

head(metode)
```


#### Deskriptive Statistik

Arithmetische Mittelwerte beider Studentengruppen (Average scores of students): 

```{r message=FALSE, warning=FALSE}
tapply(Resultat, list(Methode), mean)
```

Standardabweichungen in beiden Studentengruppen (Standard deviations of averages): 

```{r message=FALSE, warning=FALSE}
tapply(Resultat, list(Methode), sd)
```

Graphische Darstellung

```{r message=FALSE, warning=FALSE}
barplot(tapply(Resultat, list(Methode), mean), col=c(3:2))
```

Flexiblere Gestaltung mit dem Programm `ggplot2`.

```{r message=FALSE, warning=FALSE}
metode %>% 
  ggplot(aes(Methode, Resultat, fill = Methode)) +
  geom_boxplot() +
  geom_jitter(width = 0.1) +
  theme(legend.position = "none")
```


#### Zwei-Stichproben t- Test

In diesem t-Test werden zwei die arithmetischen Mittelwerte von zwei Stichproben verglichen, die unabhängig voneinander sind. Eine Studentengruppe hatten Unterricht gemäß Methode A, die andere gemäß Methode B. Ist das durchschnittliche Ergebnis beider Gruppen gleich oder unterschiedlich?

Nullhypothese $H_0$: Die Ergebnisse beider Methoden unterscheiden sich nicht signifikant.    
Alternativhypothese $H_1$: Die Ergebnisse beider Mehtoden unterscheiden sich signifikant.   

```{r message=FALSE, warning=FALSE}
# Do the means of the two samples differ significantly?
# Hypothesis H0: they don't (if p > 0.05.
# Hypothesis H1: they do (if p < 0.05.
t.test(Resultat ~ Methode, data=metode, paired = F, var.equal = T)
```

*Ergebnis des t-Tests*: In unserem erfundenen Datensatz wird die Nullhypothese angenommen. Zwischen den Ergebnissen nach Methode A und B gab es keinen signifikanten Unterschied. Der *p-Wert* lag mit p = 0,7 oberhalb dem Signifikanzniveau von p = 0,05. 

Der t-test erfordert normalverteilte Daten. Ob Normalverteilung vorliegt, kann man    
- mit dem shapiro-Test oder    
- (meist zuverlässiger) mit Hilfe eines Histrogramms überprüfen. 

Die arithmetischen Mittelwert der Gruppe A sind gemäß dem Shapiro-Wilks-Test normalverteilt, denn p > 0,05. Bei einem p-Wert von weniger als 0,05 müssten wir die Nullhypothese, dass die Variable normalverteilt ist, verwerfen. 

```{r message=FALSE, warning=FALSE}
metode %>% 
  filter(Methode == "A") %>% 
  select(Resultat) %>% 
  pull() %>% 
  shapiro.test()
```

Die arithmetischen Mittelwert der Gruppe B sind gemäß dem Shapiro-Wilks-Test ebenfalls normalverteilt, denn p > 0,05.  

```{r message=FALSE, warning=FALSE}
metode %>% 
  filter(Methode == "B") %>% 
  select(Resultat) %>% 
  pull() %>% 
  shapiro.test()
```

Die beiden Dichte-Diagramme (oder Histogramme) bestätigen den Befund des Shapiro-Wilks-Tests, dass die Variable *Resultat* in beiden Gruppen (A und B) in etwa normalverteilt sind. Das ist eine der Voraussetzungen für die Durchführung des t-Tests. 

```{r message=FALSE, warning=FALSE}
metode %>% 
  filter(Methode == "A") %>% 
  ggplot(aes(Resultat)) + 
  geom_density() +
  geom_vline(xintercept = 31) # median

metode %>% 
  filter(Methode == "B") %>% 
  ggplot(aes(Resultat)) + 
  geom_density() +
  geom_vline(xintercept = 31) # median
```

Stellt man nun fest, dass die geprüfte Variable nicht normalverteilt ist, kann man auf nicht-parametrische Tests zurückgreifen, z.B. den *Mann-Whitney-Wilcoxon-Test* (auch: **Mann-Whitney U-Test**, **Wilcoxon Rangsummentest**) für zwei abhängige Stichproben (paired = TRUE) bzw. für zwei unabhängige Stichproben (paired = FALSE. 


#### Vergleich von Medianwerten

Für den Vergleich von *Medianwerten* von nicht-normal verteilten Daten kann man den nicht-parametrischen `wilcox.test()` [Nonparametric statistics](https://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/R/R-Manual/R-Manual16.html) verwenden, bei dem die Rangzahlen von zwei Stichproben addiert und verglichen werden (in unserem Beispiel: Resultate der Methode A und B). 

In Fall unserer erfundenen Stichproben (zwei Studentengruppen, die sich durch die Unterrichtsmethode unterscheiden), ist der *p-Wert* p = 1, also oberhalb des Signifikanzniveaus von p = 0,05. Die Alternativhypothese konnte nicht bestätigt werden. Wir akzeptieren die Nullhypothese, dass zwischen den Ergebnissen der beiden Unterrichtsmethoden kein signifikanter Unterschied vorliegt. 

```{r message=FALSE, warning=FALSE}
# create two separated datasets
metodeA <- subset(metode, Methode = "A")
metodeB <- subset(metode, Methode = "B")

# both median values are equal
median(metodeA$Resultat)
median(metodeB$Resultat)

# wilcox.test
wtest <- wilcox.test(metodeA$Resultat, metodeB$Resultat, paired=FALSE)
wtest
```

Mit der `summary()`-Funktion können wir den Medianwert, den Minimal- und Maximalwert sowie den interquartilen Bereich der Variable unseres erfundenen Datensatzes ausgeben lassen. 

```{r message=FALSE, warning=FALSE}
summary(metodeA$Resultat)
summary(metodeB$Resultat)
```

#### Effektstärke

##### Nicht-parametrisch

Der *Wilcoxon-Rangsummentest* (*Mann-Whitney U-Test*) hat zwar keinen signifikanten Unterschied angezeigt, aber man **Cohen's Effektstärke** [@cohen1992power] nach einem nicht-parametrischen Mann-Whitney-Wilcoxon Test folgendermaßen berechnen lassen: 

$$
r = \frac{z}{\sqrt{n}}
$$

Die Variable `r` ist Pearsons **Korrelationskoeffizient** (Pearson product-moment correlation), der die Assoziationsstärke (d.h. die Stärke des linearen Zusammenhangs) zwischen zwei Variablen angibt. Ein Z-Score `z` beschreibt das Verhältnis eines Wertes zum Mittelwert einer Gruppe von Werten. Der Z-Score wird in Form von Standardabweichungen vom Mittelwert gemessen. Die Variable `n` steht für die Stichprobengröße. 

```{r message=FALSE, warning=FALSE}
wil <- wilcox.test(Resultat ~ Methode, 
                   paired = FALSE, exact = FALSE, data = metode)
z <- qnorm(wil$p.value)
r <- z/sqrt(length(metode$Resultat))
r
```

Die Effektstärke für den Korrelationswert `r` = 0,14 (maximal r = 1) wird gemäß [@Cohen1992power] als schwache Effektstärke eingeschätzt (ab r = 0,3 moderate Effektstärke, ab r = 0,5 große Effektstärke). Der Unterschied zwischen den beiden Gruppen ist demnach nicht unbedingt zu vernachlässigen, da der (oben berechnete) nicht-signifikante `p`-Wert möglicherweise wegen einer zu kleinen Stichprobengröße zustande gekommen ist. 


##### Parametrisch

Die Effektstärke `d` kann man aus dem Unterschied zwischen den Mittelwerten, dividiert durch die *gepaarte Standardabweichung* `sd` (*pooled standard deviation*, berechnen:    
- `d` ist Cohens Effektstärke (*effect size*);    
- $means_1$, $means_2$ sind die beiden Mittelwerte,   
- $s_1$, $s_2$ die Standardabweichungen;    
- $n_1$, $n_2$ die Größen der beiden Stichproben.   

$$
d = \frac{mean_1 - mean_2}{\sqrt{(n_1-1)s_1^2 + (n_2-1)s_2^2}/{(n_1+n_2-2)}}
$$

Am schnellsten berechnet man die Effektstärke `d` wohl mit dem Programm `effectsize`. 

```{r message=FALSE, warning=FALSE}
library(effectsize)
coh <- cohens_d(Resultat ~ Methode, data = metode)
coh
```

Die geschätzte Effekstärke (d.h. der geschätzte Unterschied zwischen den beiden Gruppen in unserer Stichprobe) beträgt etwa d = 0,12 (ab d = 0,2 gilt meist: schwacher Effekt). Cohen's `d` sagt uns, wie viele Standardabweichungen zwischen den beiden Mittelwerten liegen. 

Manuelle Berechnung: 

```{r message=FALSE, warning=FALSE}
test <- t.test(Resultat ~ Methode, var.equal = T, data = metode)

# means
mean1 = as.numeric(test$estimate[1])
mean2 = as.numeric(test$estimate[2])

#find sample standard deviation of each sample
s1 <- sd(metode$Resultat[metode$Method == "A"])
s2 <- sd(metode$Resultat[metode$Method == "B"])

#find sample size of each sample
n1 <- length(metode$Resultat[metode$Method == "A"])
n2 <- length(metode$Resultat[metode$Method == "B"])

#calculate pooled standard deviation
pooled_sd <- sqrt(((n1-1)*s1^2 + (n2-1)*s2^2) / (n1+n1-2))

d = (mean1 - mean2)/pooled_sd
d
```

Teilweise manuelle Berechung, aber Berechnung der gepaarten Standardabweichung mit Hilfe des Programms `effectsize`: 

```{r message=FALSE, warning=FALSE}
library(effectsize)
pooled_sd <- sd_pooled(metode$Resultat[metode$Methode == "A"],
          metode$Resultat[metode$Methode == "B"])

mean1 = mean(metode$Resultat[metode$Methode == "A"])
mean2 = mean(metode$Resultat[metode$Methode == "B"])

d = (mean1 - mean2)/pooled_sd
d
```


#### Lineare Regression

Statt des t-Tests kann man bei Mittelwert-Vergleichen auch eine lineare Regression durchführen. Da wir es in diesem Fall mit nur einem Prädiktor (*Methode*) zu tun haben, sind die Ergebnisse der linearen Regression (etwa der p-Wert) gleich denen, die uns der t-Test gebracht hat. Darüber hinaus erhalten wir noch andere Informationen und erweitern Vergleichsmöglichkeiten. 

```{r message=FALSE, warning=FALSE}
# Check the same hypotheses with the linear regression method
# Since there is only one predictor ("Methode"), we obtain the same result as with the t-test.
# Since p > 0.05, the score means of the two methods do not differ significantly.
m <- lm(Resultat ~ Methode, data=metode)
summary(m)
```

```{r message=FALSE, warning=FALSE}
library(effects)
```

Predicted scores

```{r message=FALSE, warning=FALSE}
allEffects(m)
```

Das Diagramm zeigt deutlich, dass kein signifikanter Unterschied zwischen den Mittelwerten der Methoden A und B vorliegt: Die Konfidenzintervalle für beide arithmetische Mittelwerte überschneidet sich fast völlig und schließen damit den jeweiligen Mittelwert der anderen Methode ein. 

```{r message=FALSE, warning=FALSE}
plot(allEffects(m), multiline=TRUE, grid=TRUE, 
     rug=FALSE, as.table=TRUE)
```


Zum Abschluss dieses Kapitels: 

Zur unkomplizierten Visualisierung von Datensatzvariablen, ohne  programmieren zu müssen, eignet sich die `library(esquisse)`. Das Programm ermöglicht die Auswahl von Variablen mit der Maus. 

```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
library(esquisse)
esquisser(metode)

```

### Höflichkeit und Grundfrequenz

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(scales)
# detach("package:rlang", unload=TRUE)
```

Datensatz von: *Bodo Winter* [@winter2012phonetic; @winter2013linear]

Thema: Politeness and Pitch (F0)

Tutorials: 
- [Lineare Regression](http://www.bodowinter.com/tutorial/bw_LME_tutorial1.pdf)   
- [Lineare Regression mit gemischten Effekten](https://bodowinter.com/tutorial/bw_LME_tutorial.pdf)   

Artikel:   
[The phonetic profile of Korean formal and informal speech registers](https://www.academia.edu/5655036/The_phonetic_profile_of_Korean_formal_and_informal_speech_registers)   

Gliederung unserer quantitativen Analyse

1\. Laden der Datei

2\. Kennenlernen der Daten und Säubern

3\. Hypothesen

4\. Test und Ergebnisse

5\. Schluss


:::rmdnote 
Eine einfache `lineare Regression` oder einen `t-Test` kann man auch in *Excel* berechnen, aber in Statistikprogrammen ist das bequemer.
:::

#### Datei laden

```{r message=FALSE, warning=FALSE}
# politeness <- read.csv("/cloud/project/data/politeness_data.csv")
politeness <- read.csv("data/politeness_data.csv")

```

#### Kennenlernen der Daten und Säubern

Welche Variablen enthält die Datei?

```{r message=FALSE, warning=FALSE}
head(politeness)
  
```

Eine weitere Funktion, um die Datenstruktur zu betrachten:

```{r message=FALSE, warning=FALSE}
glimpse(politeness)
```

Und noch eine Übersicht, die uns noch mehr zeigt, z.B. ob bestimmte Datenzellen leer sind (NA). Die Variable `frequency` enthält eine leere Datenzelle (s. `n_missing`). Das müssen wir bei der Berechnung des Durchschnitts berücksichtigen.

```{r message=FALSE, warning=FALSE}
library(skimr)
skim(politeness)
```


Am Experiment nahmen 6 Versuchspersonen teil (F1, ..., M7). Von jeder Versuchsperson (subject) haben wir 14 Messpunkte (n = 14).

```{r message=FALSE, warning=FALSE}
politeness %>% 
  count(subject)
```

Versuchspersonen: 3 weibliche und 3 männliche.

```{r message=FALSE, warning=FALSE}
politeness %>% 
  count(subject, gender)
```

Pro Verhaltensweise (attitude) stehen uns 42 Messpunkte zur Verfügung, um unsere (unten folgende) Hypothese zu überprüfen.

```{r message=FALSE, warning=FALSE}
politeness %>% 
  count(attitude)
```

Berechnen wir mal die Grundfrequenz!

```{r message=FALSE, warning=FALSE}
politeness %>% 
  mean(frequency)
```

`NA`: Hoppla! In unserer Datenreihe fehlt eine Frequenz. In solch einem Fall haben wir zwei Möglichkeiten: entweder entfernen wir diese Datenzeile aus unserer Berechnung oder wir lassen unser Programm eine Schätzung des Wertes vornehmen, die aber an der Datendistribution und am Mittelwert nichts verändert. Letzteres machen wir mit einer *impute*-Funktion, die beispielsweise den Medianwert für den fehlend Datenpunkt einsetzt.

Entfernen der leeren Datenzelle (`NA`) ist die einfachste Lösung, um die durchschnittliche Frequenz mit `mean()` berechnen zu können. Das erledigen wir mit der `tidyverse`-Funktion `drop_na()`.

```{r message=FALSE, warning=FALSE}
politeness %>% 
  drop_na(frequency) %>%
  summarise(av_freq = mean(frequency))
```

Eine andere Möglichkeit, eine leere Datenzeile aus der Mittelwertberechnung zu entfernen,  ist die Option `na.rm = TRUE` zur `mean()`-Funktion hinzuzufügen. 

```{r message=FALSE, warning=FALSE}
politeness %>% 
  summarise(av_freq = mean(frequency, na.rm = TRUE))
```

Wir haben gerade die Durchschnittsfrequenz für alle Versuchspersonen berechnet. Berechnen wir sie nun getrennt nach weiblichen und männlichen Versuchspersonen! Zu diesem Zweck müssen wir vor der Mittelwertberechnung die Daten mit der `group_by()`-Funktion gruppieren. 

```{r message=FALSE, warning=FALSE}
politeness %>% 
  drop_na(frequency) %>%
  group_by(gender) %>% 
  summarise(av_freq = mean(frequency))
```

Erwartungsgemäß ist der Durchschnittswert bei Frauen höher als bei Männern: Frauen haben ja meist eine höhere Stimme als Männer.

Ein Blick auf die Durchschnittsfrequenzen bei höflicher und informeller Sprechweise: In unserer Stichprobe mit 6 Versuchspersonen (je 14 Frequenzmessungen) zeigt sich ein Unterschied von etwa 18,2 Hz, und zwar 202,59 - 184,36. Um zu diesem Ergebnis zu gelangen, haben wir vor der `summarise()`-Funktion die `group_by()`-Funktion entsprechend angewandt.  

```{r message=FALSE, warning=FALSE}
politeness %>% 
  drop_na() %>% 
  group_by(attitude) %>% 
  summarise(avg_freq = mean(frequency),
            sd_freq = sd(frequency))

```

```{r message=FALSE, warning=FALSE}
# politeness %>% 
#   drop_na %>% 
#   transmute(attitude, frequency) %>% 
#   mutate(attitude = str_replace(attitude, "pol", "1"),
#          attitude = str_replace(attitude, "inf", "0")) %>% 
#   mutate(attitude = parse_number(attitude))

```

#### Hypothesen

-   $H_0$: Der durchschnittliche Grundfrequenzverlauf (F0) bei höflichem oder informellem *Sprechverhalten* (*attitude*) ist *gleich*.

-   $H_1$: Der durchschnittliche Grundfrequenzverlauf (F0) bei höflichem *Sprechverhalten* *unterscheidet* sich vom informellen.

Nach unserem bisherigen Wissen erwarten wir, dass unsere Daten die Hypothese $H_1$ bestätigen werden.

Das überprüfen wir zunächst mit einem t-Test, anschließend mit einer linearen Regression.

#### t-Test

Zunächst ein Blick auf die Durchschnittsfrequenzen bei höflicher und informeller Sprechweise. In unserer Stichprobe mit 6 Versuchspersonen (je 14 Frequenzmessungen) zeigt sich ein Unterschied von etwa 18,2 Hz.

Gemäß Hypothese $H_1$ ist der Unterschied nicht zufällig entstanden, sondern kann auf die Gesamtpopulation der Sprecher verallgemeinert werden.

Nicht so gemäß Hypothese $H_0$: Der Mittelwertunterschied zwischen den Stichproben kann zufällig entstanden sein, denn wenn wir eine andere Stichprobe genommen hätten, wäre der Unterschied vielleicht gleich Null gewesen.

Mit statistischen Tests können wir diese beiden Hypothesen überprüfen. Einer davon ist der *t-Test*.

```{r message=FALSE, warning=FALSE}
politeness %>% 
  drop_na() %>% 
  group_by(attitude) %>% 
  summarise(avg_freq = mean(frequency),
            sd_freq = sd(frequency))

```

Die Varianzen und damit auch die Standardabweichungen (`sd_freq`) vom Mittelwert (`avg_freq`) sind in beiden Gruppen (`inf` und `pol`) ungefähr gleich groß. Beim t-Test können wir dies berücksichtigen, und zwar mit der Option `var.equal = TRUE`. Die Option `paired = FALSE` besagt, dass die beiden Gruppen unabhängig vom Messzeitpunkt sind.

Der t-Test bestätigt $H_1$ nicht (p \> 0,05):

```{r message=FALSE, warning=FALSE}
t.test(frequency ~ attitude, data = politeness, 
       paired = FALSE, var.equal = TRUE)
```

Eine weitere Form, wie man den t-Test durchführen könnte. In den eckigen Klammern wird eine Bedingung oder Filter formuliert. 

```{r message=FALSE, warning=FALSE}
# frequencies if polite
pol = politeness$frequency[politeness$attitude == "pol"]
# frequencies if informal
inf = politeness$frequency[politeness$attitude == "inf"]
t.test(pol, inf, var.equal = TRUE)

```

Oder eine dritte (längere) Variante, den t-Test durchzuführen:

```{r message=FALSE, warning=FALSE}
polite <- politeness %>% 
  select(attitude, frequency) %>% 
  filter(attitude == "pol") %>% 
  select(-attitude)

informal <- politeness %>% 
  select(attitude, frequency) %>% 
  filter(attitude == "inf") %>% 
  select(-attitude)

t.test(polite, informal, var.equal = TRUE)

```

Wenn man die Option `var.equal = TRUE` nicht angibt, wird der *Welch-t-Test* durchgeführt, d.h. das Programm geht davon aus, dass die Varianzen (bzw. Standardabweichungen) der beiden Gruppen sich signifikant unterscheiden.


#### Lineare Regression

Mit dem *t-Test* konnten wir immer nur die Wirkung einer Variablen (z.B. attitude) auf den Frequenzverlauf prüfen. Mit einem linearen *Regressionsmodell* können wir dagegen die gleichzeitige Wirkung mehrerer Größen auf den Frequenzverlauf herausfinden. Eine lineare Regression hat den großen Vorteil, dass man mehr als eine unabhängige Variable (Prädiktor) verwenden kann, um eine Hypothese zu testen. 

Wir wählen *Geschlecht* (`gender`) und *Sprechverhalten* (`attitude`) als **unabhängige** Variablen, der *Grundfrequenzverlauf* (`frequency`) als **abhängige** Variable.

Die grundlegende Formulierung des Programmcodes (für eventuelle Vergleiche mit anderen Modellversionen haben wir dem Modell auch den neuen Namen "m1" gegeben): 

```{r message=FALSE, warning=FALSE}
m <- lm(frequency ~ gender + attitude, data = politeness)
m1 <- m 
summary(m)
```

Wie *liest* man die **Regressionsergebnisse**?^[https://moderndive.com/6-multiple-regression.html#model4interactiontable]    
Beginnen wir am Ende! Die *F-Statistik* am Ende besagt, dass das Regressionsmodell insgesamt gesehen einen signifikanten Beitrag zur Erklärung des Frequenzverlaufs leistet, denn der sehr kleine p-Wert (p-value: < 2.2e-16) liegt deutlich unter dem 5% Signifikanzniveau.   

Die vorletzte Zeile gibt den $R^2$-Wert (*Bestimmtheitsmaß*) an, also wie viel Prozent der gesamten Varianz der abhängigen Variable (frequency) vom Modell erklärt wird (hier: 0,71, demnach 71 % bzw. mit *adjusted* $R^2$ mehr als 70%, wenn die Korrektur berücksichtigt wird, die bei Einbezug mehr als einer unabhängigen Variable gilt und immer etwas niedriger ist).   

Der *Intercept* oder Konstante ist die Stelle, an der die Frequenzkurve die y-Achse schneidet (also die Ordinate). In diesem Fall beträgt der Wert etwa 257 Hz. Der Intercept-Wert ist meistens nicht sinnvoll interpretierbar (auch hier nicht). Aber wenn wir das unten folgende Diagramm *gender effect plot* betrachten und in Gedanken die Linie von dem Punkt für die weiblichen Versuchspersonen (*F*) in Richtung y-Achse verlängern, dann können wir uns vorstellen, dass die Linie etwa beim Wert 257 die y-Achse schneidet. Der Intercept ist somit der (mathematisch festgelegte) Basiswert für die weiblichen Versuchspersonen. Die weiblichen Versuchspersonen werden als Basis verwendet, weil das Programm alphabetisch vorgeht und *F* im Alphabet vor *M* erscheint. 

Der Koeffizient für *genderM* zeigt an, dass bei männlichen Versuchspersonen 108,35 Hz vom Basiswert der weiblichen Versuchspersonen (256,762) subtrahiert werden müssen. Das ist der Intercept für die männlichen Versuchspersonen. Der p-Wert ist erwartungsgemäß hochsignifikant (p < 2e-16), denn die meisten Männer haben eine tiefere Stimme als Frauen.    

In der nächsten Zeile folgt der Koeffizient für *attitudepol* (polite). Der Koeffizient (-19,553) ist negativ und muss daher vom Basiswert, dem Intercept für die weiblichen Versuchspersonen (256,762), subtrahiert werden. Demnach ist die Tonlage beim höflichen Sprechverhalten (attitudepol) um 19,55 Hz tiefer als beim informellen Sprechverhalten. Der p-Wert ist signifikant (p = 0,0146).  

Grundfrequenz für *Frauen* bei *informellem* Sprechen:    
256.762 + (-108.349)\*0 + (-19.553)\*0 = 256.762 Hz
Grundfrequenz für *Frauen* bei *höflichem* Sprechen:    
256.762 + (-108.349)\*0 + (-19.553)\*1 = 237.209 Hz

Grundfrequenz für *Männer* bei *informellem* Sprechen:    
256.762 + (-108.349)\*1 + (-19.553)\*0 = 148.413 Hz
Grundfrequenz für *Männer* bei *höflichem* Sprechen:    
256.762 + (-108.349)\*1 + (-19.553)\*1 = 128.86 Hz

*Durchschnittliche* Grundfrequenz bei *informellem* Sprechen (Frauen + Männer):   
(256.762 + 148.413)/2 = 202.5875 Hz. 
*Durchschnittliche* Grundfrequenz bei *höflichem* Sprechen: (Frauen + Männer):    
(237.209 + 128.86)/2 = 183.0345 Hz. 

Das lineare Regressionsmodell **bestätigt** somit die Hypothese $H_1$: F(2;80 = 98,38; p \< 0,001). Die Versuchspersonen sprechen demnach in einer tieferen Tonlage, wenn sie höflich sprechen, und zwar um ca. 19,5 Hz tiefer als wenn sie informell sprechen (p = 0,0146).

Außerdem bestätigt das Regressionsmodell (erwartungsgemäß) auch, dass die männlichen Versuchspersonen mit einer tieferen Stimme sprechen als die weiblichen, und zwar um durchschnittlich 108 Hz. Aber da uns das bereits aus unserer Alltagserfahrung bekannt ist, interessiert uns dieses Ergebnis nicht.


Das Bestimmtheitmaß, d.h. der $R^2$-Wert, beträgt 0,71 (d.h. etwa 71%). Das bedeutet, dass mit dem Regressionsergebnis ca. 71% der Variabilität unserer abhängigen Variable (frequency) erklärt wird. Das ist ein guter Wert in den Sozialwissenschaften.

Das Regressionsmodell wollen wir auch mit Hilfe Programms `effects` graphisch veranschaulichen. 

```{r message=FALSE, warning=FALSE}
library(effects)
allEffects(m)
plot(allEffects(m), multiline=TRUE, grid=TRUE, rug=FALSE, as.table=TRUE, confint=list(style="bars"), x.var = "gender")
```

Man kann Regressionsmodelle auch mit `tidyverse`-Funktionen formulieren (der "." bedeutet, dass der Datensatz "politeness" aus der vorherigen Zeile übernommen werden soll). Die `tidy(()`-Funktion des `broom`-Pakets sorgt für die Umformung in eine Tabelle. 

```{r message=FALSE, warning=FALSE}
library(broom)
politeness %>% 
  lm(frequency ~ attitude + gender, data = .) %>% 
  summary() %>% 
  broom::tidy()
```

Die unterschiedliche Tonlage bei informellem und höflichem Sprechen veranschaulichen wir noch mit einem *Boxplot*. 

```{r message=FALSE, warning=FALSE}
politeness %>% 
  ggplot(aes(attitude, frequency, 
             group = attitude, fill = attitude)) +
  geom_boxplot() +
  stat_summary(fun.y=mean, geom="point", 
               shape="*", size=7, color="red", fill="red") + 
  geom_jitter(width = 0.2) + 
  # geom_hline(yintercept = c(202.5), 
  #            lty = 2, col = "darkred") + # Polite-Mittelwert
  # geom_hline(yintercept = c(184.3), 
             # lty = 2, col = "darkgreen") + # Informal-Mittelwert
  facet_wrap(~ gender)
```

Der *rote Stern* markiert den *Durchschnittswert* der jeweiligen Gruppe, der *schwarze Balken* den *Median* (d.h. den Wert, der genau in der Mitte aller Daten der jeweiligen Gruppe liegt). Im *Kasten* eines **Boxplots** liegen 50% aller Werte, darunter liegen 25% und darüber ebenfalls 25%. Bei den Männern (M) ist zu sehen, dass der Median (der schwarze Balken) und das arithmetische Mittel (der rote Stern) nicht übereinstimmen. Das deutet auf extremere Unterschiede zwischen den männlichen Versuchspersonen (Schiefe oder Asymmetrie). 

Die *Schiefe* (engl. *skewness*) oder Asymmetrie der Frequenzverteilung (Distribution) kann man in einem **Histogramm** oder Dichte-Diagramm (density) veranschaulichen. Das Histogram der weiblichen Versuchspersonen ist der Normalverteilung (einer Glockenform, mit den meisten Frequenzwerten in der Mitte) ähnlich, während das der männlichen deutlich schief ist. 

```{r message=FALSE, warning=FALSE}
politeness %>% 
  ggplot(aes(frequency, fill = attitude)) +
  geom_density(alpha = 0.7) + 
  facet_wrap(~ gender)

politeness %>% 
  ggplot(aes(frequency, fill = attitude)) +
  geom_histogram(aes(y = ..count..), # density
                 binwidth = 50, alpha = 0.7, color = "white") + 
  facet_wrap(~ gender)

politeness %>% 
  filter(gender == "F") %>% 
  ggplot(aes(frequency)) +
  geom_histogram(aes(y = ..density.., fill = attitude), # count
                 binwidth = 50, alpha = 0.7, color = "white") +
  stat_function(
    fun = dnorm, 
    args = list(
      mean = mean(
        politeness$frequency[politeness$gender == "F"], na.rm = T), 
      sd = sd(politeness$frequency[politeness$gender == "F"], 
              na.rm = T)), 
    col = "#1b98e0", 
    size = 2)

politeness %>% 
  filter(gender == "M") %>% 
  ggplot(aes(frequency)) +
  geom_histogram(aes(y = ..density.., fill = attitude), # count
                 binwidth = 50, alpha = 0.7, color = "white") +
  stat_function(
    fun = dnorm, 
    args = list(
      mean = mean(
        politeness$frequency[politeness$gender == "M"], na.rm = T), 
      sd = sd(politeness$frequency[politeness$gender == "M"], 
              na.rm = T)), 
    col = "#1b98e0", 
    size = 2)
```


Wird das Sprechverhalten (attitude) durch das Geschlecht (gender) modifiziert (z.B. verändern Frauen ihre Tonlage beim höflichem Sprechen, Männer dagegen nicht oder kaum)? Das kann man durch *Hinzufügung eines Interaktionsterms* prüfen. Eine Interaktion kennzeichnet man in der Regressionsgleichung mit einem Stern zwischen den beteiligten Variablen (also wie beim Multiplizieren). Hier prüfen wir die **Interaktion** zwischen den beiden unabhängigen Variablen *Geschlecht* (gender) und *Verhalten* (attitude). 

Die *Indikatorterme* *attitude* (informal vs. polite) und *gender* (female vs. male), beide also mit zwei Stufen oder levels, sind vergleichbar mit An-/Aus-Schaltern. Sie zeigen an, um welchen Wert die Frequenzkurve nach unten (bei negativem Koeffizient) oder oben (bei positivem Koeffizient) verschoben wird. Der *Interaktionsterm* der beiden Indikatorterme zeigt an, um welchen *zusätzlichen* Wert der Frequenzverlauf verändert wird. Wäre eine kontinuierliche Variable (z.B. Zeit) in der Interaktion einbezogen, dann würde der Koeffizient der Interaktion die zusätzliche Steigung (slope) der abhängigen Variable anzeigen. 

```{r message=FALSE, warning=FALSE}
m <- lm(frequency ~ attitude*gender, data = politeness)
m2 <- m 
summary(m)
```

Allerdings ist der p-Wert für die Interaktion in unserem Fall nicht signifikant (p = 0,3135 liegt oberhalb des 5% Signifikanzniveaus, p = 0,05). Das bedeutet, dass die Interaktion zur Erklärung des Frequenzverlaufs keinen Beitrag leistet. Daher ist es sinnvoll, den Interaktionsterm aus der Regressionsgleichung zu entfernen und nur die (signifkanten) Haupteffekte beizubehalten. Wir bevorzugen demnach immer das einfachere Modell, wenn das komplexere keinen signifikanten Erklärungsbeitrag leistet. 

Mit der `anova()`-Funktion kann man Regressionsmodelle (hier: *m1* und *m2*) miteinander vergleichen und prüfen, welches geeigneter ist, den Frequenzverlauf zu erklären. Modell m1 ist das Modell ohne Interaktion, Modell m2 das Modell mit Interaktionsterm. 

```{r message=FALSE, warning=FALSE}
anova(m1, m2)
```

Der p-Wert (p = 0,3135) ist nicht signifikant. In diesem Fall bevorzugen wir das einfachere Regressionsmodell, d.h. das Modell ohne Interaktion (m1). 

Mit Hilfe des Programms `effects` stellen wir das Regressionsmodell mit hinzugefügter **Interaktion** zwischen den beiden unabhängigen Variablen *Geschlecht* (gender) und *Verhalten* (attitude) auch graphisch dar. 

```{r message=FALSE, warning=FALSE}
library(effects)
allEffects(m)
plot(allEffects(m), multiline=TRUE, grid=TRUE, rug=FALSE, as.table=TRUE, confint=list(style="bars"), x.var = "gender")

```

Die sich überschneidenden Konfidenzintervalle im Diagramm zeigen, dass die Durchschnittswerte keinen signifikanten Unterschied aufweisen. Außerdem gilt sowohl für die weiblichen als auch die männlichen Versuchspersonen, dass Frequenzwerte beim höflichen Sprechverhalten geringer sind. Die Interaktion liefert somit keinen signifikanten Erklärungsbeitrag. Es ist sinnvoll, nur die beiden Haupteffekte beizubehalten und die Interaktion aus dem Regressionsmodell herauszunehmen. 

Das nächste Diagramm bestätigt, dass die Variablen Geschlecht (gender) und Verhalten (attitude) mit statistischer Signifikanz die Höhe des Grundfrequnezverlaufs (frequency) beeinflussen, nicht jedoch die Interaktion beider Variablen (deren Konfidenzintervall überschreitet im Diagramm die Null-Linie).

```{r message=FALSE, warning=FALSE}
library(parameters)
library(see)
p1 = plot(parameters(m)) +
  ggplot2::labs(title = "A Dot-and-Whisker Plot")
p1
```

Das nächste Diagramm bestätigt, dass die Residuen (d.h. die jeweiligen Abweichungen der einzelnen Werte vom Durchschnitt) normalverteilt sind (p = 0.396, also größer als der Grenzwert 0.05). Damit ist eine der erforderlichen Bedingungen für die Durchführung einer linearen Regression erfüllt. 

```{r message=FALSE, warning=FALSE}
library(performance)
check <- check_normality(m)
## Warning: Non-normality of residuals detected (p = 0.016).

p2 = plot(check, type = "qq")
p2
```


```{r message=FALSE, warning=FALSE}
library(performance)
check <- check_normality(m, effects = "fixed")
## Warning: Non-normality of residuals detected (p = 0.016).

p2a = plot(check, type = "pp")
p2a
```

$Omega^2$ ist eine alternative Größe zu $R^2$, womit ebenfalls die erklärte Varianz eines linearen Regressionsmodells angegeben wird. Im Diagramm ist zu sehen, dass die Variable *Geschlecht* (gender) den größten Beitrag leistet (fast 70%), die Variable *Verhalten* (attitude) ca. 5%, während die Interaktion beider Variablen keinen signifikanten Beitrag zu Erklärung der Varianz leistet (Wert liegt bei 0%).

```{r message=FALSE, warning=FALSE}
library(effectsize)
library(see)

m <- aov(frequency ~ attitude*gender, data = politeness)

p3 = plot(omega_squared(m))
p3
```

Das nächste Diagramm zeigt die Verteilung der Daten für die beiden Geschlechter.

```{r message=FALSE, warning=FALSE}
p4 = ggplot(politeness, aes(x = attitude, y = frequency, color = gender)) +
  geom_point2() +
  theme_modern()
p4
```

Weitere Darstellungsmöglichkeiten der Datendistribution:

```{r message=FALSE, warning=FALSE}
p4 = ggplot(politeness, 
            aes(x = attitude, y = frequency, fill = gender)) +
  geom_violin() +
  theme_modern(axis.text.angle = 45) +
  scale_fill_material_d(palette = "ice")

p4

```

```{r message=FALSE, warning=FALSE}
p5 = ggplot(politeness, 
            aes(x = attitude, y = frequency, fill = gender)) +
  geom_violindot(fill_dots = "black") +
  geom_jitter(width = 0.05) +
  theme_modern() +
  scale_fill_material_d()
p5
```

Ob die Bedingungen für die Durchführung einer linearen Regression erfüllt sind, kann man mit einem Befehl ausführen, und zwar mit Hilfe des Programms `performance`. Hier wählen wir die Funktion `check_model()` mit dem Modell ohne Interaktion (da diese nicht signifikant war). 

```{r message=FALSE, warning=FALSE, out.width="100%", out.height="100%"}
library(performance)
m <- lm(frequency ~ attitude + gender, data = politeness)
summary(m)

check <- check_model(m)

p6 = plot(check)
p6

```

Collage mehrerer der oben einzeln gezeigten Diagramme mit Hilfe der `plots()`-Funktion im Programm `performance`:

```{r message=FALSE, warning=FALSE}
plots(p1,p2,p3,p4, 
      n_columns = 2, 
      tags = paste0("B", 1:4))
```

Eine Bayesianische Regressionsberechnung erlauben die Programmen `bayestestR` und `rstanarm`. Mit dem Programm `see` können wir die Datendistribution sichtbar machen. 

```{r message=FALSE, warning=FALSE}
library(bayestestR)
library(rstanarm)
library(see)

set.seed(123)
m <- stan_glm(frequency ~ attitude + gender, 
              data = politeness, refresh = 0)
result <- hdi(m, ci = c(0.5, 0.75, 0.89, 0.95))
plot(result)
```


#### Ergebnis

Die Regressionsanalyse hat $H_1$ bestätigt, d.h. die Grundfrequenz beim höflichen Sprechverhalten unterscheidet sich vom informellen Sprechen. Beim höflichen Sprechen sprachen die Versuchspersonen mit einer durchschnittlich 19,5 Hz tieferen Stimme: bei den weiblichen Versuchspersonen mehr als 27 Hz (261 - 233 Hz), bei den männlichen mehr als 11 Hz (144 - 133 Hz)).


#### Lineare Regression

Politeness data (B. Winter tutorial)

Programme laden: 

```{r message=FALSE, warning=FALSE}
library(tidyverse)

```


Datei laden: 

```{r message=FALSE, warning=FALSE}
# LOAD
polite <- read.csv("data/politeness_data.csv", dec=".")

```

Ansicht der Datenlage zu Orientierungszwecken: 

```{r message=FALSE, warning=FALSE}
head(polite)
```

Variablentyp festlegen: 

```{r message=FALSE, warning=FALSE}
polite$frequency = as.numeric(polite$frequency)
polite$scenario = as.factor(polite$scenario)
polite$subject = as.factor(polite$subject)
polite$gender = as.factor(polite$gender)
polite$attitude = as.factor(polite$attitude)

```

Kontraste für den statistischen Test setzen: 

```{r message=FALSE, warning=FALSE}
# In this session we use contr. sum contrasts
options(contrasts=c('contr.sum', 'contr.poly'))
options("contrasts")
```

Kontraste zurücksetzen: 

```{r message=FALSE, warning=FALSE}
# To reset default settings run: 
options(contrasts=c('contr.treatment', 'contr.poly')) 
# (all afex functions should be unaffected by this)

# # Setting contrasts of chosen variables only
# contrasts(polite$attitude) <- contr.treatment(2, base = 1)
 
```

Einfacher Boxplot: 

```{r message=FALSE, warning=FALSE}
boxplot(frequency ~ attitude*gender, 
        col=c("red","green"), data = polite)
```

Bild speichern:   
- z.B. im *jpg*-Format oder    
- im *pdf*-Format.   

```{r message=FALSE, warning=FALSE}
# 1. Open jpeg file
jpeg("pictures/politeness_boxplot.jpg", 
     width = 840, height = 535)
# 2. Create the plot
boxplot(frequency ~ attitude*gender, 
        col=c("red","green"), data = polite) 
# 3. Close the file
dev.off()
```

```{r message=FALSE, warning=FALSE}
# Open a pdf file
pdf("pictures/politeness_boxplot.pdf") 
# 2. Create a plot
boxplot(frequency ~ attitude*gender, 
        col=c("red","green"), data = polite) 
# Close the pdf file
dev.off() 
```

Beziehungen zwischen Variablenpaaren anzeigen: 

```{r message=FALSE, warning=FALSE}
library(psych)
pairs.panels(polite[c(2,4,5)])
```

Lineare Regression mit mehreren unabhängigen Variablen und einer abhängigen Variable, im Englischen auch als *Ordinary Least Squares Regression (OLS)* bekannt.   

Mit allen unabhängigen Variablen: 

```{r message=FALSE, warning=FALSE}
# model 1
m <- lm(frequency ~ gender + attitude + subject + scenario, data = polite)
summary(m)
```

Regression mit denjenigen Variablen, die als Prädiktoren für die abhängige Variable gewählt wurden:    

```{r message=FALSE, warning=FALSE}
# model 2
m <- lm(frequency ~ gender + attitude, data=polite)
summary(m)
```

Koeffizienten der Variablen anzeigen: 

```{r message=FALSE, warning=FALSE}
library(effects)
allEffects(m)
```

Visuelle Darstellung der Regressionsergebnisse: 

```{r message=FALSE, warning=FALSE}
plot(allEffects(m), multiline=TRUE, grid=TRUE, rug=FALSE, as.table=TRUE)
```

Bild sichern: 

```{r message=FALSE, warning=FALSE}
# Save plot of the effects to disk
# 1. Open jpeg file
jpeg("pictures/politeness_lineplot.jpg", 
     width = 840, height = 535)
# 2. Create the plot
plot(allEffects(m), multiline=TRUE, grid=TRUE, rug=FALSE, as.table=TRUE)
# 3. Close the file
dev.off()
```

Ein weiteres Regressionsmodell mit einer Interaktion zwischen den unabhängigen Variablen (Prädiktoren): 

```{r message=FALSE, warning=FALSE}
# model 3 (with interaction)
m <- lm(frequency ~ gender*attitude, data=polite)
summary(m)
```

Koeffizienten der Variablen anzeigen: 

```{r message=FALSE, warning=FALSE}
library(effects)
allEffects(m)
```

Visuelle Darstellung der Regressionsergebnisse: 

```{r message=FALSE, warning=FALSE}
plot(allEffects(m), multiline=TRUE, grid=TRUE, rug=FALSE, as.table=TRUE)
```

Bild als *jpg*-Datei sichern: 

```{r message=FALSE, warning=FALSE}
# Save plot of the effects to disk
# 1. Open jpeg file
jpeg("pictures/politeness_effects.jpg", 
     width = 840, height = 535)
# 2. Create the plot
plot(allEffects(m), multiline=TRUE, grid=TRUE, rug=FALSE, as.table=TRUE)
# 3. Close the file
dev.off()
```

Bild als *pdf*-Datei sichern: 

```{r message=FALSE, warning=FALSE}
# Open a pdf file
pdf("pictures/politeness_effects.pdf") 
# 2. Create a plot
plot(allEffects(m), multiline=TRUE, grid=TRUE, rug=FALSE, as.table=TRUE)
# Close the pdf file
dev.off() 
```

Diagnostische Analyse (sind die Bedingungen für eine Regression erfüllt?): 

```{r message=FALSE, warning=FALSE}
# plot diagnostic diagrams
par(mfrow = c(3,2))
plot(m, which = 1) # variance of residuals vs. fitted values?
plot(m, which = 2) # normal distributed residuals?
plot(m, which = 3) # variance of residuals standardized
plot(m, which = 4) # Cook's distance (outliers / influencing data points?)
plot(m, which = 5) # Leverage vs. standardized variance of residuals
plot(m, which = 6) # Cook's distance vs. Leverage
par(mfrow = c(1,1))

```

Entfernung eines Datenpunktes und die dabei entstehende Veränderung des Koeffizienten: 

```{r message=FALSE, warning=FALSE}
# Change of estimates if one datapoint is removed from the model
d <- dfbetas(m)
head(d) %>% as.data.frame %>% rmarkdown::paged_table()
```

Koeffizienten visuell darstellen: 

```{r message=FALSE, warning=FALSE}
# plot the dfbetas (are there any outliers or data points with high influence?)
par(mfrow = c(1,3))
plot(d[,1], col = "orange")
plot(d[,2], col = "blue")
plot(d[,3], col = "purple")
par(mfrow = c(1,1))
```


#### Regression mit gemischten Effekten

(Mixed effects Regression, Multilevel Regression)

Programme laden: 

```{r message=FALSE, warning=FALSE}
# The variables 'subject' and 'scenario' have been chosen as random effects
library(afex)
library(lmerTest)
library(LMERConvenienceFunctions)
```

Regressionsmodell mit einem individuell variierenden Intercept (Ordinate): 

```{r message=FALSE, warning=FALSE}
# random intercepts model
m <- lmer(frequency ~ 
            (1|subject), 
          REML=F, data=politeness)
m0.1 <- m
summary(m)
```

Regressionsmodell mit zwei individuell variierenden Intercepts (Ordinaten): 

```{r message=FALSE, warning=FALSE}
# random intercepts model
m <- lmer(frequency ~ 
            (1|subject) + (1|scenario), 
          REML=F, data=politeness)
m0.2 <- m
summary(m)
```

Regressionsmodell mit zwei individuell variierenden Intercepts (Ordinaten) und einer kategorischen Variable: 

```{r message=FALSE, warning=FALSE}
# random intercepts model
m <- lmer(frequency ~ gender + 
            (1|subject) + (1|scenario), 
          REML=F, data=politeness)
m1 <- m
summary(m)
```

Regressionsmodell mit zwei individuell variierenden Intercepts (Ordinaten) und zwei Prädiktoren, zwei kategorischen Variablen. Von Interesse ist die Variable *attitude* (hier: sprachliches Verhalten). 

```{r message=FALSE, warning=FALSE}
m <- lmer(frequency ~ gender + attitude + 
          (1|subject) + (1|scenario), 
          REML=F, data=politeness)
m2 <- m
summary(m)
```

Regressionsmodell mit zwei individuell variierenden Intercepts (Ordinaten) und zwei interagierenden Prädiktoren. Von Interesse ist die Variable *attitude*. 

```{r message=FALSE, warning=FALSE}
m <- lmer(frequency ~ gender*attitude + 
            (1|subject) + (1|scenario), 
          REML=F, data=politeness)
m3 <- m
summary(m)
```

Mit dem Programm `jtools` erhält man die Regressionsergebnisse in übersichtlicherer Form und mit zusätzlichen Größenberechnungen:  

```{r message=FALSE, warning=FALSE}
library(jtools)
summ(m3)
```

Vergleich der Modelle:

```{r message=FALSE, warning=FALSE}
anova(m0.1, m0.2,m1,m2,m3)
```

Mit Hilfe der `anova()`-Funktion kann man eine Anova-Tabelle erstellen. 

```{r message=FALSE, warning=FALSE}
anova(m3)
```

Die *Anova* (mit Grundfrequenz als abhängige Variable, Geschlecht, Verhalten und ihrer Interaktion als Prädiktoren sowie Versuchspersonen und Szenario als Zufallsvariablen) ergab *Geschlecht* als signifikanten Haupteffekt (F(1; 5,929) = 38,0164; p = 0,0009; $\eta_{p}^2$ = 0,87) und *Verhalten* als signifikanten Haupteffekt auf die Höhe der Grundfrequenz (F(1; 70,925) = 12,8536; p = 0,0006; $\eta_{p}^2$ = 0,15). Die *Interaktion* zwischen Geschlecht und Verhalten war nicht signifikant (F(1; 70,925) = 2,0239; p = 0,15923; $\eta_{p}^2$ = 0,03). 

Das Pseudo-$R^2$ für die Koeffizienten der Prädiktoren beträgt 0,71 (d.h. 71% der Varianz der Grundfrequenz wurden mit den Prädiktoren erklärt), das Pseudo-$R^2$ für die Koeffizienten aller Effekte (fixed effects + random effects) beträgt 0,857 (d.h. mit allen Variablen wurden fast 86% der Grundfrequenzvariation erklärt). 

Der Post-hoc-Test für die *Interaktion* von Geschlecht und Verhalten ergab außerdem signifikant Unterschiede zwischen weiblichen und männlichen Testpersonen hinsichtlich der Grundfrequenzhöhe, und zwar sowohl bei informellen Sprechen (p = 0,0003) als auch bei höflichem Sprechen (p = 0,001). Da unter beiden Bedingungen (informelles vs. höfliches sprachliches Verhalten) ein signifikante Unterschied zwischen weiblichen und männlichen Versuchspersonen festgestellt wurde, führte die Interaktion beider Prädiktoren zu keinem signifikanten Einfluss auf den Verlauf der Grundfrequenz. 

Die $\eta^2$-Funktion: 

```{r message=FALSE, warning=FALSE}
library(sjstats)
eta_sq(m3, partial = TRUE)
library(effectsize)
eta_squared(m3, partial = TRUE)
```

Die Pseudo-$R^2$-Funktion: 

```{r message=FALSE, warning=FALSE}
library(MuMIn)
r.squaredGLMM(m3)
```

Der Post-hoc-Test für die Interaktion von Geschlecht und Verhalten: 

```{r message=FALSE, warning=FALSE}
library(emmeans)
emmeans(m3, pairwise ~ gender)

# with interaction
emmeans(m3, pairwise ~ gender | attitude)
```

Die oben berechneten Regressionsmodelle berücksichtigen die beiden Zufallsvariablen (random effects) Versuchsperson und Szenario. Damit berücksichtigen wir interindividuelle Unterschiede zwischen den Testpersonen und Unterschiede zwischen den verschiedenen Szenarien, die alle die Höhe der Grundfrequenz beeinflussen könnten. Dies ergibt individuelle Regressionskonstanten (Intercepts) für die einzelnen Versuchspersonen und Szenarien.

Unterscheiden sich die Versuchspersonen nun auch darin, dass z.B. bestimmte Szenarien sie eher zu Grundfrequenzvariationen bewegen, d.h. die Steigung des Regressionskoeffizienten individuell beeinflussen (*random slope*)?

Zuerst stellen wir ein Basismodell mit individuellen Steigungskoeffizienten auf: 

```{r message=FALSE, warning=FALSE}
# politeness affected pitch (χ2(1)=11.62, p=0.00065), 
# lowering it by about 19.7 Hz ± 5.6 (standard errors) 

# random slopes model
m <- lmer(frequency ~ gender + 
            (attitude + 1|subject) + (1|scenario), 
          REML=F, data=politeness)
m00 <- m
summary(m)
```

Dann fügen wir die uns interessierende Variable *attitude* hinzu: 

```{r message=FALSE, warning=FALSE}
m <- lmer(frequency ~ gender + attitude + 
          (1|subject) + (attitude + 1|scenario), 
          REML=F, data=politeness)
m01 <- m
summary(m)
```

Wenn das Regressionsmodell mit den individuell variierenden Steigungskoeffizienten nicht berechnet werden kann, könnte auch ein Modell mit nur einem individuell variierenden Intercept in Frage kommen, z.B. diesem hier: 

```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
m <- lmer(frequency ~ gender + attitude + 
            (attitude + 1|subject), 
          REML=F, data=polite)
```

Eine weitere mögliche Variante mit nur einem individuell variierenden Steigungskoeffizienten: 

```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
m <- lmer(frequency ~ gender + attitude + 
            (attitude + 1|scenario), 
          REML=F, data=polite)
```

Die Steigungskoeffizienten: 

```{r message=FALSE, warning=FALSE}
m <- m01
library(effects)
allEffects(m)
```

Visuelle Darstellung der Regressionsergebnisse: 

```{r message=FALSE, warning=FALSE}
plot(allEffects(m), multiline=TRUE, grid=TRUE, rug=FALSE, as.table=TRUE)
```

Das volle Regressionsmodell mit zwei individuell variierenden Intercepts und einem individuell variierenden Steigungskoeffizienten sowie einer Interaktion zweier kategorieller Prädiktoren: 

```{r message=FALSE, warning=FALSE}
m <- lmer(frequency ~ gender*attitude + 
            (1|subject) + (attitude + 1|scenario), 
          REML=F, data=politeness)
```

Die Regressionsergebnisse: 

```{r message=FALSE, warning=FALSE}
m02 <- m
summary(m)
library(jtools)
summ(m)
```

*Vergleich der Modelle*:   
Das Modell m02 (mit Interaktion) ist nicht signifikant besser als Modell m01 (ohne Interaktion). Demnach entscheiden wir uns für das einfachere Regressionsmodell (d.h. ohne Interaktion). Beide Modelle weisen individuell variierende Intercepts (random intercepts) und einen individuell variierenden Steigungskoeffizienten (random slope) auf.   

```{r message=FALSE, warning=FALSE}
anova(m00,m01,m02)
```

Die `step()`-Funktion ermittelt (mittels Rückwärtseliminierung nicht signifikanter Variablen) die entsprechenden Bestandteile der Regressionsgleichung: 

```{r message=FALSE, warning=FALSE}
library(lmerTest)
s <- step(m)
s
```

**Diagnostik** mit Hilfe des Programms `library(LMERConvenienceFunctions)` am Beispiel des Modells ohne Interaktion, aber mit individuell variierenden Intercetps und Steigungskoeffizienten: 

```{r message=FALSE, warning=FALSE}
m <- lmer(frequency ~ gender + attitude + 
            (1|subject) + (attitude + 1|scenario), 
          REML=F, data=politeness)
m01 <- m
summary(m)
```


```{r message=FALSE, warning=FALSE}
library(LMERConvenienceFunctions)
# Check model asumptions
mcp.fnc(m)
```

Das Programm `library(performance)` hat ebenfalls mehrere Funktionen, um zu überprüfen, ob die Bedingungen für die Durchführung der linearen Regression erfüllt sind: 

```{r message=FALSE, warning=FALSE}
library(performance)
model_parameters(m)
model_performance(m)
check_normality(m)
check_heteroscedasticity(m)
check_collinearity(m)
check_distribution(m)
# check_model(m)
```

Überprüfung der Varianzhomogenität (für Regression ohne gemischte Effekte): 

```{r message=FALSE, warning=FALSE}
fligner.test(frequency ~ attitude, politeness)
```

```{r message=FALSE, warning=FALSE}
fligner.test(frequency ~ gender, politeness)
```

Überprüfung auf Normalität der abhängigen Variable mit Hilfe eines statistischen Tests, der aber bei großen Stichproben nicht zuverlässig ist: 

```{r message=FALSE, warning=FALSE}
shapiro.test(politeness$frequency)
```

Welcher Datenpunkt fehlt im Datensatz?

```{r message=FALSE, warning=FALSE}
which(is.na(politeness$frequency)) 
```

Entfernen des fehlenden Datenpunktes aus dem Datensatz: 

```{r message=FALSE, warning=FALSE}
# delete NA from data frame in row 39
polite1 <- politeness[-39,]
```

Programmfunktion, die Ausreißer (outlier) im Datensatz feststellt und entfernt: 

```{r message=FALSE, warning=FALSE}
# Remove outliers
freqout <- romr.fnc(m, polite1, trim=2.5)
```

Anzahl der entfernten Ausreißer: 

```{r message=FALSE, warning=FALSE}
freqout$n.removed
```

Anteil der entfernten Ausreißer: 

```{r message=FALSE, warning=FALSE}
freqout$percent.removed
```

Auswahl des neuen Datensatzes, aus dem die Ausreißer entfernt wurden: 

```{r message=FALSE, warning=FALSE}
freqout <- freqout$data
attach(freqout)
```

Regression mit dem Datensatz, aus dem die Ausreißer entfernt wurden: 

```{r message=FALSE, warning=FALSE}
# update model
m <- lmer(frequency ~ gender + attitude + 
            (1|subject) + (1|scenario), 
          REML=F, data=freqout)
m01 <- m
summary(m)
library(jtools)
summ(m)
```

Erneute Überprüfung der Varianzhomoskedastizität (Gleichförmigkeit der Varianz) und Normalität der Residuen (Abweichungen vom Mittelwert): 

```{r message=FALSE, warning=FALSE}
# Re-Check model asumptions
mcp.fnc(m)
```

Andere Varianztests (vor allem für Regression ohne gemischte Effekte geeignet): 

```{r message=FALSE, warning=FALSE}
fligner.test(frequency ~ attitude, freqout)
```

```{r message=FALSE, warning=FALSE}
fligner.test(frequency ~ gender, freqout)
```

Normalitätstest (geeignet für kleinere Stichproben): 

```{r message=FALSE, warning=FALSE}
shapiro.test(freqout$frequency)
```



```{r message=FALSE, warning=FALSE}
politeness %>% 
  drop_na() %>% 
  group_by(gender, attitude) %>% 
  summarise(M = mean(frequency))
```

