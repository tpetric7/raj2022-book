## Intervallskalierte Größen

Statistische Tests:

-   t-Test,

-   lineare Regression,

-   lineare Regression mit gemischten Effekten.


### Äußerungslänge in einer Kurzgeschichte

Im *Wikipedia*-[Artikel](https://de.wikipedia.org/wiki/Satzl%C3%A4nge#Durchschnittliche_Satzl%C3%A4nge) zum Thema *Satzlänge* (nach unserer Terminologie: *Äußerungslänge*) wird angegeben, dass die durchschnittliche Satzlänge in Prosatexten für literarische Prosa im 20. Jahrhundert gemäß [Best(2002)](https://de.wikipedia.org/wiki/Satzl%C3%A4nge#Durchschnittliche_Satzl%C3%A4nge) zwischen 7,08 und 19,62 Wörtern liegt. 

#### Programme und Tabelle laden

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(scales)
library(janitor)
library(readxl)
wiki_utter_length <- 
  read_xlsx("data/wikipedia_satzlaenge_durchschnitt.xlsx")
wiki_utter_length %>% rmarkdown::paged_table()
```

Roman-Dialoge weisen laut [Pieper(1979)](https://de.wikipedia.org/wiki/Satzl%C3%A4nge#Durchschnittliche_Satzl%C3%A4nge) einen Medianwert von 6,01 Wörtern auf, Roman-Nichtdialoge dagegen einen Medianwert von 12,98 Wörtern. Der Median ist ein Mittelwert, der genau in der Mitte aller Werte liegt: 50% aller Werte liegen unterhalb des Medians, 50% oberhalb davon. 

```{r message=FALSE, warning=FALSE}
wiki_utter_length_median <- 
  read_xlsx("data/wikipedia_satzlaenge_median.xlsx")
wiki_utter_length_median %>% rmarkdown::paged_table()
```

#### Hypothesen für den t-Test

Aufgrund der in den beiden Tabellen vorgestellten Mittelwerte gehen wir im Fall von *Borcherts* Kurzgeschichte *Die Küchenuhr* von der folgende *Nullhypothese* ($H_0$) aus:    
Die durchschnittliche Äußerungslänge beträgt so wie in literarischer Prosa etwa $\mu$ = 12 Wörter pro Äußerung. Die Kurzgeschichte ist ein Beispiel für literarische Prosa, in der auch Dialoge vorkommen. 
Die *Alternativhypothese* ($H_1$) besagt dagegen, dass das arithmetische Mittel (der Durchschnittswert) in Borcherts Kurzgeschichte von dem erwarteten Durchschnitt für literarische Prosa (mit Dialog- und Nicht-Dialog-Passagen) $\mu$ abweicht. 

Der t-Test wird auf folgende Weise berechnet:   

$$
t = \frac{m - \mu}{{s}/{\sqrt{n}}}
$$
- *m* ist der arithmetische Mittelwert der Stichprobe;   
- $\mu$ ist der arithmetische Mittelwert für literarische Prosa;   
- *n* ist die Stichprobengröße (d.h. die Anzahl der Äußerungen);   
- *s* ist die Standardabweichung mit $n - 1$ Freiheitsgraden. Da wir die Standardabweichung in der Grundgesamtheit $\sigma$ nicht kennen, sind wir bei diesem t-Test mit einer Stichprobe auf die Standardabweichung der Stichprobe $s$ (d.h. einer Zufallsvariable) angewiesen.    

Der *t-Wert* und der *p-Wert* werden bei *df* = $n - 1$ *Freiheitsgraden* berechnet. Falls der p-Wert < 0,05, verwerfen wir die Nullhypothese, liegt er dagegen oberhalb dieses Signifikanzniveaus, behalten wir die Nullhypothese bei.  


#### Textvorbereitung

Zuerst muss der Text geöffnet und dann in Äußerungen zerlegt werden. Dann kann `quanteda` die Anzahl der Tokens (d.h. Wörter + Interpunktionszeichen) zählen. Die Interpunktionszeichen werden hier der Einfachheit halber nicht herausgefiltert, so dass die ermittelten Zahlen etwas höher ausfallen. Für die Durchführung eines t-Test erstellen wir einen Datensatz, in dem die Wortanzahl (Tokenanzahl) für jede Äußerung auftritt. 

```{r message=FALSE, warning=FALSE}
library(quanteda)
library(quanteda.textstats)
# open the text file
borchert_kuechenuhr <- read_lines(
  "data/borchert/borchert_kuechenuhr.txt")
# create corpus
borchert_corp_basic <- corpus (borchert_kuechenuhr)
# corpus reshaped by utterances
borchert_corp_utter <- corpus_reshape(borchert_corp_basic, 
                                      to = "sentences")
# create a dataframe
borchert_df <- as.character(borchert_corp_utter) %>% 
  as.data.frame() %>% 
  rename(text = ".") %>% 
  rownames_to_column(., var = "doc_id")

# mandatory for t-test: count tokens per utterance
borchert_textstats <- summary(borchert_corp_utter, n = 130) %>% 
  rename(doc_id = Text)

# join both datasets
borchert_df_all <- left_join(borchert_df, borchert_textstats, 
                             by = "doc_id") %>% 
  filter(Tokens > 0)

# remove title and author from dataframe
# 109 sentences remain
borchert_df_all <- borchert_df_all %>% 
  filter(doc_id != "text1.1")
```


#### Durchführung des t-Tests

Nun führen wir den **Ein-Stichproben t-Test** durch. Dazu genügt der Datensatz *borchert_textstats*. 

```{r message=FALSE, warning=FALSE}
# install.packages("ggpubr")
library(ggpubr)
# remove 0 values and title
borchert_textstats <- borchert_textstats %>% 
  filter(Tokens > 0, doc_id != "text1.1")
# test
t.test(borchert_textstats$Tokens, mu = 12, alternative = "two.sided")
```

Das *Ergebnis*: Die durchschnittliche Äußerungslänge in Borcherts Kurzgeschichte (mean = 9,25 Wörter pro Äußerung) unterscheidet sich signifikant vom erwarteten arithmetischen Mittelwert für literarische Prosa $\mu$ = 12 Wörter. 

Der folgende t-Test wird mit dem vollständigen Datensatz *borchert_df_all* durchgeführt, aber dieses Mal mit der Nullhypothese, dass der Mittelwert *m* der Stichprobe gleich dem Mittelwert $\mu$ = 7,08 beträgt (d.h. der Untergrenze der Äußerungslänge literarischer Prosa). 

```{r message=FALSE, warning=FALSE}
# install.packages("ggpubr")
library(ggpubr)
t.test(borchert_df_all$Tokens, mu = 7.08, alternative = "two.sided")

```

Die durchschnittliche Äußerungslänge in Borcherts Kurzgeschichte unterscheidet sich demnach mit statistischer Signifikanz sowohl vom angenommenen Mittelwert $\mu$ = 12 Wörter für literarische Prosa als auch von der Untergrenze $\mu$ = 7,08 Wörter. 

Der schwarze Balken im Boxplot zeigt den Medianwert unserer Stichprobe (median = 9 Wlrter bzw. genauer: Tokens), der nur knapp unter dem arithmetischen Mittelwert liegt (mean = 9,29 Tokens). Die gestrichelten blauen Linien kennzeichnen die Ober- und Untergrenze der durchschnittlichen Äußerungslängen für literarische Prosa (s. Wikipedia-Tabelle oben). Genau 50% aller Äußerungslängen aus Borcherts Kurzgeschichte liegen im blauen Kasten. 

```{r message=FALSE, warning=FALSE}
borchert_df_all %>% 
  ggplot(aes(y = Tokens)) +
  geom_boxplot(fill = "cyan") + 
  geom_hline(yintercept = 19.62, color = "blue", lty = 3, size = 2) +
  geom_hline(yintercept = 7.08, color = "blue", 
             linetype = "dotted", size = 2)
```


### Wirkung von Unterrichtsmethoden

Welche Wirkung haben zwei verschiedene Unterrichtsmethoden auf die Ergebnisse von Sprachtests? Welche Gruppe von Studierenden erreichte eine höhere Punktzahl beim Test? 

Diese Frage soll mit Hilfe eines *t-Tests für zwei unabhängige Stichproben* geprüft werden. 

#### Data

```{r message=FALSE, warning=FALSE}
# Two teaching methods and the scores in a language test.
metode <- read.csv("data/ttest2a.csv", dec=",")
attach(metode)

head(metode)
```


#### Deskriptive Statistik

Arithmetische Mittelwerte beider Studentengruppen (Average scores of students): 

```{r message=FALSE, warning=FALSE}
tapply(Resultat, list(Methode), mean)
```

Standardabweichungen in beiden Studentengruppen (Standard deviations of averages): 

```{r message=FALSE, warning=FALSE}
tapply(Resultat, list(Methode), sd)
```

Graphische Darstellung

```{r message=FALSE, warning=FALSE}
barplot(tapply(Resultat, list(Methode), mean), col=c(3:2))
```

Flexiblere Gestaltung mit dem Programm `ggplot2`.

```{r message=FALSE, warning=FALSE}
metode %>% 
  ggplot(aes(Methode, Resultat, fill = Methode)) +
  geom_boxplot() +
  geom_jitter(width = 0.1) +
  theme(legend.position = "none")
```


#### Zwei-Stichproben t- Test

In diesem t-Test werden zwei die arithmetischen Mittelwerte von zwei Stichproben verglichen, die unabhängig voneinander sind. Eine Studentengruppe hatten Unterricht gemäß Methode A, die andere gemäß Methode B. Ist das durchschnittliche Ergebnis beider Gruppen gleich oder unterschiedlich?

Nullhypothese $H_0$: Die Ergebnisse beider Methoden unterscheiden sich nicht signifikant.    
Alternativhypothese $H_1$: Die Ergebnisse beider Mehtoden unterscheiden sich signifikant.   

```{r message=FALSE, warning=FALSE}
# Do the means of the two samples differ significantly?
# Hypothesis H0: they don't (if p > 0.05.
# Hypothesis H1: they do (if p < 0.05.
t.test(Resultat ~ Methode, data=metode, paired = F, var.equal = T)
```

*Ergebnis des t-Tests*: In unserem erfundenen Datensatz wird die Nullhypothese angenommen. Zwischen den Ergebnissen nach Methode A und B gab es keinen signifikanten Unterschied. Der *p-Wert* lag mit p = 0,7 oberhalb dem Signifikanzniveau von p = 0,05. 

Der t-test erfordert normalverteilte Daten. Ob Normalverteilung vorliegt, kann man    
- mit dem shapiro-Test oder    
- (meist zuverlässiger) mit Hilfe eines Histrogramms überprüfen. 

Die arithmetischen Mittelwert der Gruppe A sind gemäß dem Shapiro-Wilks-Test normalverteilt, denn p > 0,05. Bei einem p-Wert von weniger als 0,05 müssten wir die Nullhypothese, dass die Variable normalverteilt ist, verwerfen. 

```{r message=FALSE, warning=FALSE}
metode %>% 
  filter(Methode == "A") %>% 
  select(Resultat) %>% 
  pull() %>% 
  shapiro.test()
```

Die arithmetischen Mittelwert der Gruppe B sind gemäß dem Shapiro-Wilks-Test ebenfalls normalverteilt, denn p > 0,05.  

```{r message=FALSE, warning=FALSE}
metode %>% 
  filter(Methode == "B") %>% 
  select(Resultat) %>% 
  pull() %>% 
  shapiro.test()
```

Die beiden Dichte-Diagramme (oder Histogramme) bestätigen den Befund des Shapiro-Wilks-Tests, dass die Variable *Resultat* in beiden Gruppen (A und B) in etwa normalverteilt sind. Das ist eine der Voraussetzungen für die Durchführung des t-Tests. 

```{r message=FALSE, warning=FALSE}
metode %>% 
  filter(Methode == "A") %>% 
  ggplot(aes(Resultat)) + 
  geom_density() +
  geom_vline(xintercept = 31) # median

metode %>% 
  filter(Methode == "B") %>% 
  ggplot(aes(Resultat)) + 
  geom_density() +
  geom_vline(xintercept = 31) # median
```

Stellt man nun fest, dass die geprüfte Variable nicht normalverteilt ist, kann man auf nicht-parametrische Tests zurückgreifen, z.B. den *Mann-Whitney-Wilcoxon-Test* (auch: **Mann-Whitney U-Test**, **Wilcoxon Rangsummentest**) für zwei abhängige Stichproben (paired = TRUE) bzw. für zwei unabhängige Stichproben (paired = FALSE. 


#### Vergleich von Medianwerten

Für den Vergleich von *Medianwerten* von nicht-normal verteilten Daten kann man den nicht-parametrischen `wilcox.test()` [Nonparametric statistics](https://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/R/R-Manual/R-Manual16.html) verwenden, bei dem die Rangzahlen von zwei Stichproben addiert und verglichen werden (in unserem Beispiel: Resultate der Methode A und B). 

In Fall unserer erfundenen Stichproben (zwei Studentengruppen, die sich durch die Unterrichtsmethode unterscheiden), ist der *p-Wert* p = 1, also oberhalb des Signifikanzniveaus von p = 0,05. Die Alternativhypothese konnte nicht bestätigt werden. Wir akzeptieren die Nullhypothese, dass zwischen den Ergebnissen der beiden Unterrichtsmethoden kein signifikanter Unterschied vorliegt. 

```{r message=FALSE, warning=FALSE}
# create two separated datasets
metodeA <- subset(metode, Methode = "A")
metodeB <- subset(metode, Methode = "B")

# both median values are equal
median(metodeA$Resultat)
median(metodeB$Resultat)

# wilcox.test
wtest <- wilcox.test(metodeA$Resultat, metodeB$Resultat, paired=FALSE)
wtest
```

Mit der `summary()`-Funktion können wir den Medianwert, den Minimal- und Maximalwert sowie den interquartilen Bereich der Variable unseres erfundenen Datensatzes ausgeben lassen. 

```{r message=FALSE, warning=FALSE}
summary(metodeA$Resultat)
summary(metodeB$Resultat)
```

#### Effektstärke

##### Nicht-parametrisch

Der *Wilcoxon-Rangsummentest* (*Mann-Whitney U-Test*) hat zwar keinen signifikanten Unterschied angezeigt, aber man **Cohen's Effektstärke** [@cohen1992power] nach einem nicht-parametrischen Mann-Whitney-Wilcoxon Test folgendermaßen berechnen lassen: 

$$
r = \frac{z}{\sqrt{n}}
$$

Die Variable `r` ist Pearsons **Korrelationskoeffizient** (Pearson product-moment correlation), der die Assoziationsstärke (d.h. die Stärke des linearen Zusammenhangs) zwischen zwei Variablen angibt. Ein Z-Score `z` beschreibt das Verhältnis eines Wertes zum Mittelwert einer Gruppe von Werten. Der Z-Score wird in Form von Standardabweichungen vom Mittelwert gemessen. Die Variable `n` steht für die Stichprobengröße. 

```{r}
wil <- wilcox.test(Resultat ~ Methode, 
                   paired = FALSE, exact = FALSE, data = metode)
z <- qnorm(wil$p.value)
r <- z/sqrt(length(metode$Resultat))
r
```

Die Effektstärke für den Korrelationswert `r` = 0,14 (maximal r = 1) wird gemäß [@Cohen1992power] als schwache Effektstärke eingeschätzt (ab r = 0,3 moderate Effektstärke, ab r = 0,5 große Effektstärke). Der Unterschied zwischen den beiden Gruppen ist demnach nicht unbedingt zu vernachlässigen, da der (oben berechnete) nicht-signifikante `p`-Wert möglicherweise wegen einer zu kleinen Stichprobengröße zustande gekommen ist. 


##### Parametrisch

Die Effektstärke `d` kann man aus dem Unterschied zwischen den Mittelwerten, dividiert durch die *gepaarte Standardabweichung* `sd` (*pooled standard deviation*, berechnen:    
- `d` ist Cohens Effektstärke (*effect size*);    
- $means_1$, $means_2$ sind die beiden Mittelwerte,   
- $s_1$, $s_2$ die Standardabweichungen;    
- $n_1$, $n_2$ die Größen der beiden Stichproben.   

$$
d = \frac{mean_1 - mean_2}{\sqrt{(n_1-1)s_1^2 + (n_2-1)s_2^2}/{(n_1+n_2-2)}}
$$

Am schnellsten berechnet man die Effektstärke `d` wohl mit dem Programm `effectsize`. 

```{r}
library(effectsize)
coh <- cohens_d(Resultat ~ Methode, data = metode)
coh
```

Die geschätzte Effekstärke (d.h. der geschätzte Unterschied zwischen den beiden Gruppen in unserer Stichprobe) beträgt etwa d = 0,12 (ab d = 0,2 gilt meist: schwacher Effekt). Cohen's `d` sagt uns, wie viele Standardabweichungen zwischen den beiden Mittelwerten liegen. 

Manuelle Berechnung: 

```{r}
test <- t.test(Resultat ~ Methode, var.equal = T, data = metode)

# means
mean1 = as.numeric(test$estimate[1])
mean2 = as.numeric(test$estimate[2])

#find sample standard deviation of each sample
s1 <- sd(metode$Resultat[metode$Method == "A"])
s2 <- sd(metode$Resultat[metode$Method == "B"])

#find sample size of each sample
n1 <- length(metode$Resultat[metode$Method == "A"])
n2 <- length(metode$Resultat[metode$Method == "B"])

#calculate pooled standard deviation
pooled_sd <- sqrt(((n1-1)*s1^2 + (n2-1)*s2^2) / (n1+n1-2))

d = (mean1 - mean2)/pooled_sd
d
```

Teilweise manuelle Berechung, aber Berechnung der gepaarten Standardabweichung mit Hilfe des Programms `effectsize`: 

```{r}
library(effectsize)
pooled_sd <- sd_pooled(metode$Resultat[metode$Methode == "A"],
          metode$Resultat[metode$Methode == "B"])

mean1 = mean(metode$Resultat[metode$Methode == "A"])
mean2 = mean(metode$Resultat[metode$Methode == "B"])

d = (mean1 - mean2)/pooled_sd
d
```


#### Lineare Regression

Statt des t-Tests kann man bei Mittelwert-Vergleichen auch eine lineare Regression durchführen. Da wir es in diesem Fall mit nur einem Prädiktor (*Methode*) zu tun haben, sind die Ergebnisse der linearen Regression (etwa der p-Wert) gleich denen, die uns der t-Test gebracht hat. Darüber hinaus erhalten wir noch andere Informationen und erweitern Vergleichsmöglichkeiten. 

```{r message=FALSE, warning=FALSE}
# Check the same hypotheses with the linear regression method
# Since there is only one predictor ("Methode"), we obtain the same result as with the t-test.
# Since p > 0.05, the score means of the two methods do not differ significantly.
m <- lm(Resultat ~ Methode, data=metode)
summary(m)
```

```{r message=FALSE, warning=FALSE}
library(effects)
```

Predicted scores

```{r message=FALSE, warning=FALSE}
allEffects(m)
```

Das Diagramm zeigt deutlich, dass kein signifikanter Unterschied zwischen den Mittelwerten der Methoden A und B vorliegt: Die Konfidenzintervalle für beide arithmetische Mittelwerte überschneidet sich fast völlig und schließen damit den jeweiligen Mittelwert der anderen Methode ein. 

```{r message=FALSE, warning=FALSE}
plot(allEffects(m), multiline=TRUE, grid=TRUE, 
     rug=FALSE, as.table=TRUE)
```


Zum Abschluss dieses Kapitels: 

Zur unkomplizierten Visualisierung von Datensatzvariablen, ohne  programmieren zu müssen, eignet sich die `library(esquisse)`. Das Programm ermöglicht die Auswahl von Variablen mit der Maus. 

```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
library(esquisse)
esquisser(metode)

```

