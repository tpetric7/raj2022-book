#### Lineare Regression

Politeness data (B. Winter tutorial)

Programme laden: 

```{r message=FALSE, warning=FALSE}
library(tidyverse)

```


Datei laden: 

```{r message=FALSE, warning=FALSE}
# LOAD
rm(list=ls(all=TRUE)) # clear memory
polite <- read.csv("data/politeness_data.csv", dec=".")

```

Ansicht der Datenlage zu Orientierungszwecken: 

```{r message=FALSE, warning=FALSE}
head(polite)
```

Variablentyp festlegen: 

```{r message=FALSE, warning=FALSE}
polite$frequency = as.numeric(polite$frequency)
polite$scenario = as.factor(polite$scenario)
polite$subject = as.factor(polite$subject)
polite$gender = as.factor(polite$gender)
polite$attitude = as.factor(polite$attitude)

```

Kontraste für den statistischen Test setzen: 

```{r message=FALSE, warning=FALSE}
# In this session we use contr. sum contrasts
options(contrasts=c('contr.sum', 'contr.poly'))
options("contrasts")
```

Kontraste zurücksetzen: 

```{r message=FALSE, warning=FALSE}
# To reset default settings run: 
options(contrasts=c('contr.treatment', 'contr.poly')) 
# (all afex functions should be unaffected by this)

# # Setting contrasts of chosen variables only
# contrasts(polite$attitude) <- contr.treatment(2, base = 1)
 
```

Einfacher Boxplot: 

```{r message=FALSE, warning=FALSE}
boxplot(frequency ~ attitude*gender, 
        col=c("red","green"), data = polite)
```

Bild speichern:   
- z.B. im *jpg*-Format oder    
- im *pdf*-Format.   

```{r message=FALSE, warning=FALSE}
# 1. Open jpeg file
jpeg("pictures/politeness_boxplot.jpg", 
     width = 840, height = 535)
# 2. Create the plot
boxplot(frequency ~ attitude*gender, 
        col=c("red","green"), data = polite) 
# 3. Close the file
dev.off()
```

```{r message=FALSE, warning=FALSE}
# Open a pdf file
pdf("pictures/politeness_boxplot.pdf") 
# 2. Create a plot
boxplot(frequency ~ attitude*gender, 
        col=c("red","green"), data = polite) 
# Close the pdf file
dev.off() 
```

Beziehungen zwischen Variablenpaaren anzeigen: 

```{r message=FALSE, warning=FALSE}
library(psych)
pairs.panels(polite[c(2,4,5)])
```

Lineare Regression mit mehreren unabhängigen Variablen und einer abhängigen Variable, im Englischen auch als *Ordinary Least Squares Regression (OLS)* bekannt.   

Mit allen unabhängigen Variablen: 

```{r message=FALSE, warning=FALSE}
# model 1
m <- lm(frequency ~ gender + attitude + subject + scenario, data = polite)
summary(m)
```

Regression mit denjenigen Variablen, die als Prädiktoren für die abhängige Variable gewählt wurden:    

```{r message=FALSE, warning=FALSE}
# model 2
m <- lm(frequency ~ gender + attitude, data=polite)
summary(m)
```

Koeffizienten der Variablen anzeigen: 

```{r message=FALSE, warning=FALSE}
library(effects)
allEffects(m)
```

Visuelle Darstellung der Regressionsergebnisse: 

```{r message=FALSE, warning=FALSE}
plot(allEffects(m), multiline=TRUE, grid=TRUE, rug=FALSE, as.table=TRUE)
```

Bild sichern: 

```{r message=FALSE, warning=FALSE}
# Save plot of the effects to disk
# 1. Open jpeg file
jpeg("pictures/politeness_lineplot.jpg", 
     width = 840, height = 535)
# 2. Create the plot
plot(allEffects(m), multiline=TRUE, grid=TRUE, rug=FALSE, as.table=TRUE)
# 3. Close the file
dev.off()
```

Ein weiteres Regressionsmodell mit einer Interaktion zwischen den unabhängigen Variablen (Prädiktoren): 

```{r message=FALSE, warning=FALSE}
# model 3 (with interaction)
m <- lm(frequency ~ gender*attitude, data=polite)
summary(m)
```

Koeffizienten der Variablen anzeigen: 

```{r message=FALSE, warning=FALSE}
library(effects)
allEffects(m)
```

Visuelle Darstellung der Regressionsergebnisse: 

```{r message=FALSE, warning=FALSE}
plot(allEffects(m), multiline=TRUE, grid=TRUE, rug=FALSE, as.table=TRUE)
```

Bild als *jpg*-Datei sichern: 

```{r message=FALSE, warning=FALSE}
# Save plot of the effects to disk
# 1. Open jpeg file
jpeg("pictures/politeness_effects.jpg", 
     width = 840, height = 535)
# 2. Create the plot
plot(allEffects(m), multiline=TRUE, grid=TRUE, rug=FALSE, as.table=TRUE)
# 3. Close the file
dev.off()
```

Bild als *pdf*-Datei sichern: 

```{r message=FALSE, warning=FALSE}
# Open a pdf file
pdf("pictures/politeness_effects.pdf") 
# 2. Create a plot
plot(allEffects(m), multiline=TRUE, grid=TRUE, rug=FALSE, as.table=TRUE)
# Close the pdf file
dev.off() 
```

Diagnostische Analyse (sind die Bedingungen für eine Regression erfüllt?): 

```{r message=FALSE, warning=FALSE}
# plot diagnostic diagrams
par(mfrow = c(3,2))
plot(m, which = 1) # variance of residuals vs. fitted values?
plot(m, which = 2) # normal distributed residuals?
plot(m, which = 3) # variance of residuals standardized
plot(m, which = 4) # Cook's distance (outliers / influencing data points?)
plot(m, which = 5) # Leverage vs. standardized variance of residuals
plot(m, which = 6) # Cook's distance vs. Leverage
par(mfrow = c(1,1))

```

Entfernung eines Datenpunktes und die dabei entstehende Veränderung des Koeffizienten: 

```{r message=FALSE, warning=FALSE}
# Change of estimates if one datapoint is removed from the model
d <- dfbetas(m)
head(d) %>% as.data.frame %>% rmarkdown::paged_table()
```

Koeffizienten visuell darstellen: 

```{r message=FALSE, warning=FALSE}
# plot the dfbetas (are there any outliers or data points with high influence?)
par(mfrow = c(1,3))
plot(d[,1], col = "orange")
plot(d[,2], col = "blue")
plot(d[,3], col = "purple")
par(mfrow = c(1,1))
```


#### Regression mit gemischten Effekten
(Mixed effects Regression, Multilevel Regression)

Programme laden: 

```{r message=FALSE, warning=FALSE}
# The variables 'subject' and 'scenario' have been chosen as random effects
library(afex)
```

Regressionsmodell mit einem individuell variierenden Intercept (Ordinate): 

```{r message=FALSE, warning=FALSE}
# random intercepts model
m <- lmer(frequency ~ 
            (1|subject), 
          REML=F, data=polite)
m0.1 <- m
summary(m)
```

Regressionsmodell mit zwei individuell variierenden Intercepts (Ordinaten): 

```{r message=FALSE, warning=FALSE}
# random intercepts model
m <- lmer(frequency ~ 
            (1|subject) + (1|scenario), 
          REML=F, data=polite)
m0.2 <- m
summary(m)
```

Regressionsmodell mit zwei individuell variierenden Intercepts (Ordinaten) und einer kategorischen Variable: 

```{r message=FALSE, warning=FALSE}
# random intercepts model
m <- lmer(frequency ~ gender + 
            (1|subject) + (1|scenario), 
          REML=F, data=polite)
m1 <- m
summary(m)
```

Regressionsmodell mit zwei individuell variierenden Intercepts (Ordinaten) und zwei Prädiktoren, zwei kategorischen Variablen. Von Interesse ist die Variable *attitude* (hier: sprachliches Verhalten). 

```{r message=FALSE, warning=FALSE}
m <- lmer(frequency ~ gender + attitude + 
          (1|subject) + (1|scenario), 
          REML=F, data=polite)
m2 <- m
summary(m)
```

Regressionsmodell mit zwei individuell variierenden Intercepts (Ordinaten) und zwei interagierenden Prädiktoren. Von Interesse ist die Variable *attitude*. 

```{r message=FALSE, warning=FALSE}
m <- lmer(frequency ~ gender*attitude + 
            (1|subject) + (1|scenario), 
          REML=F, data=polite)
m3 <- m
summary(m)
```

Mit dem Programm `jtools` erhält man die Regressionsergebnisse in übersichtlicherer Form und mit zusätzlichen Größenberechnungen:  

```{r}
library(jtools)
summ(m3)
```

Vergleich der Modelle:

```{r message=FALSE, warning=FALSE}
anova(m0.1, m0.2,m1,m2,m3)
```

Mit Hilfe der `anova()`-Funktion kann man eine Anova-Tabelle erstellen. 

```{r}
anova(m3)
```

Die *Anova* (mit Grundfrequenz als abhängige Variable, Geschlecht, Verhalten und ihrer Interaktion als Prädiktoren sowie Versuchspersonen und Szenario als Zufallsvariablen) ergab *Geschlecht* als signifikanten Haupteffekt (F(1; 5,929) = 38,0164; p = 0,0009; $\eta_{p}^2$ = 0,87) und *Verhalten* als signifikanten Haupteffekt auf die Höhe der Grundfrequenz (F(1; 70,925) = 12,8536; p = 0,0006; $\eta_{p}^2$ = 0,15). Die *Interaktion* zwischen Geschlecht und Verhalten war nicht signifikant (F(1; 70,925) = 2,0239; p = 0,15923; $\eta_{p}^2$ = 0,03). 

Das Pseudo-$R^2$ für die Koeffizienten der Prädiktoren beträgt 0,71 (d.h. 71% der Varianz der Grundfrequenz wurden mit den Prädiktoren erklärt), das Pseudo-$R^2$ für die Koeffizienten aller Effekte (fixed effects + random effects) beträgt 0,857 (d.h. mit allen Variablen wurden fast 86% der Grundfrequenzvariation erklärt). 

Der Post-hoc-Test für die *Interaktion* von Geschlecht und Verhalten ergab außerdem signifikant Unterschiede zwischen weiblichen und männlichen Testpersonen hinsichtlich der Grundfrequenzhöhe, und zwar sowohl bei informellen Sprechen (p = 0,0003) als auch bei höflichem Sprechen (p = 0,001). Da unter beiden Bedingungen (informelles vs. höfliches sprachliches Verhalten) ein signifikante Unterschied zwischen weiblichen und männlichen Versuchspersonen festgestellt wurde, führte die Interaktion beider Prädiktoren zu keinem signifikanten Einfluss auf den Verlauf der Grundfrequenz. 

Die $\eta^2$-Funktion: 

```{r}
library(sjstats)
eta_sq(m3, partial = TRUE)
library(effectsize)
eta_squared(m3, partial = TRUE)
```

Die Pseudo-$R^2$-Funktion: 

```{r}
library(MuMIn)
r.squaredGLMM(m3)
```

Der Post-hoc-Test für die Interaktion von Geschlecht und Verhalten: 

```{r}
library(emmeans)
emmeans(m3, pairwise ~ gender)

# with interaction
emmeans(m3, pairwise ~ gender | attitude)
```

Die oben berechneten Regressionsmodelle berücksichtigen die beiden Zufallsvariablen (random effects) Versuchsperson und Szenario. Damit berücksichtigen wir interindividuelle Unterschiede zwischen den Testpersonen und Unterschiede zwischen den verschiedenen Szenarien, die alle die Höhe der Grundfrequenz beeinflussen könnten. Dies ergibt individuelle Regressionskonstanten (Intercepts) für die einzelnen Versuchspersonen und Szenarien.

Unterscheiden sich die Versuchspersonen nun auch darin, dass z.B. bestimmte Szenarien sie eher zu Grundfrequenzvariationen bewegen, d.h. die Steigung des Regressionskoeffizienten individuell beeinflussen (*random slope*)?

Zuerst stellen wir ein Basismodell mit individuellen Steigungskoeffizienten auf: 

```{r message=FALSE, warning=FALSE}
# politeness affected pitch (χ2(1)=11.62, p=0.00065), 
# lowering it by about 19.7 Hz ± 5.6 (standard errors) 

# random slopes model
m <- lmer(frequency ~ gender + 
            (attitude + 1|subject) + (attitude + 1|scenario), 
          REML=F, data=polite)
m00 <- m
summary(m)
```

Dann fügen wir die uns interessierende Variable *attitude* hinzu: 

```{r message=FALSE, warning=FALSE}
m <- lmer(frequency ~ gender + attitude + 
          (attitude + 1|subject) + (attitude + 1|scenario), 
          REML=F, data=polite)
m01 <- m
summary(m)
```

Wenn das Regressionsmodell mit den individuell variierenden Steigungskoeffizienten nicht berechnet werden kann, könnte auch ein Modell mit nur einem individuell variierenden Intercept in Frage kommen, z.B. diesem hier: 

```{r message=FALSE, warning=FALSE}
m <- lmer(frequency ~ gender + attitude + 
            (attitude + 1|subject), 
          REML=F, data=polite)
```

Die Steigungskoeffizienten: 

```{r message=FALSE, warning=FALSE}
library(effects)
allEffects(m)
```

Visuelle Darstellung der Regressionsergebnisse: 

```{r message=FALSE, warning=FALSE}
plot(allEffects(m), multiline=TRUE, grid=TRUE, rug=FALSE, as.table=TRUE)
```

Eine weitere Variante mit nur einem individuell variierenden Steigungskoeffizienten: 

```{r message=FALSE, warning=FALSE}
m <- lmer(frequency ~ gender + attitude + 
            (attitude + 1|scenario), 
          REML=F, data=polite)
```

Die Ergebnisse: 

```{r message=FALSE, warning=FALSE}
library(effects)
allEffects(m)
```

Visuelle Darstellung der Regressionsergebnisse: 

```{r message=FALSE, warning=FALSE}
plot(allEffects(m), multiline=TRUE, grid=TRUE, rug=FALSE, as.table=TRUE)
```

Das volle Regressionsmodell mit zwei individuell variierenden Intercepts und individuell variierenden Steigungskoeffizienten sowie einer Interaktion zweier kategorieller Prädiktoren: 

```{r message=FALSE, warning=FALSE}
m <- lmer(frequency ~ gender*attitude + 
            (attitude + 1|subject) + (attitude + 1|scenario), 
          REML=F, data=polite)
```

Die Regressionsergebnisse: 

```{r message=FALSE, warning=FALSE}
m02 <- m
summary(m)
library(jtools)
summ(m)
```

Vergleich der Modelle:

```{r message=FALSE, warning=FALSE}
anova(m00,m01,m02)
```

Die `step()`-Funktion ermittelt (mittels Rückwärtseliminierung nicht signifikanter Variablen) die entsprechenden Bestandteile der Regressionsgleichung: 

```{r message=FALSE, warning=FALSE}
library(lmerTest)
s <- step(m)
s
```

**Diagnostik** mit Hilfe des Programms `library(LMERConvenienceFunctions)` am Beispiel des Modells ohne Interaktion, aber mit individuell variierenden Intercetps und Steigungskoeffizienten: 

```{r message=FALSE, warning=FALSE}
m <- lmer(frequency ~ gender + attitude + 
            (attitude + 1|subject) + (attitude + 1|scenario), 
          REML=F, data=polite)
m01 <- m
summary(m)
```


```{r message=FALSE, warning=FALSE}
library(LMERConvenienceFunctions)
# Check model asumptions
mcp.fnc(m)
```

Das Programm `library(performance)` hat ebenfalls mehrere Funktionen, um zu überprüfen, ob die Bedingungen für die Durchführung der linearen Regression erfüllt sind: 

```{r message=FALSE, warning=FALSE}
library(performance)
check_model(m)
```

Überprüfung der Varianzhomogenität (für Regression ohne gemischte Effekte): 

```{r message=FALSE, warning=FALSE}
fligner.test(frequency ~ attitude, polite)
```

```{r message=FALSE, warning=FALSE}
fligner.test(frequency ~ gender, polite)
```

Überprüfung auf Normalität der abhängigen Variable mit Hilfe eines statistischen Tests, der aber bei großen Stichproben nicht zuverlässig ist: 

```{r message=FALSE, warning=FALSE}
shapiro.test(polite$frequency)
```

Welcher Datenpunkt fehlt im Datensatz?

```{r message=FALSE, warning=FALSE}
which(is.na(polite$frequency)) 
```

Entfernen des fehlenden Datenpunktes aus dem Datensatz: 

```{r message=FALSE, warning=FALSE}
# delete NA from data frame in row 39
polite1 <- polite[-39,]
```

Programmfunktion, die Ausreißer (outlier) im Datensatz feststellt und entfernt: 

```{r message=FALSE, warning=FALSE}
# Remove outliers
freqout <- romr.fnc(m, polite1, trim=2.5)
```

Anzahl der entfernten Ausreißer: 

```{r message=FALSE, warning=FALSE}
freqout$n.removed
```

Anteil der entfernten Ausreißer: 

```{r message=FALSE, warning=FALSE}
freqout$percent.removed
```

Auswahl des neuen Datensatzes, aus dem die Ausreißer entfernt wurden: 

```{r message=FALSE, warning=FALSE}
freqout <- freqout$data
attach(freqout)
```

Regression mit dem Datensatz, aus dem die Ausreißer entfernt wurden: 

```{r message=FALSE, warning=FALSE}
# update model
m <- lmer(frequency ~ gender + attitude + 
            (attitude + 1|subject) + (attitude + 1|scenario), 
          REML=F, data=freqout)
m01 <- m
summary(m)
library(jtools)
summ(m)
```

Erneute Überprüfung der Varianzhomoskedastizität (Gleichförmigkeit der Varianz) und Normalität der Residuen (Abweichungen vom Mittelwert): 

```{r message=FALSE, warning=FALSE}
# Re-Check model asumptions
mcp.fnc(m)
```

Andere Varianztests (vor allem für Regression ohne gemischte Effekte geeignet): 

```{r message=FALSE, warning=FALSE}
fligner.test(frequency ~ attitude, freqout)
```

```{r message=FALSE, warning=FALSE}
fligner.test(frequency ~ gender, freqout)
```

Normalitätstest (geeignet für kleinere Stichproben): 

```{r message=FALSE, warning=FALSE}
shapiro.test(freqout$frequency)
```

